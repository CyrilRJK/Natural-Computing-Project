{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9UVUW024ePUa"
   },
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "qu7b6yRNJHeZ",
    "outputId": "0fb233f4-8c62-4cfa-f94d-cfd2f000ac27"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, Input, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "IqAu5I9qMDVs",
    "outputId": "eb4022d9-4962-4fdf-f4a7-e67656d72c19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "lf0FZmBcMtlp",
    "outputId": "8857ee77-48fc-4ac4-fb97-de6c57907b24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "jqHMJu6LLyeW",
    "outputId": "63fbdc27-358f-4310-ff3f-4c0b43d6b8b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "colab_type": "code",
    "id": "4Ej9ItFqM7VF",
    "outputId": "91835b0d-09bb-4ca6-d679-31c4f07ffebd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "Number of images in x_train 60000\n",
      "Number of images in x_test 10000\n",
      "y_train shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "# Reshaping the array to 4-dims so that it can work with the Keras API\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "# Making sure that the values are float so that we can get decimal points after division\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('Number of images in x_train', x_train.shape[0])\n",
    "print('Number of images in x_test', x_test.shape[0])\n",
    "print('y_train shape:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "52Wd1PcfGnIH"
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "num_classes=10\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "LyVhuhYbLhJd",
    "outputId": "b042fa03-a22c-4cdd-a67c-ca047c3b50c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N5mx_A56TL2E"
   },
   "outputs": [],
   "source": [
    "# CNN from the Appendix of the 2020 paper \n",
    "\n",
    "\n",
    "inp = Input(shape=input_shape)\n",
    "conv1 = Conv2D(32, (3,3),activation='relu')(inp)\n",
    "conv2 = Conv2D(32, (3,3),activation='relu')(conv1)\n",
    "max_pool1 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "drop = Dropout(0.25)(max_pool1)\n",
    "flat =  Flatten()(drop)\n",
    "dense1 = Dense(128,activation=\"relu\")(flat)\n",
    "drop = Dropout(0.5)(dense1)\n",
    "predictions = Dense(10,activation=\"softmax\")(drop) # softmax layer \n",
    "model = Model(inputs=[inp], outputs=[predictions])\n",
    "\n",
    "model.summary() \n",
    "\n",
    "model.compile(optimizer='Adadelta', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=x_train,y=y_train, epochs=10, validation_data=[x_test,y_test])\n",
    "\n",
    "score= model.evaluate(x_test, y_test,verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model.save_weights(\"CNN_MNIST.h5\")\n",
    "\n",
    "'''\n",
    "RESULT:\n",
    "\n",
    "loss: 0.0457 - accuracy: 0.9871 - val_loss: 0.0327 - val_accuracy: 0.9907\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YLP2XmeH_0p1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d7QTPPyn4zYP"
   },
   "outputs": [],
   "source": [
    "# CNN FROM 2020 PAPER\n",
    "\n",
    "'''\n",
    "I could not train this network because we have input 28x28 , and this network was made for \n",
    "48x48 images , so here there are too many conv and pooling layers for this small image \n",
    "\n",
    "I build it in case we use traffic signs. \n",
    "'''\n",
    "\n",
    "'''\n",
    "inp = Input(shape=input_shape)\n",
    "conv1 = Conv2D(32,(3,3), activation =\"relu\")(inp)\n",
    "conv2 = Conv2D(32,(3,3),activation=\"relu\")(conv1)\n",
    "max_pool1= MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "conv3 = Conv2D(64,(3,3), activation =\"relu\")(max_pool1)\n",
    "conv4 = Conv2D(64,(3,3), activation =\"relu\")(conv3)\n",
    "max_pool2= MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "conv5= Conv2D(128,(3,3), activation =\"relu\")(max_pool2)\n",
    "conv6= Conv2D(128,(3,3), activation =\"relu\")(conv5)\n",
    "max_pool3 = MaxPooling2D(pool_size=(2, 2))(conv6)\n",
    "\n",
    "flat =  Flatten()(max_pool3)\n",
    "dense1 = Dense(512,activation=\"relu\")(flat)\n",
    "predictions = Dense(10,activation=\"softmax\")(dense1) \n",
    "model = Model(inputs=[inp], outputs=[predictions])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='sgd', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aOojffJfYC-k"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "01UtXglNeEkk"
   },
   "source": [
    "## CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100
    },
    "colab_type": "code",
    "id": "e4cc1v7A1q1d",
    "outputId": "b640fc3e-9346-4c10-eb87-8e4d1d3d0658"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 2s 0us/step\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_train_C, y_train_C), (x_test_C, y_test_C) = cifar10.load_data()\n",
    "print('x_train shape:', x_train_C.shape)\n",
    "print(x_train_C.shape[0], 'train samples')\n",
    "print(x_test_C.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iEvHrqRbWTpq"
   },
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices.\n",
    "num_classes=10\n",
    "epochs=10\n",
    "img_shape=32 \n",
    "y_train_C = to_categorical(y_train_C, num_classes)\n",
    "y_test_C = to_categorical(y_test_C, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100
    },
    "colab_type": "code",
    "id": "9Tm_6C7CMO4A",
    "outputId": "7f033f46-305e-418b-eac9-824f06a753d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "Number of images in x_train 50000\n",
      "Number of images in x_test 10000\n",
      "y_train shape: (50000, 10)\n",
      "input shape:  (32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#input_shape = (img_shape, img_shape, 3)\n",
    "\n",
    "x_train_C = x_train_C.astype('float32')\n",
    "x_test_C = x_test_C.astype('float32')\n",
    "x_train_C /= 255\n",
    "x_test_C /= 255\n",
    "\n",
    "\n",
    "print('x_train shape:', x_train_C.shape)\n",
    "print('Number of images in x_train', x_train_C.shape[0])\n",
    "print('Number of images in x_test', x_test_C.shape[0])\n",
    "print('y_train shape:', y_train_C.shape)\n",
    "input_shape=(32,32,1)\n",
    "print(\"input shape: \",input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UoX0u79kvhGO"
   },
   "outputs": [],
   "source": [
    "# CONVERT TO GRAY SCALE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def grayscale(data, dtype='float32'):\n",
    "    # luma coding weighted average in video systems\n",
    "    r, g, b = np.asarray(.3, dtype=dtype), np.asarray(.59, dtype=dtype), np.asarray(.11, dtype=dtype)\n",
    "    rst = r * data[:, :, :, 0] + g * data[:, :, :, 1] + b * data[:, :, :, 2]\n",
    "    # add channel dimension\n",
    "    rst = np.expand_dims(rst, axis=3)\n",
    "    return rst\n",
    "\n",
    "x_train_C = grayscale(x_train_C)\n",
    "x_test_C = grayscale(x_test_C)\n",
    "\n",
    "# now we have only one channel in the images\n",
    "img_channels = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qQQ56xAp6qWC"
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "\n",
    "inp = Input(shape=input_shape)\n",
    "conv1 = Conv2D(32, (3,3),activation='relu')(inp)\n",
    "conv2 = Conv2D(32, (3,3),activation='relu')(conv1)\n",
    "max_pool1 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "drop = Dropout(0.25)(max_pool1)\n",
    "flat =  Flatten()(drop)\n",
    "dense1 = Dense(128,activation=\"relu\")(flat)\n",
    "drop = Dropout(0.5)(dense1)\n",
    "predictions = Dense(10,activation=\"softmax\")(drop) # softmax layer \n",
    "model = Model(inputs=[inp], outputs=[predictions])\n",
    "model.summary()\n",
    "\n",
    "opt = RMSprop(learning_rate=0.0001, decay=1e-6)\n",
    "\n",
    "model.compile(optimizer=opt, \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=x_train_C,y=y_train_C, epochs=30, validation_data=[x_test_C,y_test_C])\n",
    "\n",
    "score= model.evaluate(x_test_C, y_test_C,verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model.save_weights(\"CNN_CIFAR10_GRAYSCALE.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j1KPH7wZ0w1C"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "all results for Cifar10 :\n",
    "\n",
    "Cifar10: \n",
    "\n",
    "1) same network from the paper (as for MNIST), 30 epochs\n",
    "   loss: 1.0949 - accuracy: 0.6321 - val_loss: 1.1367 - val_accuracy: 0.6471\n",
    "\n",
    "2) net 1 - traffic signs network with max pool layer (1,1) , 50 epochs\n",
    "loss: 0.3876 - accuracy: 0.8790 - val_loss: 1.5371 - val_accuracy: 0.6496\n",
    "\n",
    "3) net 2 was too bad and super slow, just skipped it \n",
    "\n",
    "\n",
    "4) net 3- stolen from a blog - epochs=30, batch_size=100 ******* this one I used at the end\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9-RX421sED7J"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('CNN_CIFAR10_GRAYSCALE.h5')\n",
    "files.download('CNN_MNIST.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oPRUHVccafdW"
   },
   "source": [
    "# **TRYOUTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9gBPjc1tfHrE"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wc1y-f-Eah3T"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "this is the network used for traffic signs in Petras paper, I used it here for Cifar10 \n",
    "but just changed max pool layer (1,1) cause dimensions of the image are smaller \n",
    "\n",
    "overfitting after ~9th epoch...\n",
    "'''\n",
    "from keras.optimizers import SGD\n",
    "# NET 1 \n",
    "\n",
    "inp = Input(shape=input_shape)\n",
    "conv1 = Conv2D(32,(3,3), activation =\"relu\")(inp)\n",
    "conv2 = Conv2D(32,(3,3),activation=\"relu\")(conv1)\n",
    "max_pool1= MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "conv3 = Conv2D(64,(3,3), activation =\"relu\")(max_pool1)\n",
    "conv4 = Conv2D(64,(3,3), activation =\"relu\")(conv3)\n",
    "max_pool2= MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "conv5= Conv2D(128,(3,3), activation =\"relu\")(max_pool2)\n",
    "conv6= Conv2D(128,(3,3), activation =\"relu\")(conv5)\n",
    "max_pool3 = MaxPooling2D(pool_size=(1, 1))(conv6)\n",
    "\n",
    "flat =  Flatten()(max_pool3)\n",
    "dense1 = Dense(512,activation=\"relu\")(flat)\n",
    "predictions = Dense(10,activation=\"softmax\")(dense1) \n",
    "model = Model(inputs=[inp], outputs=[predictions])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "opt = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9)\n",
    "\n",
    "model.compile(optimizer=opt, \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=x_train_C,y=y_train_C, epochs=30, validation_data=[x_test_C,y_test_C])\n",
    "\n",
    "score= model.evaluate(x_test_C, y_test_C,verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model.save_weights(\"CNN_CIFAR10_net1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G4SgJhu-ayKS"
   },
   "outputs": [],
   "source": [
    "# Network 2\n",
    "\n",
    "# stolen from Stackoverflow: \n",
    "# https://stats.stackexchange.com/questions/272607/cifar-10-cant-get-above-60-accuracy-keras-with-tensorflow-backend\n",
    "# https://arxiv.org/pdf/1412.6806.pdf\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=input_shape, filters=96, kernel_size=(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(filters=96, kernel_size=(3,3), strides=2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(filters=192, kernel_size=(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(filters=192, kernel_size=(3,3), strides=2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=x_train_C,y=y_train_C, epochs=40, batch_size=100, validation_data=[x_test_C,y_test_C])\n",
    "\n",
    "score= model.evaluate(x_test_C, y_test_C,verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model.save_weights(\"CNN_CIFAR10_net2.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "bsICKif5g_oJ",
    "outputId": "9b98d10b-4c1b-45d8-c3f5-088f7ee9c9e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' accuracy: 0.8827 - val_loss: 0.9329 - val_accuracy: 0.7467 '"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.download('CNN_CIFAR10_net2.h5')\n",
    "''' accuracy: 0.8827 - val_loss: 0.9329 - val_accuracy: 0.7467 '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "pZy-JDUYbyf9",
    "outputId": "29584e39-95e1-4926-caa9-f729d1e1779c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 308,714\n",
      "Trainable params: 307,818\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 448s 9ms/step - loss: 1.8441 - accuracy: 0.4411 - val_loss: 1.4035 - val_accuracy: 0.5183\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 454s 9ms/step - loss: 1.1611 - accuracy: 0.6184 - val_loss: 1.0484 - val_accuracy: 0.6581\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 451s 9ms/step - loss: 0.9731 - accuracy: 0.6821 - val_loss: 0.9236 - val_accuracy: 0.7055\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 454s 9ms/step - loss: 0.8718 - accuracy: 0.7142 - val_loss: 0.8570 - val_accuracy: 0.7365\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 458s 9ms/step - loss: 0.8095 - accuracy: 0.7401 - val_loss: 0.7714 - val_accuracy: 0.7513\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 453s 9ms/step - loss: 0.7538 - accuracy: 0.7619 - val_loss: 0.7755 - val_accuracy: 0.7629\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 457s 9ms/step - loss: 0.7167 - accuracy: 0.7762 - val_loss: 0.7180 - val_accuracy: 0.7841\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 460s 9ms/step - loss: 0.6795 - accuracy: 0.7929 - val_loss: 0.7308 - val_accuracy: 0.7768\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 457s 9ms/step - loss: 0.6430 - accuracy: 0.8047 - val_loss: 0.7611 - val_accuracy: 0.7748\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 451s 9ms/step - loss: 0.6261 - accuracy: 0.8130 - val_loss: 0.7083 - val_accuracy: 0.7912\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 455s 9ms/step - loss: 0.6046 - accuracy: 0.8222 - val_loss: 0.6862 - val_accuracy: 0.8044\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 457s 9ms/step - loss: 0.5822 - accuracy: 0.8332 - val_loss: 0.7365 - val_accuracy: 0.7930\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 459s 9ms/step - loss: 0.5670 - accuracy: 0.8407 - val_loss: 0.6851 - val_accuracy: 0.8114\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 454s 9ms/step - loss: 0.5622 - accuracy: 0.8441 - val_loss: 0.8386 - val_accuracy: 0.7774\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 460s 9ms/step - loss: 0.5455 - accuracy: 0.8512 - val_loss: 0.7044 - val_accuracy: 0.8116\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 460s 9ms/step - loss: 0.5416 - accuracy: 0.8544 - val_loss: 0.7977 - val_accuracy: 0.7926\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 458s 9ms/step - loss: 0.5259 - accuracy: 0.8619 - val_loss: 0.7216 - val_accuracy: 0.8127\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 453s 9ms/step - loss: 0.5199 - accuracy: 0.8664 - val_loss: 0.7014 - val_accuracy: 0.8194\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 457s 9ms/step - loss: 0.5152 - accuracy: 0.8693 - val_loss: 0.7605 - val_accuracy: 0.7956\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 461s 9ms/step - loss: 0.5076 - accuracy: 0.8727 - val_loss: 0.7034 - val_accuracy: 0.8210\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 463s 9ms/step - loss: 0.5062 - accuracy: 0.8740 - val_loss: 0.6881 - val_accuracy: 0.8260\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 457s 9ms/step - loss: 0.4996 - accuracy: 0.8758 - val_loss: 0.7270 - val_accuracy: 0.8198\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 463s 9ms/step - loss: 0.4937 - accuracy: 0.8798 - val_loss: 0.8198 - val_accuracy: 0.7893\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 461s 9ms/step - loss: 0.4911 - accuracy: 0.8820 - val_loss: 0.7471 - val_accuracy: 0.8192\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 459s 9ms/step - loss: 0.4843 - accuracy: 0.8836 - val_loss: 0.7483 - val_accuracy: 0.8209\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 454s 9ms/step - loss: 0.4821 - accuracy: 0.8868 - val_loss: 0.7260 - val_accuracy: 0.8231\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 456s 9ms/step - loss: 0.4741 - accuracy: 0.8905 - val_loss: 0.7556 - val_accuracy: 0.8186\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 459s 9ms/step - loss: 0.4753 - accuracy: 0.8918 - val_loss: 0.7814 - val_accuracy: 0.8131\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 458s 9ms/step - loss: 0.4701 - accuracy: 0.8951 - val_loss: 0.7680 - val_accuracy: 0.8210\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 454s 9ms/step - loss: 0.4693 - accuracy: 0.8940 - val_loss: 0.7353 - val_accuracy: 0.8245\n",
      "Test loss: 0.7353199801445007\n",
      "Test accuracy: 0.8245000243186951\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2b6789cf2870>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CNN_CIFAR10_net3.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CNN_CIFAR10_net3_weights.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CNN_CIFAR10_net3.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CNN_CIFAR10_net3_weights.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mode' is not defined"
     ]
    }
   ],
   "source": [
    "# Network 3 \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar10\n",
    "from keras import regularizers\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import numpy as np\n",
    "'''\n",
    "Stolen from https://appliedmachinelearning.blog/2018/03/24/achieving-90-accuracy-in-object-recognition-task-on-cifar-10-dataset-with-keras-convolutional-neural-networks/\n",
    "\n",
    "- without z-score, without data augmentation \n",
    "\n",
    "'''\n",
    "weight_decay = 1e-4\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=input_shape))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    " \n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    " \n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    " \n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    " \n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(x=x_train_C,y=y_train_C, epochs=30, batch_size=100, validation_data=[x_test_C,y_test_C])\n",
    "\n",
    "score= model.evaluate(x_test_C, y_test_C,verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model.save(\"CNN_CIFAR10_net3.h5\")\n",
    "model.save_weights(\"CNN_CIFAR10_net3_weights.h5\")\n",
    "files.download('CNN_CIFAR10_net3.h5')\n",
    "files.download(\"CNN_CIFAR10_net3_weights.h5\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "training_CNN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
