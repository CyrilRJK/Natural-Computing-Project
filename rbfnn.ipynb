{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RBF Neural Network is based on the implementation of [this github repo](https://github.com/darecophoenixx/wordroid.sblo.jp/tree/master/lib/keras_ex/gkernel)\n",
    "\n",
    "\n",
    "Also, to train the MNIST dataset, [his example of digit recognizer](https://www.kaggle.com/wordroid/keras-rbf-layer-quick-start) is heavily used.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links (if you cannot open):\n",
    "* https://github.com/darecophoenixx/wordroid.sblo.jp/tree/master/lib/keras_ex/gkernel\n",
    "* https://www.kaggle.com/wordroid/keras-rbf-layer-quick-start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install the Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/darecophoenixx/wordroid.sblo.jp\r\n",
      "  Cloning https://github.com/darecophoenixx/wordroid.sblo.jp to /tmp/pip-req-build-b3d_tneo\r\n",
      "Requirement already satisfied: gensim in /opt/conda/lib/python3.6/site-packages (from wordroid.sblo.jp==0.0.1) (3.7.2)\r\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.6/site-packages (from gensim->wordroid.sblo.jp==0.0.1) (1.1.0)\r\n",
      "Requirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.6/site-packages (from gensim->wordroid.sblo.jp==0.0.1) (1.16.3)\r\n",
      "Requirement already satisfied: six>=1.5.0 in /opt/conda/lib/python3.6/site-packages (from gensim->wordroid.sblo.jp==0.0.1) (1.12.0)\r\n",
      "Requirement already satisfied: smart-open>=1.7.0 in /opt/conda/lib/python3.6/site-packages (from gensim->wordroid.sblo.jp==0.0.1) (1.8.2)\r\n",
      "Requirement already satisfied: boto>=2.32 in /opt/conda/lib/python3.6/site-packages (from smart-open>=1.7.0->gensim->wordroid.sblo.jp==0.0.1) (2.48.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from smart-open>=1.7.0->gensim->wordroid.sblo.jp==0.0.1) (2.21.0)\r\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.6/site-packages (from smart-open>=1.7.0->gensim->wordroid.sblo.jp==0.0.1) (1.9.134)\r\n",
      "Requirement already satisfied: bz2file in /opt/conda/lib/python3.6/site-packages (from smart-open>=1.7.0->gensim->wordroid.sblo.jp==0.0.1) (0.98)\r\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->smart-open>=1.7.0->gensim->wordroid.sblo.jp==0.0.1) (2.6)\r\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->smart-open>=1.7.0->gensim->wordroid.sblo.jp==0.0.1) (3.0.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->smart-open>=1.7.0->gensim->wordroid.sblo.jp==0.0.1) (2019.3.9)\r\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->smart-open>=1.7.0->gensim->wordroid.sblo.jp==0.0.1) (1.22)\r\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from boto3->smart-open>=1.7.0->gensim->wordroid.sblo.jp==0.0.1) (0.2.0)\r\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.134 in /opt/conda/lib/python3.6/site-packages (from boto3->smart-open>=1.7.0->gensim->wordroid.sblo.jp==0.0.1) (1.12.134)\r\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3->smart-open>=1.7.0->gensim->wordroid.sblo.jp==0.0.1) (0.9.4)\r\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /opt/conda/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.134->boto3->smart-open>=1.7.0->gensim->wordroid.sblo.jp==0.0.1) (2.6.0)\r\n",
      "Requirement already satisfied: docutils>=0.10 in /opt/conda/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.134->boto3->smart-open>=1.7.0->gensim->wordroid.sblo.jp==0.0.1) (0.14)\r\n",
      "Building wheels for collected packages: wordroid.sblo.jp\r\n",
      "  Building wheel for wordroid.sblo.jp (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-evnaf8uq/wheels/3d/6d/24/44e7d6dc47b39e74772a04beb27433ba2ebed90876394cda60\r\n",
      "Successfully built wordroid.sblo.jp\r\n",
      "Installing collected packages: wordroid.sblo.jp\r\n",
      "Successfully installed wordroid.sblo.jp-0.0.1\r\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 20.1 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/darecophoenixx/wordroid.sblo.jp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras and tf versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other libraries that are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from keras_ex.gkernel import GaussianKernel, GaussianKernel2, GaussianKernel3\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get MNIST data and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X, y), (X_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape((X.shape[0], -1))\n",
    "X_sc = X / 256.0\n",
    "X_sc.shape\n",
    "y_cat = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape((X_test.shape[0], -1))\n",
    "X_test_sc = X_test / 256.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Choose landmarks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "chose landmarks from sample\n",
    "pick 10 data each digit\n",
    "'''\n",
    "np.random.seed(0)\n",
    "num_lm0 = 100\n",
    "num_lm = num_lm0 * 10\n",
    "init_list = []\n",
    "for ii in range(10):\n",
    "    init_wgt0 = X_sc[y==ii]\n",
    "    init_wgt0 = init_wgt0[np.random.choice(range(init_wgt0.shape[0]), size=num_lm0, replace=False)] + \\\n",
    "                np.random.normal(scale=0.01, size=num_lm0*784).reshape(num_lm0, 784)\n",
    "    init_list.append(init_wgt0)\n",
    "init_wgt = np.vstack(init_list)\n",
    "init_wgt = init_wgt[np.random.permutation(range(init_wgt.shape[0]))]\n",
    "init_wgt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inp (InputLayer)             (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "gkernel1 (GaussianKernel)    (None, 1000)              784000    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 794,010\n",
      "Trainable params: 794,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "inp = Input(shape=(28*28,), name='inp')\n",
    "oup = GaussianKernel(num_lm, 28*28,\n",
    "                     kernel_gamma='auto', weights=[init_wgt],\n",
    "                     name='gkernel1')(inp)\n",
    "oup = Dense(10, activation='softmax')(oup)\n",
    "model = Model(inp, oup)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/250\n",
      "60000/60000 [==============================] - 4s 75us/step - loss: 1.8494 - acc: 0.5292\n",
      "Epoch 2/250\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 1.1754 - acc: 0.7643\n",
      "Epoch 3/250\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.8726 - acc: 0.8070\n",
      "Epoch 4/250\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.7117 - acc: 0.8394\n",
      "Epoch 5/250\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.6176 - acc: 0.8561\n",
      "Epoch 6/250\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.5559 - acc: 0.8649\n",
      "Epoch 7/250\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.5081 - acc: 0.8752\n",
      "Epoch 8/250\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.4759 - acc: 0.8809\n",
      "Epoch 9/250\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.4493 - acc: 0.8861\n",
      "Epoch 10/250\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.4293 - acc: 0.8898\n",
      "Epoch 11/250\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.4132 - acc: 0.8925\n",
      "Epoch 12/250\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.4015 - acc: 0.8935\n",
      "Epoch 13/250\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.3886 - acc: 0.8957\n",
      "Epoch 14/250\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.3792 - acc: 0.8982\n",
      "Epoch 15/250\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.3713 - acc: 0.8989\n",
      "Epoch 16/250\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.3643 - acc: 0.9008\n",
      "Epoch 17/250\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.3588 - acc: 0.9018\n",
      "Epoch 18/250\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.3515 - acc: 0.9040\n",
      "Epoch 19/250\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.3461 - acc: 0.9043\n",
      "Epoch 20/250\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.3430 - acc: 0.9055\n",
      "Epoch 21/250\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.3389 - acc: 0.9055\n",
      "Epoch 22/250\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.3347 - acc: 0.9064\n",
      "Epoch 23/250\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.3321 - acc: 0.9076\n",
      "Epoch 24/250\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.3279 - acc: 0.9092\n",
      "Epoch 25/250\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.3256 - acc: 0.9079\n",
      "Epoch 26/250\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.3222 - acc: 0.9102\n",
      "Epoch 27/250\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.3206 - acc: 0.9102\n",
      "Epoch 28/250\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.3191 - acc: 0.9097\n",
      "Epoch 29/250\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.3161 - acc: 0.9105\n",
      "Epoch 30/250\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.3127 - acc: 0.9124\n",
      "Epoch 31/250\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.3121 - acc: 0.9125\n",
      "Epoch 32/250\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.3099 - acc: 0.9126\n",
      "Epoch 33/250\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.3077 - acc: 0.9135\n",
      "Epoch 34/250\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.3069 - acc: 0.9138\n",
      "Epoch 35/250\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.3070 - acc: 0.9135\n",
      "Epoch 36/250\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.3036 - acc: 0.9142\n",
      "Epoch 37/250\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.3033 - acc: 0.9140\n",
      "Epoch 38/250\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.3013 - acc: 0.9140\n",
      "Epoch 39/250\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.3000 - acc: 0.9148\n",
      "Epoch 40/250\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.3000 - acc: 0.9145\n",
      "Epoch 41/250\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.2985 - acc: 0.9145\n",
      "Epoch 42/250\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.2974 - acc: 0.9157\n",
      "Epoch 43/250\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.2958 - acc: 0.9166\n",
      "Epoch 44/250\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2940 - acc: 0.9162\n",
      "Epoch 45/250\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2934 - acc: 0.9166\n",
      "Epoch 46/250\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.2929 - acc: 0.9167\n",
      "Epoch 47/250\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.2915 - acc: 0.9176\n",
      "Epoch 48/250\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.2918 - acc: 0.9164\n",
      "Epoch 49/250\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.2905 - acc: 0.9174\n",
      "Epoch 50/250\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.2905 - acc: 0.9179\n",
      "Epoch 51/250\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2879 - acc: 0.9176\n",
      "Epoch 52/250\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.2882 - acc: 0.9177\n",
      "Epoch 53/250\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2869 - acc: 0.9183\n",
      "Epoch 54/250\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.2873 - acc: 0.9183\n",
      "Epoch 55/250\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.2852 - acc: 0.9187\n",
      "Epoch 56/250\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.2857 - acc: 0.9182\n",
      "Epoch 57/250\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.2830 - acc: 0.9195\n",
      "Epoch 58/250\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.2847 - acc: 0.9179\n",
      "Epoch 59/250\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.2825 - acc: 0.9193\n",
      "Epoch 60/250\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2828 - acc: 0.9194\n",
      "Epoch 61/250\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.2816 - acc: 0.9199\n",
      "Epoch 62/250\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.2809 - acc: 0.9197\n",
      "Epoch 63/250\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2817 - acc: 0.9198\n",
      "Epoch 64/250\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.2793 - acc: 0.9203\n",
      "Epoch 65/250\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.2790 - acc: 0.9200\n",
      "Epoch 66/250\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.2777 - acc: 0.9214\n",
      "Epoch 67/250\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.2787 - acc: 0.9204\n",
      "Epoch 68/250\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2775 - acc: 0.9214\n",
      "Epoch 69/250\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.2774 - acc: 0.9206\n",
      "Epoch 70/250\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.2764 - acc: 0.9212\n",
      "Epoch 71/250\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.2764 - acc: 0.9216\n",
      "Epoch 72/250\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.2781 - acc: 0.9208\n",
      "Epoch 73/250\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.2768 - acc: 0.9215\n",
      "Epoch 74/250\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2763 - acc: 0.9207\n",
      "Epoch 75/250\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.2745 - acc: 0.9218\n",
      "Epoch 76/250\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.2741 - acc: 0.9218\n",
      "Epoch 77/250\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.2748 - acc: 0.9213\n",
      "Epoch 78/250\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.2728 - acc: 0.9224\n",
      "Epoch 79/250\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.2735 - acc: 0.9222\n",
      "Epoch 80/250\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.2726 - acc: 0.9225\n",
      "Epoch 81/250\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.2700 - acc: 0.9230\n",
      "Epoch 82/250\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.2713 - acc: 0.9231\n",
      "Epoch 83/250\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.2709 - acc: 0.9229\n",
      "Epoch 84/250\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.2696 - acc: 0.9234\n",
      "Epoch 85/250\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.2708 - acc: 0.9229\n",
      "Epoch 86/250\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.2703 - acc: 0.9236\n",
      "Epoch 87/250\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2697 - acc: 0.9231\n",
      "Epoch 88/250\n",
      "48500/60000 [=======================>......] - ETA: 0s - loss: 0.2695 - acc: 0.9237"
     ]
    }
   ],
   "source": [
    "model.fit(X_sc, y_cat, verbose=1,batch_size=500,epochs=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model.predict(X_test_sc)\n",
    "y_pred_train = model.predict(X_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.93305\n",
      "Test accuracy:  0.9297\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy: \",accuracy_score(y,np.argmax(y_pred_train,axis=1)))\n",
    "print(\"Test accuracy: \",accuracy_score(y_test,np.argmax(y_pred_test,axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conf matrix train:\n",
      "  [[5759    1    9    9   12   37   37    7   48    4]\n",
      " [   1 6620   16   20    6   21    3    7   38   10]\n",
      " [  33  123 5236  102   81   24   79   79  172   29]\n",
      " [  20   50   69 5540    5  196   18   48  124   61]\n",
      " [  11   35   16    4 5480    6   53    6   34  197]\n",
      " [  48   31   13  106   48 4946   74   12   97   46]\n",
      " [  33   26   16    1   46   76 5685    3   31    1]\n",
      " [  16   45   42   16   50   10    2 5879   16  189]\n",
      " [  30  137   22   94   24   97   33   11 5342   61]\n",
      " [  24   42    8   65  127   29    2  109   47 5496]]\n",
      "Conf matrix test:\n",
      "  [[ 964    0    1    2    0    3    5    2    3    0]\n",
      " [   0 1120    2    2    0    1    4    2    4    0]\n",
      " [   7   15  899   20    9    3   15   11   45    8]\n",
      " [   3    2    8  929    1   23    2   11   19   12]\n",
      " [   1    3    2    1  918    0   11    2    6   38]\n",
      " [   9    4    0   26   10  790   16    5   24    8]\n",
      " [  10    3    4    0    9   16  910    2    4    0]\n",
      " [   1   15   14    7    9    2    0  944    3   33]\n",
      " [   7   10    3   14    9   15    8    6  895    7]\n",
      " [   8    9    1    8   27   11    1   11    5  928]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Conf matrix train:\\n \",confusion_matrix(y,np.argmax(y_pred_train,axis=1)))\n",
    "print(\"Conf matrix test:\\n \",confusion_matrix(y_test,np.argmax(y_pred_test,axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRFS train:\n",
      " (array([0.96384937, 0.93108298, 0.96126308, 0.92999832, 0.93213131,\n",
      "       0.90885704, 0.949716  , 0.95422821, 0.89796604, 0.90187069]), array([0.97231133, 0.98190448, 0.8788184 , 0.90360463, 0.93803492,\n",
      "       0.91237779, 0.96062859, 0.93838787, 0.91300632, 0.92385275]), array([0.96806186, 0.95581865, 0.91819377, 0.91661152, 0.9350738 ,\n",
      "       0.91061401, 0.95514113, 0.94624175, 0.90542373, 0.91272939]), array([5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949]))\n",
      "PRFS test:\n",
      " (array([0.95445545, 0.94834886, 0.96252677, 0.92071358, 0.92540323,\n",
      "       0.91435185, 0.93621399, 0.94779116, 0.88789683, 0.89748549]), array([0.98367347, 0.98678414, 0.87112403, 0.91980198, 0.93482688,\n",
      "       0.88565022, 0.94989562, 0.91828794, 0.91889117, 0.9197225 ]), array([0.96884422, 0.9671848 , 0.9145473 , 0.92025755, 0.93009119,\n",
      "       0.89977221, 0.94300518, 0.93280632, 0.90312815, 0.90846794]), array([ 980, 1135, 1032, 1010,  982,  892,  958, 1028,  974, 1009]))\n"
     ]
    }
   ],
   "source": [
    "print(\"PRFS train:\\n\",precision_recall_fscore_support(y,np.argmax(y_pred_train,axis=1)))\n",
    "print(\"PRFS test:\\n\",precision_recall_fscore_support(y_test,np.argmax(y_pred_test,axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"rbfnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp2 = Input(shape=(28*28,), name='inp')\n",
    "oup2 = GaussianKernel(num_lm, 28*28,\n",
    "                     kernel_gamma='auto', weights=[init_wgt],\n",
    "                     name='gkernel1')(inp2)\n",
    "oup2 = Dense(10, activation='softmax')(oup2)\n",
    "model2 = Model(inp2, oup2)\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_weights(\"rbfnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model2.predict(X_test_sc)\n",
    "y_pred_train = model2.predict(X_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.93305\n",
      "Test accuracy:  0.9297\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy: \",accuracy_score(y,np.argmax(y_pred_train,axis=1)))\n",
    "print(\"Test accuracy: \",accuracy_score(y_test,np.argmax(y_pred_test,axis=1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
