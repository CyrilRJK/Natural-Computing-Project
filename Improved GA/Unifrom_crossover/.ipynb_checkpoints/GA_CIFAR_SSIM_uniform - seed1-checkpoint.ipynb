{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OmqP9iw8qi2w"
   },
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a4o2nRW3uHkP"
   },
   "source": [
    "In this notebook I did not normalized images before evolving, just when predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "lV-6sDntqd61",
    "outputId": "0cbc2ce7-49b2-4fbc-ebea-609b58207590"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "import time\n",
    "from skimage.measure import compare_ssim\n",
    "import tensorflow as tf\n",
    "from keras.models import Model,load_model\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, Input, Activation\n",
    "from keras.utils import to_categorical\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kGtAwbEMqmmv"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-51197199c029>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Set seeds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "#Set seeds\n",
    "random.seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UMYv1iroqpKy"
   },
   "source": [
    "# GLOBAL VARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3JLxcgMPqoDE"
   },
   "outputs": [],
   "source": [
    "INDIVIDUALS = 50\n",
    "P_CROSS = 0.6\n",
    "P_MUTATION = 0.01\n",
    "CIFAR_IMG= 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uhUutenzqt18"
   },
   "source": [
    "# THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "ZZTtcGJAJLuM",
    "outputId": "2cbc5552-7adf-47f3-eb0c-3c949c60c25c"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_train_C, y_train_C), (x_test_C, y_test_C) = cifar10.load_data()\n",
    "print('x_train shape:', x_train_C.shape)\n",
    "print(x_train_C.shape[0], 'train samples')\n",
    "print(x_test_C.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "num_classes=10\n",
    "epochs=10\n",
    "img_shape=32 \n",
    "y_train_C = to_categorical(y_train_C, num_classes)\n",
    "y_test_C = to_categorical(y_test_C, num_classes)\n",
    "\n",
    "\n",
    "input_shape=(32,32,1)\n",
    "\n",
    "x_train_C = x_train_C.astype('float32')\n",
    "x_test_C = x_test_C.astype('float32')\n",
    "x_train_C /= 255\n",
    "x_test_C /= 255\n",
    "\n",
    "\n",
    "print('x_train shape:', x_train_C.shape)\n",
    "print('Number of images in x_train', x_train_C.shape[0])\n",
    "print('Number of images in x_test', x_test_C.shape[0])\n",
    "print('y_train shape:', y_train_C.shape)\n",
    "print(\"input shape: \",input_shape)\n",
    "\n",
    "\n",
    "# CONVERT TO GRAY SCALE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def grayscale(data, dtype='float32'):\n",
    "    # luma coding weighted average in video systems\n",
    "    r, g, b = np.asarray(.3, dtype=dtype), np.asarray(.59, dtype=dtype), np.asarray(.11, dtype=dtype)\n",
    "    rst = r * data[:, :, :, 0] + g * data[:, :, :, 1] + b * data[:, :, :, 2]\n",
    "    # add channel dimension\n",
    "    rst = np.expand_dims(rst, axis=3)\n",
    "    return rst\n",
    "\n",
    "x_train_C = grayscale(x_train_C)\n",
    "x_test_C = grayscale(x_test_C)\n",
    "\n",
    "# now we have only one channel in the images\n",
    "img_channels = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_--StA9kq4mw"
   },
   "source": [
    "# READ PICKLE FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F3glGbBeq2lz"
   },
   "outputs": [],
   "source": [
    "with open('../../Subsets/subset_cifar', 'rb') as f:\n",
    "    original = pickle.load(f)\n",
    "    adversarial= pickle.load(f)\n",
    "    original_y = pickle.load(f)\n",
    "    adversarial_y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "n1LZoAPNq996",
    "outputId": "02f5a576-8da4-4b94-ebee-630982d4884b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape (914, 32, 32, 1)\n",
      "Adversarial shape (133, 32, 32, 1)\n",
      "Original labels shape (914, 1)\n",
      "Adversarial labels shape (133, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original shape {original.shape}\")\n",
    "print(f\"Adversarial shape {adversarial.shape}\")\n",
    "print(f\"Original labels shape {original_y.shape}\")\n",
    "print(f\"Adversarial labels shape {adversarial_y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zr0TMOV_q_9J"
   },
   "source": [
    "# LOAD THE MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JibFPCmerJwW"
   },
   "source": [
    "3. CNN v2\n",
    "\n",
    "This network is made for CIFAR 10. The network is taken from [this blog]( https://appliedmachinelearning.blog/2018/03/24/achieving-90-accuracy-in-object-recognition-task-on-cifar-10-dataset-with-keras-convolutional-neural-networks/) . In this version below I didn't use some things used in the blog e.g. z-score and data augmentation.\n",
    "\n",
    "\n",
    "This network has training accuracy: 0.8940 , validation accuracy: 0.8245.\n",
    "\n",
    "**NOTE:** Training really slow, try to avoid it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "DjDjKgyWJwqY",
    "outputId": "12e3326d-926a-4871-80ff-dc618756132c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 308,714\n",
      "Trainable params: 307,818\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Network 3 \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar10\n",
    "from keras import regularizers\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import numpy as np\n",
    "\n",
    "input_shape = (CIFAR_IMG,CIFAR_IMG,1)\n",
    "weight_decay = 1e-4\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=input_shape))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    " \n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    " \n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    " \n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    " \n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "'''\n",
    "history = model.fit(x=x_train_C,y=y_train_C, epochs=150, batch_size=64, validation_data=[x_test_C,y_test_C])\n",
    "\n",
    "score= model.evaluate(x_test_C, y_test_C,verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model.save_weights(\"CNN_CIFAR10_net3.h5\")\n",
    "files.download('CNN_CIFAR10_net3.h5')\n",
    "'''\n",
    "\n",
    "model = load_model(\"../../Models/CNN_CIFAR10_net3.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MGSQOJJprRG-"
   },
   "source": [
    "# GENETIC ALGORITHM FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQuqZrKL4qqW"
   },
   "outputs": [],
   "source": [
    "\n",
    "def computing_SSIM(individual,target):\n",
    "    return compare_ssim(individual.reshape(CIFAR_IMG,CIFAR_IMG), target.reshape(CIFAR_IMG,CIFAR_IMG))\n",
    "\n",
    "def calculate_fitness(model,ind,target_image,label,l1=0.2, l2=0.8, N=50, num_classes=10):\n",
    "  # predict the population\n",
    "  predictions=model.predict(ind.reshape(1,CIFAR_IMG,CIFAR_IMG,1) / 255.0)  \n",
    "  # po is the ground truth prediction, so for label = 0, it will be prediciton[0]\n",
    "  predictions=predictions[0]\n",
    "  po=predictions[label]\n",
    "  # set that value to 0\n",
    "  predictions[label]=0\n",
    "  # take next highest one\n",
    "  pd = np.max(predictions)\n",
    "  diff=pd-po\n",
    "  return l1*computing_SSIM(ind.reshape(CIFAR_IMG,CIFAR_IMG),target_image.reshape(CIFAR_IMG,CIFAR_IMG)) +l2*(diff)\n",
    "  \n",
    "\n",
    "\n",
    "def pop_fitness(model,pop,target,label):\n",
    "    return [calculate_fitness(model, p, target, label) for p in pop]\n",
    "\n",
    "def flatten(imgs):\n",
    "    # flatten all images in np array or list\n",
    "    return np.array([im.flatten() for im in imgs])\n",
    "\n",
    "def gaussian_noise():\n",
    "    # draw one sample of noise from zero mean 1 variance Gaussian\n",
    "    return np.random.normal(0, 10)\n",
    "\n",
    "def p_noise(x):\n",
    "  if 0.01 > np.random.uniform():\n",
    "    return x + gaussian_noise()\n",
    "  else:\n",
    "    return x\n",
    "    \n",
    "def add_noise(image):\n",
    "    noise_v=np.vectorize(p_noise)\n",
    "    return noise_v(image) #np.array([x + gaussian_noise() if P_MUTATION > np.random.uniform(0.0, 1.0) else x+0 for x in image])\n",
    "\n",
    "def k_crossover(im1, im2, k=1):\n",
    "    c1, c2 = [], []\n",
    "    # get k crossover points\n",
    "    points = sorted([np.random.randint(0, CIFAR_IMG*CIFAR_IMG-1, 1) for p in range(k)])\n",
    "    points = sorted([np.random.randint(0,CIFAR_IMG*CIFAR_IMG-1,1) for p in range(k)])\n",
    "    im_1_split = np.split(im1, [int(p) for p in points])\n",
    "    im_2_split = np.split(im2, [int(p) for p in points])\n",
    "    \n",
    "    # alternate between lists to realise crossover (theres got to be a more clever way to do this)\n",
    "    for i in range(k+1):\n",
    "        if i % 2 == 0:\n",
    "            c1.append(im_1_split[i])\n",
    "            c2.append(im_2_split[i])\n",
    "        else:\n",
    "            c1.append(im_2_split[i])\n",
    "            c2.append(im_1_split[i])\n",
    "    return np.concatenate(c1, axis=0), np.concatenate(c2, axis=0)\n",
    "\n",
    "def tournament(pop, model, ground_truth, target, k=3):\n",
    "\n",
    "    indices = np.random.choice(range(len(pop)), k, replace=False) #we get 3 indxes [2 34 46]    \n",
    "    individuals = pop.take(indices,axis=0)\n",
    "    scores = pop_fitness(model,np.expand_dims(individuals.reshape(individuals.shape[0],CIFAR_IMG,CIFAR_IMG),axis=3), ground_truth.reshape(CIFAR_IMG,CIFAR_IMG), target)\n",
    "    index_max = np.argmax(scores)\n",
    "    winner = individuals[index_max]\n",
    "    return winner\n",
    "\n",
    "\n",
    "def check_adv_termination(ind, label,ground_truth, model):\n",
    "  # individual - the best one from the generation\n",
    "  # label - class we want\n",
    "  # ground_truth - the image (32,32)\n",
    "  # model we are using \n",
    "  dist = 1-compare_ssim(ind.reshape(CIFAR_IMG,CIFAR_IMG),ground_truth.reshape(CIFAR_IMG,CIFAR_IMG))\n",
    "  predictions= model.predict(ind.reshape(1,CIFAR_IMG,CIFAR_IMG,1)/255.0)\n",
    "  predicted_label= np.argmax(predictions[0])\n",
    "  if label != predicted_label and dist < 0.001:\n",
    "    print(\"FOUND ADVERSARIAL\")\n",
    "    print(f\"Fitness of the adversarial {calculate_fitness(model,ind,ground_truth,label)}\")\n",
    "    return ind\n",
    "  return []\n",
    "\n",
    "def init_pop_from_sample(n,img,label):\n",
    "    x = np.array([add_noise(img) for i in range(n)])\n",
    "    return x.reshape(n, CIFAR_IMG*CIFAR_IMG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-epJQRlguXyK"
   },
   "source": [
    "Functions from the past, just didn't want to erase them yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "zlm5dKzOuXNw",
    "outputId": "00d4613d-f533-4e7a-cce0-cd5ad53ee562"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef check_adverserial(pop, model, fitness, target,ground_truth):\\n    #print(f\"this is adversarial function\")\\n    preds=model.predict(pop.reshape(pop.shape[0],28,28,1))\\n    #print(f\"These are predictions made here {preds}\")\\n    for ind, pr in zip(pop,preds): \\n      #print(f\"prediction for an individual {pr}\")\\n      preds=np.argmax(pr)\\n      #print(f\"getting the index of highest value in predictions {preds}\")\\n      #setting the value to 0\\n      pr[0]=0\\n      #print(f\"this is our target {target}\")\\n      #print(f\"this is out ground_truth {ground_truth.shape}\")\\n      fitness=computing_SSIM(ind.reshape(28,28),ground_truth.reshape(28,28))\\n      #print(f\"these are the fitness values {fitness}\")\\n      next_highest = np.argmax(pr)\\n      #print(f\"getting the next highest value {next_highest}\")\\n      if next_highest != target and fitness > 0.98:\\n          return ind, True\\n      return None, False\\n\\ndef init_pop(n, num, data, labels):\\n    indices = np.where(labels==num)[0]\\n    n_indices = np.random.choice(indices, n, replace=True)\\n    sample = np.take(data, n_indices, axis=0)\\n    return sample, np.full((n), num, dtype=int) # return sample+array of labels\\n\\n\\nCyrils model\\n\\ndef save_trained_model(model, filename=\\'SVC_model.sav\\'):\\n    pickle.dump(model, open(filename, \\'wb\\'))\\n    \\ndef load_trained_model(filename=\\'SVC_model.sav\\'):\\n    return pickle.load(open(filename, \\'rb\\'))\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def check_adverserial(pop, model, fitness, target,ground_truth):\n",
    "    #print(f\"this is adversarial function\")\n",
    "    preds=model.predict(pop.reshape(pop.shape[0],28,28,1))\n",
    "    #print(f\"These are predictions made here {preds}\")\n",
    "    for ind, pr in zip(pop,preds): \n",
    "      #print(f\"prediction for an individual {pr}\")\n",
    "      preds=np.argmax(pr)\n",
    "      #print(f\"getting the index of highest value in predictions {preds}\")\n",
    "      #setting the value to 0\n",
    "      pr[0]=0\n",
    "      #print(f\"this is our target {target}\")\n",
    "      #print(f\"this is out ground_truth {ground_truth.shape}\")\n",
    "      fitness=computing_SSIM(ind.reshape(28,28),ground_truth.reshape(28,28))\n",
    "      #print(f\"these are the fitness values {fitness}\")\n",
    "      next_highest = np.argmax(pr)\n",
    "      #print(f\"getting the next highest value {next_highest}\")\n",
    "      if next_highest != target and fitness > 0.98:\n",
    "          return ind, True\n",
    "      return None, False\n",
    "\n",
    "def init_pop(n, num, data, labels):\n",
    "    indices = np.where(labels==num)[0]\n",
    "    n_indices = np.random.choice(indices, n, replace=True)\n",
    "    sample = np.take(data, n_indices, axis=0)\n",
    "    return sample, np.full((n), num, dtype=int) # return sample+array of labels\n",
    "\n",
    "\n",
    "Cyrils model\n",
    "\n",
    "def save_trained_model(model, filename='SVC_model.sav'):\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    \n",
    "def load_trained_model(filename='SVC_model.sav'):\n",
    "    return pickle.load(open(filename, 'rb'))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FOEo4wAfggNs"
   },
   "outputs": [],
   "source": [
    "''' my part of the code ''' \n",
    "''' I know it is ugly, I will fix it . this is the intial version'''\n",
    "# from Goorge Clooney paper\n",
    "def quadrant_crossover(parent_1,parent_2):\n",
    "\n",
    "  # reshape parents\n",
    "  parent_1,parent_2= parent_1.reshape((CIFAR_IMG,CIFAR_IMG)), parent_2.reshape((CIFAR_IMG,CIFAR_IMG))\n",
    "  # quadrants for both parents\n",
    "  p1,p2,p3,p4,q1,q2,q3,q4 = [],[],[],[],[],[],[],[]\n",
    "  child1, child2 = [],[]\n",
    "  # getting random (x,y) point in 2D matrix\n",
    "  x,y = np.random.randint(0,CIFAR_IMG-1), np.random.randint(0,CIFAR_IMG-1)  \n",
    "\n",
    "  # choose which quadrant we want to crossover\n",
    "  N = np.random.randint(0,3)\n",
    "  #make quadrants\n",
    "  for i in range(CIFAR_IMG):\n",
    "    if (i<=x):\n",
    "      p1.append(parent_1[i][:y+1])\n",
    "      p2.append(parent_1[i][y+1:])\n",
    "      q1.append(parent_2[i][:y+1])\n",
    "      q2.append(parent_2[i][y+1:])\n",
    "    else:\n",
    "      p3.append(parent_1[i][:y+1])\n",
    "      p4.append(parent_1[i][y+1:])\n",
    "      q3.append(parent_2[i][:y+1])\n",
    "      q4.append(parent_2[i][y+1:])\n",
    "\n",
    "  if (N==0):\n",
    "    ch1 = connect_quadrants(p1,q2,q3,q4)\n",
    "    ch2 = connect_quadrants(q1,p2,p3,p4)\n",
    "  elif (N==1):\n",
    "    ch1 = connect_quadrants(q1,p2,q3,q4)\n",
    "    ch2 = connect_quadrants(p1,q2,p3,p4)\n",
    "  elif (N==2):\n",
    "    ch1 = connect_quadrants(q1,q2,p3,q4)\n",
    "    ch2 = connect_quadrants(p1,p2,q3,p4)\n",
    "  else:\n",
    "    ch1 = connect_quadrants(q1,q2,q3,p4)\n",
    "    ch2 = connect_quadrants(p1,p2,p3,q4)\n",
    "\n",
    "  return ch1,ch2\n",
    "\n",
    "def connect_quadrants(q1,q2,q3,q4):\n",
    "  left = np.concatenate((q1,q3))\n",
    "  right = np.concatenate((q2,q4))\n",
    "  image = np.concatenate((left,right),axis=1)\n",
    "  return image.flatten()\n",
    "\n",
    "\n",
    "def multi_crossover(parent1,parent2,target):\n",
    "  pop= []\n",
    "  # 2-k crossover\n",
    "  pop.append(k_crossover(parent1, parent2))\n",
    "  # Gorge Clooney crossover\n",
    "  pop.append(quadrant_crossover(parent1,parent2))\n",
    "  # uniform crossover\n",
    "  pop.append(k_crossover(parent1, parent2,1))\n",
    "  # SSIM similarity \n",
    "  flattened_list = [y for x in pop for y in x] # need to flatten the list because pop is list of lists, cause every crossover function returns 2 obj\n",
    "  ssim = [computing_SSIM(ind,target) for ind in flattened_list ]\n",
    "  # taking the index of largest two score\n",
    "  id1=np.argmax(ssim)\n",
    "  ssim[id1]=0\n",
    "  id2 = np.argmax(ssim)\n",
    "  #returning parents\n",
    "  return flattened_list[id1],flattened_list[id2]\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J7Z_4b8EqUmj"
   },
   "outputs": [],
   "source": [
    "def return_best_individual(pop,fitness):\n",
    "  index = np.argmax(fitness)\n",
    "  best = pop[index]\n",
    "  return best, np.max(fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tcVTicSPvYoy"
   },
   "outputs": [],
   "source": [
    "def choose_better_child(ch1, ch2,ground_truth,label,model):\n",
    "  # I named it better child, but we choose by this parents as well\n",
    "  ch1_f = calculate_fitness(model,ch1.reshape(CIFAR_IMG,CIFAR_IMG),ground_truth.reshape(CIFAR_IMG,CIFAR_IMG),label)\n",
    "  ch2_f = calculate_fitness(model,ch2.reshape(CIFAR_IMG,CIFAR_IMG),ground_truth.reshape(CIFAR_IMG,CIFAR_IMG),label)\n",
    "  # change this into ternary operator\n",
    "  if ch1_f>ch2_f:\n",
    "    return ch1\n",
    "  else:\n",
    "    return ch2              \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UiXxgPDmriTE"
   },
   "source": [
    "# THE MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "T-8hS44GPb2B",
    "outputId": "3661aaab-b99a-4560-cacf-0335b114d94b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX = flatten(x_train)\\nX_t = flatten(x_test)\\nprint(f\"X train shape {X.shape}\")\\nprint(f\"X test shape {X_t.shape}\")\\nprint(f\"y train shape {y.shape}\")\\nprint(f\"y test shape {y_t.shape}\")\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This not necessary when using subset \n",
    "'''\n",
    "'''\n",
    "X = flatten(x_train)\n",
    "X_t = flatten(x_test)\n",
    "print(f\"X train shape {X.shape}\")\n",
    "print(f\"X test shape {X_t.shape}\")\n",
    "print(f\"y train shape {y.shape}\")\n",
    "print(f\"y test shape {y_t.shape}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "r99NLfBt-ngX",
    "outputId": "1dafbbc7-39cb-4cc7-b99f-ef47d32210bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial fitness: \n",
      " [-0.6006210911634455, -0.6033665414899362, -0.6000092788656581, -0.601905365322793, -0.6023987949459152, -0.6000117650669052, -0.6024779959503466, -0.6046547917537709, -0.6037307333614155, -0.6018327048650227, -0.6002572973396729, -0.6002903173907451, -0.60068366437832, -0.6006401269071266, -0.601300964043418, -0.6003358421658718, -0.6029363446411603, -0.601913841588911, -0.6004406922865849, -0.6007119537957029, -0.6011580784678078, -0.6005336588540756, -0.6017376098804634, -0.6027593639162852, -0.6040432220364483, -0.6018395693930101, -0.602305928487546, -0.6032444673638473, -0.6018614359417083, -0.6006953041160611, -0.6022465517467009, -0.6039030312803849, -0.6004588905657975, -0.6040282956050167, -0.6010398065958062, -0.6004793957997006, -0.6021921684021161, -0.6009060829571182, -0.603490547272519, -0.5999164444712171, -0.6017285575680191, -0.6013266442675094, -0.6008129890729035, -0.6016326870149112, -0.6009182339088968, -0.600529908070906, -0.6018194977819847, -0.6013998422839033, -0.6006149930895315, -0.6022747113769917]\n"
     ]
    }
   ],
   "source": [
    "# for each image and label in adversarial\n",
    "n=50\n",
    "import time\n",
    "# these are the examples that are found as adversarialwe will save these at the end in a file\n",
    "evolved_examples= []\n",
    "# fitness of the adversarials\n",
    "fitness_of_evolved=[]\n",
    "# time necessary to evolve the adversarial\n",
    "times=[]\n",
    "# the distance between the original image and the adversarial\n",
    "ssim_values=[]\n",
    "# number of round necessary to produce adversarial \n",
    "number_of_rounds=[]\n",
    "# this will serve to see if the fitness changes or not \n",
    "best_fitness = 0\n",
    "\n",
    "\n",
    "numb_of_found_after30=0\n",
    "numb_of_adv_found=0\n",
    "\n",
    "#dictionary to keep the best individual to check if the fitness is improving or not \n",
    "\n",
    "\n",
    "predicted_class= []\n",
    "for img,label in zip(adversarial,adversarial_y):\n",
    "  winner_of_gen = {\"image\":[],\"label\": None, \"fitness\": None}\n",
    "  #temporary variable to check generations:\n",
    "  fitness_no_change = 0\n",
    "  start = time.time()\n",
    "  label=label[0]\n",
    "  #intialize population from the image and with the given label\n",
    "  population = init_pop_from_sample(n,img,label)\n",
    "  # calculate fitness of these individuals\n",
    "  fitness = pop_fitness(model,np.expand_dims(population.reshape(population.shape[0],CIFAR_IMG,CIFAR_IMG),axis=3),img.reshape(CIFAR_IMG,CIFAR_IMG),label)\n",
    "  print(f\"Initial fitness: \\n {fitness}\")\n",
    "  #retun the best one from the population\n",
    "  best,fit_max = return_best_individual(population,fitness)\n",
    "  #check if adversarial\n",
    "  check_adv = check_adv_termination(best,label,img, model)\n",
    "  #define max generation\n",
    "  max_gen=0\n",
    "  winner_of_gen.update(image= best)\n",
    "  winner_of_gen.update(label= label)\n",
    "  winner_of_gen.update(fitness= fit_max)\n",
    "\n",
    "  while (len(check_adv)==0 or max_gen<10000):\n",
    "      new_pop=[]\n",
    "      for i in range(50):\n",
    "        parent1= tournament(population, model, img, label) \n",
    "        parent2 = tournament(population, model, img, label)\n",
    "        if 0.8 > np.random.uniform(0.0, 1.0):\n",
    "          child1, child2 = k_crossover(parent1, parent2) # crossover\n",
    "          new_pop.append(add_noise(choose_better_child(child1, child2,img,label,model)))\n",
    "        else:\n",
    "          new_pop.append(add_noise(choose_better_child(parent1, parent2,img,label,model)))\n",
    "\n",
    "      # to reshape into an array \n",
    "      population= np.array(new_pop)\n",
    "      #check fitness of the generation\n",
    "      fitness = pop_fitness(model,np.expand_dims(population.reshape(population.shape[0],CIFAR_IMG,CIFAR_IMG),axis=3),img.reshape(CIFAR_IMG,CIFAR_IMG),label) \n",
    "      #find the highest fitness\n",
    "      best,fit_max1 = return_best_individual(population,fitness)\n",
    "      # check adversarial - check if pred != target, distance < 0.001 or fitness didn't improve 0.001 after 30 generations(this is in else condition)\n",
    "      check_adv = check_adv_termination(best,label,img,model)\n",
    "\n",
    "      #check if the first termination true \n",
    "      if(len(check_adv) != 0):\n",
    "        print(\"Adversarial example image: \\n\")\n",
    "        evolved_examples.append(check_adv) #add evolved example\n",
    "        ssim_values.append(1-compare_ssim(check_adv.reshape(CIFAR_IMG,CIFAR_IMG),img.reshape(CIFAR_IMG,CIFAR_IMG))) #add the distance\n",
    "        end=time.time()\n",
    "        times.append(end-start) #add the time \n",
    "        fitness_of_evolved.append(calculate_fitness(model,check_adv,img,label)) #add the fitness value of adversarial\n",
    "        number_of_rounds.append(max_gen)\n",
    "        pred_l=np.argmax(model.predict(check_adv.reshape(1,CIFAR_IMG,CIFAR_IMG,1)/255.0))\n",
    "        predicted_class.append(pred_l)\n",
    "        print(\"Left: adversarial \\t Right: ground truth\")\n",
    "        fd, idx = plt.subplots(1,2)\n",
    "        idx[0].imshow(check_adv.reshape(CIFAR_IMG,CIFAR_IMG),cmap='gray')\n",
    "        idx[1].imshow(img.reshape(CIFAR_IMG,CIFAR_IMG),cmap='gray')\n",
    "        plt.show()\n",
    "        print(f\"True label: {label}\")\n",
    "        print(f\"predicted label: {pred_l}\") \n",
    "        print(\"Time: \",end-start ,\" seconds\")\n",
    "        numb_of_adv_found+=1\n",
    "        break\n",
    "      #check the second termination \n",
    "      else:\n",
    "          #check if fitness increases, if not , add +1 to temporary var\n",
    "        if fit_max1>fit_max:\n",
    "          fit_max=fit_max1\n",
    "          winner_of_gen.update(image= best)\n",
    "          winner_of_gen.update(label= label)\n",
    "          winner_of_gen.update(fitness= fit_max1)\n",
    "          fitness_no_change=0\n",
    "        else:\n",
    "          fitness_no_change+=1\n",
    "      \n",
    "      #print after every 10 generations to see the progress\n",
    "      if (max_gen % 10 == 0):\n",
    "        print(f\"Generation {max_gen}\")\n",
    "        print(f\"Max fitness value {fit_max}\")\n",
    "      max_gen+=1\n",
    "\n",
    "      # if fitness did not improve for 30 generations, save the image that was best , saved it in a dicitonary\n",
    "      if fitness_no_change==30:\n",
    "        print(\"FITNESS DID NOT IMPROVE FOR 30 GENERATIONS\")\n",
    "        print(\"Best adversarial image we could find: \\n\")\n",
    "        evolved_examples.append(winner_of_gen[\"image\"])\n",
    "        ssim_values.append(1-compare_ssim(np.array(winner_of_gen[\"image\"]).reshape(CIFAR_IMG,CIFAR_IMG),img.reshape(CIFAR_IMG,CIFAR_IMG)))\n",
    "        number_of_rounds.append(max_gen)\n",
    "        end=time.time()\n",
    "        times.append(end-start)\n",
    "        fitness_of_evolved.append(winner_of_gen[\"fitness\"])\n",
    "        pred_l=np.argmax(model.predict(np.array(winner_of_gen[\"image\"]).reshape(1,CIFAR_IMG,CIFAR_IMG,1)/255.0))\n",
    "        predicted_class.append(pred_l)\n",
    "        print(\"Left: adversarial \\t Right: ground truth\")\n",
    "        fd, idx = plt.subplots(1,2)\n",
    "        idx[0].imshow(np.array(winner_of_gen[\"image\"]).reshape(CIFAR_IMG,CIFAR_IMG),cmap='gray')\n",
    "        idx[1].imshow(img.reshape(CIFAR_IMG,CIFAR_IMG),cmap='gray')\n",
    "        plt.show()\n",
    "        print(f\"True label: {label}\")\n",
    "        print(f\"predicted label: {pred_l}\")\n",
    "        print(\"Time: \",end-start ,\" seconds\")\n",
    "        numb_of_found_after30 +=1\n",
    "        break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XEMXgasB3Llv"
   },
   "source": [
    "# Save files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "u43v4fe33RGZ",
    "outputId": "5118cd4e-ecb9-4967-c242-6b95df84ceb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max time: 689.0073523521423\n",
      "Min time: 1.920302391052246\n",
      "Mean time: 192.19042799347326\n",
      "Std time: 119.84222304055714\n",
      "\n",
      "Max fitness evolved: 0.9988023444329798\n",
      "Min fitness evolved:: -0.6013678319995003\n",
      "Mean fitness evolved: 0.8901382661300241\n",
      "Std fitness evolved:: 0.37869671290260337\n",
      "\n",
      "Max ssim: 0.33835804611293985\n",
      "Min ssim: 4.730621262938328e-06\n",
      "Mean ssim: 0.04467366696985318\n",
      "Std ssim: 0.04788750218727948\n",
      "\n",
      "Max round: 339\n",
      "Min rounds: 0\n",
      "Mean rounds: 97.73684210526316\n",
      "Std rounds: 60.55642925290664\n",
      "\n",
      "Percentage of adversarial founds sucessfully : 0.022556390977443608 %\n",
      "Percentage of adversarial founds after fitness not improving for 30 generations: 0.9774436090225563 %\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "file_ = open('GA_adv_cifar_ssim_uniform', 'wb')\n",
    "pickle.dump(evolved_examples, file_)\n",
    "pickle.dump(times, file_)\n",
    "pickle.dump(ssim_values, file_)\n",
    "pickle.dump(fitness_of_evolved , file_)\n",
    "pickle.dump(predicted_class, file_)\n",
    "pickle.dump(number_of_rounds, file_)\n",
    "file_.close()\n",
    "\n",
    "print(f\"Max time: {np.max(times)}\")\n",
    "print(f\"Min time: {np.min(times)}\")\n",
    "print(f\"Mean time: {np.mean(times)}\")\n",
    "print(f\"Std time: {np.std(times)}\\n\")\n",
    "\n",
    "print(f\"Max fitness evolved: {np.max(fitness_of_evolved)}\")\n",
    "print(f\"Min fitness evolved:: {np.min(fitness_of_evolved)}\")\n",
    "print(f\"Mean fitness evolved: {np.mean(fitness_of_evolved)}\")\n",
    "print(f\"Std fitness evolved:: {np.std(fitness_of_evolved)}\\n\")\n",
    "\n",
    "print(f\"Max ssim: {np.max(ssim_values)}\")\n",
    "print(f\"Min ssim: {np.min(ssim_values)}\")\n",
    "print(f\"Mean ssim: {np.mean(ssim_values)}\")\n",
    "print(f\"Std ssim: {np.std(ssim_values)}\\n\")\n",
    "\n",
    "print(f\"Max round: {np.max(number_of_rounds)}\")\n",
    "print(f\"Min rounds: {np.min(number_of_rounds)}\")\n",
    "print(f\"Mean rounds: {np.mean(number_of_rounds)}\")\n",
    "print(f\"Std rounds: {np.std(number_of_rounds)}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Percentage of adversarial founds sucessfully : {numb_of_adv_found/len(adversarial_y)} %\")\n",
    "print(f\"Percentage of adversarial founds after fitness not improving for 30 generations: {numb_of_found_after30/len(adversarial_y)} %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uQoHNMX_8nor"
   },
   "source": [
    "Open adversarial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rEK7GsD78oq5"
   },
   "outputs": [],
   "source": [
    "with open('./results/GA_adv_cifar_ssim_Kcrossover', 'rb') as f:\n",
    "    evolved_examples = pickle.load(f)\n",
    "    times= pickle.load(f)\n",
    "    ssim_values = pickle.load(f)\n",
    "    fitness_of_evolved = pickle.load(f)\n",
    "    predicted_class = pickle.load(f)\n",
    "    number_of_rounds = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max ssim: 0.9999719092126748\n",
      "Min ssim: 0.6997527243063725\n",
      "Mean ssim: 0.9594270743027448\n",
      "Std ssim: 0.04437958341615912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Correction of ssim values\n",
    "new_ssim=[]\n",
    "for s in ssim_values:\n",
    "    new_ssim.append(1-s)\n",
    "    \n",
    "print(f\"Max ssim: {np.max(new_ssim)}\")\n",
    "print(f\"Min ssim: {np.min(new_ssim)}\")\n",
    "print(f\"Mean ssim: {np.mean(new_ssim)}\")\n",
    "print(f\"Std ssim: {np.std(new_ssim)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 96,  67,  48, 155, 134,  47, 171, 254, 115,  43,  65,  50,  68,\n",
       "       158,  66,  30,  68,  45,  95, 183,  55,  31,  63,  30,  30, 219,\n",
       "        44,  50,  70, 157,  43,  56,  62, 153, 158,  50,  30,  30, 157,\n",
       "        37,  57,  72, 117,  71,  79,  77,  53,  64,  65, 182,  59,  59,\n",
       "       113,   1,  72,  89,  39,  47,  53,  35,  78, 105,  52,  98,  58,\n",
       "        53,  46,  88,  66, 183,  54,  74,  96,  57, 166, 120, 105, 230,\n",
       "       110,  52,  30,  76,  47, 232,  94, 128, 170,  77, 174, 105, 283,\n",
       "        69, 109, 142,  49, 150,  80,  85,  87,  52,  55,  51, 102,  84,\n",
       "       120,  73, 161, 127,  64, 147, 170, 166,  51, 126,  58,  63,  30,\n",
       "        94,  49, 124, 141,  98,  56,  79,  30, 260, 165, 129, 104,   1,\n",
       "        58, 173,  73])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Correctionf of rounds  (replacing 0 with 1)\n",
    "number_of_rounds = np.where(np.array(number_of_rounds)==0, 1, number_of_rounds) \n",
    "number_of_rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max round: 283\n",
      "Min rounds: 1\n",
      "Mean rounds: 92.47368421052632\n",
      "Std rounds: 54.939690645571574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Max round: {np.max(number_of_rounds)}\")\n",
    "print(f\"Min rounds: {np.min(number_of_rounds)}\")\n",
    "print(f\"Mean rounds: {np.mean(number_of_rounds)}\")\n",
    "print(f\"Std rounds: {np.std(number_of_rounds)}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0e9R7ACErtqK"
   },
   "source": [
    "# Examples of what functions do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cpEVAzR7rtK8"
   },
   "outputs": [],
   "source": [
    "population = init_pop_from_sample(50,adversarial[15],adversarial_y[15][0])\n",
    "fitness = pop_fitness(model,np.expand_dims(population.reshape(population.shape[0],CIFAR_IMG,CIFAR_IMG),axis=3),img.reshape(CIFAR_IMG,CIFAR_IMG),adversarial_y[15][0])\n",
    "print(fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "colab_type": "code",
    "id": "0aYxCQLEu1BB",
    "outputId": "6a29e5dc-27d0-4479-81b7-6e1288329285"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class for this 1\n",
      "[[2.2063480e-10 1.0000000e+00 6.6041472e-14 3.5760719e-12 3.9276270e-13\n",
      "  1.1313486e-13 8.8119643e-13 6.8588521e-13 1.9681285e-13 3.7839783e-08]]\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(population[0].reshape(CIFAR_IMG,CIFAR_IMG))\n",
    "plt.show()\n",
    "print(f\"Class for this {adversarial_y[15][0]}\")\n",
    "print(model.predict(population[0].reshape(1,CIFAR_IMG,CIFAR_IMG,1) /255.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "xhxCaFZPGPpe",
    "outputId": "35163672-1426-46f3-d021-b87dc280c722"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python3.6/dist-packages/skimage/measure/_structural_similarity.py:17: UserWarning: Inputs have mismatched dtype.  Setting data_range based on im1.dtype.\n",
      "  **kwargs)\n"
     ]
    }
   ],
   "source": [
    "parent1 = tournament(population, model, adversarial[15], adversarial_y[15]) \n",
    "parent2 = tournament(population, model, adversarial[15], adversarial_y[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "colab_type": "code",
    "id": "gORkePYLv4EW",
    "outputId": "17422d1a-b936-43f2-a2c2-33f4cb500bf4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8f5ea68dd8>"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fd, idx =  plt.subplots(1,2)\n",
    "idx[0].imshow(parent1.reshape(CIFAR_IMG,CIFAR_IMG),cmap=\"gray\")\n",
    "idx[1].imshow(parent2.reshape(CIFAR_IMG,CIFAR_IMG),cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "HZJXShUyHIrS",
    "outputId": "c26ae352-d1a1-4510-9da7-ae5e01d1ec43"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python3.6/dist-packages/skimage/measure/_structural_similarity.py:17: UserWarning: Inputs have mismatched dtype.  Setting data_range based on im1.dtype.\n",
      "  **kwargs)\n"
     ]
    }
   ],
   "source": [
    "child1, child2 = multi_crossover(parent1, parent2,adversarial[15]) # crossover \n",
    "#child1, child2 = add_noise(child1), add_noise(child2) # apply mutation to pixels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "colab_type": "code",
    "id": "72tQ7R_RHZzZ",
    "outputId": "c81cdb63-ed10-42c2-d477-894c5e91bcf7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8f5e585550>"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fd, idx =  plt.subplots(1,2)\n",
    "idx[0].imshow(child1.reshape(CIFAR_IMG,CIFAR_IMG),cmap=\"gray\")\n",
    "idx[1].imshow(child2.reshape(CIFAR_IMG,CIFAR_IMG),cmap=\"gray\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4a3pXLQSwZlT"
   },
   "outputs": [],
   "source": [
    "print(f\"diff between children {np.unique(child1-child2)}\")\n",
    "print(f\"diff between parents {np.unique(parent1-parent2)}\")\n",
    "print(f\"diff between p1 and c1 {np.unique(parent1-child1)}\")\n",
    "print(f\"diff between p1 and c2 {np.unique(parent1-child2)}\")\n",
    "print(f\"diff between p2 and c1 {np.unique(parent2-child1)}\")\n",
    "print(f\"diff between p2 and c2 {np.unique(parent2-child2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "xEPQapUpILBr",
    "outputId": "ac694765-e044-4f9f-82ee-9c599a2eb431"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python3.6/dist-packages/skimage/measure/_structural_similarity.py:17: UserWarning: Inputs have mismatched dtype.  Setting data_range based on im1.dtype.\n",
      "  **kwargs)\n"
     ]
    }
   ],
   "source": [
    "bb = choose_better_child(child1, child2,adversarial[15],adversarial_y[15][0],model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "UCl4mvK99XYj",
    "outputId": "fd9867bc-0c0a-486e-c393-ad74b8ef6298"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python3.6/dist-packages/skimage/measure/_structural_similarity.py:17: UserWarning: Inputs have mismatched dtype.  Setting data_range based on im1.dtype.\n",
      "  **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.26002962878595726, -0.25999958545736684, -0.26007314251448344, -0.26004007622401076, -0.26003266487525345, -0.26011373574731095, -0.2599816460817825, -0.25998496480763594, -0.2600353571926644, -0.2600021864303609, -0.260040721413234, -0.2600228430135187, -0.26003768485830203, -0.26002701209750284, -0.26006302743228543, -0.2599796432991168, -0.2600043346069123, -0.26003024147792836, -0.2600466627237271, -0.26003812318804226, -0.2600652442884724, -0.2600447098702882, -0.2600085762943468, -0.26001327339828323, -0.2599806557454484, -0.26007237070197037, -0.25996000471207786, -0.2600457997287944, -0.2600101441535663, -0.26005323947618036, -0.2600554130353725, -0.2600860828123626, -0.26003997918862914, -0.26004537198733424, -0.2600515291553301, -0.2600503663988854, -0.26001231736237695, -0.2600170667581806, -0.2600851316879575, -0.2599960477747653, -0.260017809873727, -0.2600171997460062, -0.2600455137861651, -0.26001145913341955, -0.2600466317811507, -0.2600557191632309, -0.26006128108305554, -0.2599700462660023, -0.26005349311420517, -0.2600591984831575]\n"
     ]
    }
   ],
   "source": [
    "fitness = pop_fitness(model,np.expand_dims(population.reshape(population.shape[0],CIFAR_IMG,CIFAR_IMG),axis=3),img.reshape(CIFAR_IMG,CIFAR_IMG),label) \n",
    "print(fitness)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GA_CIFAR_SSIM_k_crossover.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
