{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GA_CIFAR_SSIM_k_crossover.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmqP9iw8qi2w",
        "colab_type": "text"
      },
      "source": [
        "# IMPORT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4o2nRW3uHkP",
        "colab_type": "text"
      },
      "source": [
        "In this notebook I did not normalized images before evolving, just when predicting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV-6sDntqd61",
        "colab_type": "code",
        "outputId": "0cbc2ce7-49b2-4fbc-ebea-609b58207590",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.svm import SVC\n",
        "import pickle\n",
        "import time\n",
        "from skimage.measure import compare_ssim\n",
        "import tensorflow as tf\n",
        "from keras.models import Model,load_model\n",
        "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, Input, Activation\n",
        "from keras.utils import to_categorical\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGtAwbEMqmmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMYv1iroqpKy",
        "colab_type": "text"
      },
      "source": [
        "# GLOBAL VARS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JLxcgMPqoDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INDIVIDUALS = 50\n",
        "P_CROSS = 0.6\n",
        "P_MUTATION = 0.01\n",
        "CIFAR_IMG= 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhUutenzqt18",
        "colab_type": "text"
      },
      "source": [
        "# THE DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZTtcGJAJLuM",
        "colab_type": "code",
        "outputId": "2cbc5552-7adf-47f3-eb0c-3c949c60c25c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "# The data, split between train and test sets:\n",
        "(x_train_C, y_train_C), (x_test_C, y_test_C) = cifar10.load_data()\n",
        "print('x_train shape:', x_train_C.shape)\n",
        "print(x_train_C.shape[0], 'train samples')\n",
        "print(x_test_C.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "num_classes=10\n",
        "epochs=10\n",
        "img_shape=32 \n",
        "y_train_C = to_categorical(y_train_C, num_classes)\n",
        "y_test_C = to_categorical(y_test_C, num_classes)\n",
        "\n",
        "\n",
        "input_shape=(32,32,1)\n",
        "\n",
        "x_train_C = x_train_C.astype('float32')\n",
        "x_test_C = x_test_C.astype('float32')\n",
        "x_train_C /= 255\n",
        "x_test_C /= 255\n",
        "\n",
        "\n",
        "print('x_train shape:', x_train_C.shape)\n",
        "print('Number of images in x_train', x_train_C.shape[0])\n",
        "print('Number of images in x_test', x_test_C.shape[0])\n",
        "print('y_train shape:', y_train_C.shape)\n",
        "print(\"input shape: \",input_shape)\n",
        "\n",
        "\n",
        "# CONVERT TO GRAY SCALE\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def grayscale(data, dtype='float32'):\n",
        "    # luma coding weighted average in video systems\n",
        "    r, g, b = np.asarray(.3, dtype=dtype), np.asarray(.59, dtype=dtype), np.asarray(.11, dtype=dtype)\n",
        "    rst = r * data[:, :, :, 0] + g * data[:, :, :, 1] + b * data[:, :, :, 2]\n",
        "    # add channel dimension\n",
        "    rst = np.expand_dims(rst, axis=3)\n",
        "    return rst\n",
        "\n",
        "x_train_C = grayscale(x_train_C)\n",
        "x_test_C = grayscale(x_test_C)\n",
        "\n",
        "# now we have only one channel in the images\n",
        "img_channels = 1\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "Number of images in x_train 50000\n",
            "Number of images in x_test 10000\n",
            "y_train shape: (50000, 10)\n",
            "input shape:  (32, 32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_--StA9kq4mw",
        "colab_type": "text"
      },
      "source": [
        "# READ PICKLE FILES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3glGbBeq2lz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('subset_cifar', 'rb') as f:\n",
        "    original = pickle.load(f)\n",
        "    adversarial= pickle.load(f)\n",
        "    original_y = pickle.load(f)\n",
        "    adversarial_y = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1LZoAPNq996",
        "colab_type": "code",
        "outputId": "02f5a576-8da4-4b94-ebee-630982d4884b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(f\"Original shape {original.shape}\")\n",
        "print(f\"Adversarial shape {adversarial.shape}\")\n",
        "print(f\"Original labels shape {original_y.shape}\")\n",
        "print(f\"Adversarial labels shape {adversarial_y.shape}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original shape (914, 32, 32, 1)\n",
            "Adversarial shape (133, 32, 32, 1)\n",
            "Original labels shape (914, 1)\n",
            "Adversarial labels shape (133, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr0TMOV_q_9J",
        "colab_type": "text"
      },
      "source": [
        "# LOAD THE MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JibFPCmerJwW",
        "colab_type": "text"
      },
      "source": [
        "3. CNN v2\n",
        "\n",
        "This network is made for CIFAR 10. The network is taken from [this blog]( https://appliedmachinelearning.blog/2018/03/24/achieving-90-accuracy-in-object-recognition-task-on-cifar-10-dataset-with-keras-convolutional-neural-networks/) . In this version below I didn't use some things used in the blog e.g. z-score and data augmentation.\n",
        "\n",
        "\n",
        "This network has training accuracy: 0.8940 , validation accuracy: 0.8245.\n",
        "\n",
        "**NOTE:** Training really slow, try to avoid it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjDjKgyWJwqY",
        "colab_type": "code",
        "outputId": "12e3326d-926a-4871-80ff-dc618756132c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Network 3 \n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.datasets import cifar10\n",
        "from keras import regularizers\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "import numpy as np\n",
        "\n",
        "input_shape = (CIFAR_IMG,CIFAR_IMG,1)\n",
        "weight_decay = 1e-4\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=input_shape))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        " \n",
        "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        " \n",
        "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        " \n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='softmax'))\n",
        " \n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "'''\n",
        "history = model.fit(x=x_train_C,y=y_train_C, epochs=150, batch_size=64, validation_data=[x_test_C,y_test_C])\n",
        "\n",
        "score= model.evaluate(x_test_C, y_test_C,verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "model.save_weights(\"CNN_CIFAR10_net3.h5\")\n",
        "files.download('CNN_CIFAR10_net3.h5')\n",
        "'''\n",
        "\n",
        "model = load_model(\"CNN_CIFAR10_net3.h5\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        320       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 308,714\n",
            "Trainable params: 307,818\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGSQOJJprRG-",
        "colab_type": "text"
      },
      "source": [
        "# GENETIC ALGORITHM FUNCTIONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQuqZrKL4qqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def computing_SSIM(individual,target):\n",
        "    return compare_ssim(individual.reshape(CIFAR_IMG,CIFAR_IMG), target.reshape(CIFAR_IMG,CIFAR_IMG))\n",
        "\n",
        "def calculate_fitness(model,ind,target_image,label,l1=0.2, l2=0.8, N=50, num_classes=10):\n",
        "  # predict the population\n",
        "  predictions=model.predict(ind.reshape(1,CIFAR_IMG,CIFAR_IMG,1) / 255.0)  \n",
        "  # po is the ground truth prediction, so for label = 0, it will be prediciton[0]\n",
        "  predictions=predictions[0]\n",
        "  po=predictions[label]\n",
        "  # set that value to 0\n",
        "  predictions[label]=0\n",
        "  # take next highest one\n",
        "  pd = np.max(predictions)\n",
        "  diff=pd-po\n",
        "  return l1*computing_SSIM(ind.reshape(CIFAR_IMG,CIFAR_IMG),target_image.reshape(CIFAR_IMG,CIFAR_IMG)) +l2*(diff)\n",
        "  \n",
        "\n",
        "\n",
        "def pop_fitness(model,pop,target,label):\n",
        "    return [calculate_fitness(model, p, target, label) for p in pop]\n",
        "\n",
        "def flatten(imgs):\n",
        "    # flatten all images in np array or list\n",
        "    return np.array([im.flatten() for im in imgs])\n",
        "\n",
        "def gaussian_noise():\n",
        "    # draw one sample of noise from zero mean 1 variance Gaussian\n",
        "    return np.random.normal(0, 10)\n",
        "\n",
        "def p_noise(x):\n",
        "  if 0.01 > np.random.uniform():\n",
        "    return x + gaussian_noise()\n",
        "  else:\n",
        "    return x\n",
        "    \n",
        "def add_noise(image):\n",
        "    noise_v=np.vectorize(p_noise)\n",
        "    return noise_v(image) #np.array([x + gaussian_noise() if P_MUTATION > np.random.uniform(0.0, 1.0) else x+0 for x in image])\n",
        "\n",
        "def k_crossover(im1, im2, k=2):\n",
        "    c1, c2 = [], []\n",
        "    # get k crossover points\n",
        "    points = sorted([np.random.randint(0, CIFAR_IMG*CIFAR_IMG-1, 1) for p in range(k)])\n",
        "    points = sorted([np.random.randint(0,CIFAR_IMG*CIFAR_IMG-1,1) for p in range(k)])\n",
        "    im_1_split = np.split(im1, [int(p) for p in points])\n",
        "    im_2_split = np.split(im2, [int(p) for p in points])\n",
        "    \n",
        "    # alternate between lists to realise crossover (theres got to be a more clever way to do this)\n",
        "    for i in range(k+1):\n",
        "        if i % 2 == 0:\n",
        "            c1.append(im_1_split[i])\n",
        "            c2.append(im_2_split[i])\n",
        "        else:\n",
        "            c1.append(im_2_split[i])\n",
        "            c2.append(im_1_split[i])\n",
        "    return np.concatenate(c1, axis=0), np.concatenate(c2, axis=0)\n",
        "\n",
        "def tournament(pop, model, ground_truth, target, k=3):\n",
        "\n",
        "    indices = np.random.choice(range(len(pop)), k, replace=False) #we get 3 indxes [2 34 46]    \n",
        "    individuals = pop.take(indices,axis=0)\n",
        "    scores = pop_fitness(model,np.expand_dims(individuals.reshape(individuals.shape[0],CIFAR_IMG,CIFAR_IMG),axis=3), ground_truth.reshape(CIFAR_IMG,CIFAR_IMG), target)\n",
        "    index_max = np.argmax(scores)\n",
        "    winner = individuals[index_max]\n",
        "    return winner\n",
        "\n",
        "\n",
        "def check_adv_termination(ind, label,ground_truth, model):\n",
        "  # individual - the best one from the generation\n",
        "  # label - class we want\n",
        "  # ground_truth - the image (32,32)\n",
        "  # model we are using \n",
        "  dist = 1-compare_ssim(ind.reshape(CIFAR_IMG,CIFAR_IMG),ground_truth.reshape(CIFAR_IMG,CIFAR_IMG))\n",
        "  predictions= model.predict(ind.reshape(1,CIFAR_IMG,CIFAR_IMG,1)/255.0)\n",
        "  predicted_label= np.argmax(predictions[0])\n",
        "  if label != predicted_label and dist < 0.001:\n",
        "    print(\"FOUND ADVERSARIAL\")\n",
        "    print(f\"Fitness of the adversarial {calculate_fitness(model,ind,ground_truth,label)}\")\n",
        "    return ind\n",
        "  return []\n",
        "\n",
        "def init_pop_from_sample(n,img,label):\n",
        "    x = np.array([add_noise(img) for i in range(n)])\n",
        "    return x.reshape(n, CIFAR_IMG*CIFAR_IMG)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-epJQRlguXyK",
        "colab_type": "text"
      },
      "source": [
        "Functions from the past, just didn't want to erase them yet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlm5dKzOuXNw",
        "colab_type": "code",
        "outputId": "00d4613d-f533-4e7a-cce0-cd5ad53ee562",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''\n",
        "def check_adverserial(pop, model, fitness, target,ground_truth):\n",
        "    #print(f\"this is adversarial function\")\n",
        "    preds=model.predict(pop.reshape(pop.shape[0],28,28,1))\n",
        "    #print(f\"These are predictions made here {preds}\")\n",
        "    for ind, pr in zip(pop,preds): \n",
        "      #print(f\"prediction for an individual {pr}\")\n",
        "      preds=np.argmax(pr)\n",
        "      #print(f\"getting the index of highest value in predictions {preds}\")\n",
        "      #setting the value to 0\n",
        "      pr[0]=0\n",
        "      #print(f\"this is our target {target}\")\n",
        "      #print(f\"this is out ground_truth {ground_truth.shape}\")\n",
        "      fitness=computing_SSIM(ind.reshape(28,28),ground_truth.reshape(28,28))\n",
        "      #print(f\"these are the fitness values {fitness}\")\n",
        "      next_highest = np.argmax(pr)\n",
        "      #print(f\"getting the next highest value {next_highest}\")\n",
        "      if next_highest != target and fitness > 0.98:\n",
        "          return ind, True\n",
        "      return None, False\n",
        "\n",
        "def init_pop(n, num, data, labels):\n",
        "    indices = np.where(labels==num)[0]\n",
        "    n_indices = np.random.choice(indices, n, replace=True)\n",
        "    sample = np.take(data, n_indices, axis=0)\n",
        "    return sample, np.full((n), num, dtype=int) # return sample+array of labels\n",
        "\n",
        "\n",
        "Cyrils model\n",
        "\n",
        "def save_trained_model(model, filename='SVC_model.sav'):\n",
        "    pickle.dump(model, open(filename, 'wb'))\n",
        "    \n",
        "def load_trained_model(filename='SVC_model.sav'):\n",
        "    return pickle.load(open(filename, 'rb'))\n",
        "\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef check_adverserial(pop, model, fitness, target,ground_truth):\\n    #print(f\"this is adversarial function\")\\n    preds=model.predict(pop.reshape(pop.shape[0],28,28,1))\\n    #print(f\"These are predictions made here {preds}\")\\n    for ind, pr in zip(pop,preds): \\n      #print(f\"prediction for an individual {pr}\")\\n      preds=np.argmax(pr)\\n      #print(f\"getting the index of highest value in predictions {preds}\")\\n      #setting the value to 0\\n      pr[0]=0\\n      #print(f\"this is our target {target}\")\\n      #print(f\"this is out ground_truth {ground_truth.shape}\")\\n      fitness=computing_SSIM(ind.reshape(28,28),ground_truth.reshape(28,28))\\n      #print(f\"these are the fitness values {fitness}\")\\n      next_highest = np.argmax(pr)\\n      #print(f\"getting the next highest value {next_highest}\")\\n      if next_highest != target and fitness > 0.98:\\n          return ind, True\\n      return None, False\\n\\ndef init_pop(n, num, data, labels):\\n    indices = np.where(labels==num)[0]\\n    n_indices = np.random.choice(indices, n, replace=True)\\n    sample = np.take(data, n_indices, axis=0)\\n    return sample, np.full((n), num, dtype=int) # return sample+array of labels\\n\\n\\nCyrils model\\n\\ndef save_trained_model(model, filename=\\'SVC_model.sav\\'):\\n    pickle.dump(model, open(filename, \\'wb\\'))\\n    \\ndef load_trained_model(filename=\\'SVC_model.sav\\'):\\n    return pickle.load(open(filename, \\'rb\\'))\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOEo4wAfggNs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' my part of the code ''' \n",
        "''' I know it is ugly, I will fix it . this is the intial version'''\n",
        "# from Goorge Clooney paper\n",
        "def quadrant_crossover(parent_1,parent_2):\n",
        "\n",
        "  # reshape parents\n",
        "  parent_1,parent_2= parent_1.reshape((CIFAR_IMG,CIFAR_IMG)), parent_2.reshape((CIFAR_IMG,CIFAR_IMG))\n",
        "  # quadrants for both parents\n",
        "  p1,p2,p3,p4,q1,q2,q3,q4 = [],[],[],[],[],[],[],[]\n",
        "  child1, child2 = [],[]\n",
        "  # getting random (x,y) point in 2D matrix\n",
        "  x,y = np.random.randint(0,CIFAR_IMG-1), np.random.randint(0,CIFAR_IMG-1)  \n",
        "\n",
        "  # choose which quadrant we want to crossover\n",
        "  N = np.random.randint(0,3)\n",
        "  #make quadrants\n",
        "  for i in range(CIFAR_IMG):\n",
        "    if (i<=x):\n",
        "      p1.append(parent_1[i][:y+1])\n",
        "      p2.append(parent_1[i][y+1:])\n",
        "      q1.append(parent_2[i][:y+1])\n",
        "      q2.append(parent_2[i][y+1:])\n",
        "    else:\n",
        "      p3.append(parent_1[i][:y+1])\n",
        "      p4.append(parent_1[i][y+1:])\n",
        "      q3.append(parent_2[i][:y+1])\n",
        "      q4.append(parent_2[i][y+1:])\n",
        "\n",
        "  if (N==0):\n",
        "    ch1 = connect_quadrants(p1,q2,q3,q4)\n",
        "    ch2 = connect_quadrants(q1,p2,p3,p4)\n",
        "  elif (N==1):\n",
        "    ch1 = connect_quadrants(q1,p2,q3,q4)\n",
        "    ch2 = connect_quadrants(p1,q2,p3,p4)\n",
        "  elif (N==2):\n",
        "    ch1 = connect_quadrants(q1,q2,p3,q4)\n",
        "    ch2 = connect_quadrants(p1,p2,q3,p4)\n",
        "  else:\n",
        "    ch1 = connect_quadrants(q1,q2,q3,p4)\n",
        "    ch2 = connect_quadrants(p1,p2,p3,q4)\n",
        "\n",
        "  return ch1,ch2\n",
        "\n",
        "def connect_quadrants(q1,q2,q3,q4):\n",
        "  left = np.concatenate((q1,q3))\n",
        "  right = np.concatenate((q2,q4))\n",
        "  image = np.concatenate((left,right),axis=1)\n",
        "  return image.flatten()\n",
        "\n",
        "\n",
        "def multi_crossover(parent1,parent2,target):\n",
        "  pop= []\n",
        "  # 2-k crossover\n",
        "  pop.append(k_crossover(parent1, parent2))\n",
        "  # Gorge Clooney crossover\n",
        "  pop.append(quadrant_crossover(parent1,parent2))\n",
        "  # uniform crossover\n",
        "  pop.append(k_crossover(parent1, parent2,1))\n",
        "  # SSIM similarity \n",
        "  flattened_list = [y for x in pop for y in x] # need to flatten the list because pop is list of lists, cause every crossover function returns 2 obj\n",
        "  ssim = [computing_SSIM(ind,target) for ind in flattened_list ]\n",
        "  # taking the index of largest two score\n",
        "  id1=np.argmax(ssim)\n",
        "  ssim[id1]=0\n",
        "  id2 = np.argmax(ssim)\n",
        "  #returning parents\n",
        "  return flattened_list[id1],flattened_list[id2]\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7Z_4b8EqUmj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def return_best_individual(pop,fitness):\n",
        "  index = np.argmax(fitness)\n",
        "  best = pop[index]\n",
        "  return best, np.max(fitness)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcVTicSPvYoy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def choose_better_child(ch1, ch2,ground_truth,label,model):\n",
        "  # I named it better child, but we choose by this parents as well\n",
        "  ch1_f = calculate_fitness(model,ch1.reshape(CIFAR_IMG,CIFAR_IMG),ground_truth.reshape(CIFAR_IMG,CIFAR_IMG),label)\n",
        "  ch2_f = calculate_fitness(model,ch2.reshape(CIFAR_IMG,CIFAR_IMG),ground_truth.reshape(CIFAR_IMG,CIFAR_IMG),label)\n",
        "  # change this into ternary operator\n",
        "  if ch1_f>ch2_f:\n",
        "    return ch1\n",
        "  else:\n",
        "    return ch2              \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiXxgPDmriTE",
        "colab_type": "text"
      },
      "source": [
        "# THE MAIN LOOP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-8hS44GPb2B",
        "colab_type": "code",
        "outputId": "3661aaab-b99a-4560-cacf-0335b114d94b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "'''\n",
        "This not necessary when using subset \n",
        "'''\n",
        "'''\n",
        "X = flatten(x_train)\n",
        "X_t = flatten(x_test)\n",
        "print(f\"X train shape {X.shape}\")\n",
        "print(f\"X test shape {X_t.shape}\")\n",
        "print(f\"y train shape {y.shape}\")\n",
        "print(f\"y test shape {y_t.shape}\")\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nX = flatten(x_train)\\nX_t = flatten(x_test)\\nprint(f\"X train shape {X.shape}\")\\nprint(f\"X test shape {X_t.shape}\")\\nprint(f\"y train shape {y.shape}\")\\nprint(f\"y test shape {y_t.shape}\")\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r99NLfBt-ngX",
        "colab_type": "code",
        "outputId": "937849c3-3141-400c-9217-dfb12ba2ba2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        }
      },
      "source": [
        "# for each image and label in adversarial\n",
        "n=50\n",
        "import time\n",
        "# these are the examples that are found as adversarialwe will save these at the end in a file\n",
        "evolved_examples= []\n",
        "# fitness of the adversarials\n",
        "fitness_of_evolved=[]\n",
        "# time necessary to evolve the adversarial\n",
        "times=[]\n",
        "# the distance between the original image and the adversarial\n",
        "ssim_values=[]\n",
        "# number of round necessary to produce adversarial \n",
        "number_of_rounds=[]\n",
        "# this will serve to see if the fitness changes or not \n",
        "best_fitness = 0\n",
        "\n",
        "\n",
        "numb_of_found_after30=0\n",
        "numb_of_adv_found=0\n",
        "\n",
        "#dictionary to keep the best individual to check if the fitness is improving or not \n",
        "\n",
        "\n",
        "predicted_class= []\n",
        "for img,label in zip(adversarial,adversarial_y):\n",
        "  winner_of_gen = {\"image\":[],\"label\": None, \"fitness\": None}\n",
        "  #temporary variable to check generations:\n",
        "  fitness_no_change = 0\n",
        "  start = time.time()\n",
        "  label=label[0]\n",
        "  #intialize population from the image and with the given label\n",
        "  population = init_pop_from_sample(n,img,label)\n",
        "  # calculate fitness of these individuals\n",
        "  fitness = pop_fitness(model,np.expand_dims(population.reshape(population.shape[0],CIFAR_IMG,CIFAR_IMG),axis=3),img.reshape(CIFAR_IMG,CIFAR_IMG),label)\n",
        "  print(f\"Initial fitness: \\n {fitness}\")\n",
        "  #retun the best one from the population\n",
        "  best,fit_max = return_best_individual(population,fitness)\n",
        "  #check if adversarial\n",
        "  check_adv = check_adv_termination(best,label,img, model)\n",
        "  #define max generation\n",
        "  max_gen=0\n",
        "      \n",
        "  while (len(check_adv)==0 or max_gen<10000):\n",
        "      new_pop=[]\n",
        "      for i in range(50):\n",
        "        parent1= tournament(population, model, img, label) \n",
        "        parent2 = tournament(population, model, img, label)\n",
        "        if 0.8 > np.random.uniform(0.0, 1.0):\n",
        "          child1, child2 = k_crossover(parent1, parent2) # crossover\n",
        "          new_pop.append(add_noise(choose_better_child(child1, child2,img,label,model)))\n",
        "        else:\n",
        "          new_pop.append(add_noise(choose_better_child(parent1, parent2,img,label,model)))\n",
        "\n",
        "      # to reshape into an array \n",
        "      population= np.array(new_pop)\n",
        "      #check fitness of the generation\n",
        "      fitness = pop_fitness(model,np.expand_dims(population.reshape(population.shape[0],CIFAR_IMG,CIFAR_IMG),axis=3),img.reshape(CIFAR_IMG,CIFAR_IMG),label) \n",
        "      #find the highest fitness\n",
        "      best,fit_max1 = return_best_individual(population,fitness)\n",
        "      # check adversarial - check if pred != target, distance < 0.001 or fitness didn't improve 0.001 after 30 generations(this is in else condition)\n",
        "      check_adv = check_adv_termination(best,label,img,model)\n",
        "\n",
        "      #check if the first termination true \n",
        "      if(len(check_adv) != 0):\n",
        "        print(\"Adversarial example image: \\n\")\n",
        "        evolved_examples.append(check_adv) #add evolved example\n",
        "        ssim_values.append(1-compare_ssim(check_adv.rehspe(CIFAR_IMG,CIFAR_IMG),img.reshape(CIFAR_IMG,CIFAR_IMG))) #add the distance\n",
        "        end=time.time()\n",
        "        times.append(end-start) #add the time \n",
        "        fitness_of_evolved.append(calculate_fitness(model,check_adv,img,label)) #add the fitness value of adversarial\n",
        "        number_of_rounds.append(max_gen)\n",
        "        pred_l=np.argmax(model.predict(check_adv.reshape(1,CIFAR_IMG,CIFAR_IMG,1)/255.0))\n",
        "        predicted_class.append(pred_l)\n",
        "        print(\"Left: adversarial \\t Right: ground truth\")\n",
        "        fd, idx = plt.subplots(1,2)\n",
        "        idx[0].imshow(check_adv.reshape(CIFAR_IMG,CIFAR_IMG),cmap='gray')\n",
        "        idx[1].imshow(img.reshape(CIFAR_IMG,CIFAR_IMG),cmap='gray')\n",
        "        plt.show()\n",
        "        print(f\"True label: {label}\")\n",
        "        print(f\"predicted label: {pred_l}\") \n",
        "        print(\"Time: \",end-start ,\" seconds\")\n",
        "        numb_of_adv_found+=1\n",
        "        break\n",
        "      #check the second termination \n",
        "      else:\n",
        "          #check if fitness increases, if not , add +1 to temporary var\n",
        "        if fit_max1>fit_max:\n",
        "          fit_max=fit_max1\n",
        "          winner_of_gen.update(image= best)\n",
        "          winner_of_gen.update(label= label)\n",
        "          winner_of_gen.update(fitness= fit_max1)\n",
        "          fitness_no_change=0\n",
        "        else:\n",
        "          fitness_no_change+=1\n",
        "      \n",
        "      #print after every 10 generations to see the progress\n",
        "      if (max_gen % 10 == 0):\n",
        "        print(f\"Generation {max_gen}\")\n",
        "        print(f\"Max fitness value {fit_max}\")\n",
        "      max_gen+=1\n",
        "\n",
        "      # if fitness did not improve for 30 generations, save the image that was best , saved it in a dicitonary\n",
        "      if fitness_no_change==30:\n",
        "        print(\"FITNESS DID NOT IMPROVE FOR 30 GENERATIONS\")\n",
        "        print(\"Best adversarial image we could find: \\n\")\n",
        "        evolved_examples.append(winner_of_gen[\"image\"])\n",
        "        ssim_values.append(1-compare_ssim(np.array(winner_of_gen[\"image\"]).reshape(CIFAR_IMG,CIFAR_IMG),img.reshape(CIFAR_IMG,CIFAR_IMG)))\n",
        "        number_of_rounds.append(max_gen)\n",
        "        end=time.time()\n",
        "        times.append(end-start)\n",
        "        fitness_of_evolved.append(winner_of_gen[\"fitness\"])\n",
        "        pred_l=np.argmax(model.predict(np.array(winner_of_gen[\"image\"]).reshape(1,CIFAR_IMG,CIFAR_IMG,1)/255.0))\n",
        "        predicted_class.append(pred_l)\n",
        "        print(\"Left: adversarial \\t Right: ground truth\")\n",
        "        fd, idx = plt.subplots(1,2)\n",
        "        idx[0].imshow(np.array(winner_of_gen[\"image\"]).reshape(CIFAR_IMG,CIFAR_IMG),cmap='gray')\n",
        "        idx[1].imshow(img.reshape(CIFAR_IMG,CIFAR_IMG),cmap='gray')\n",
        "        plt.show()\n",
        "        print(f\"True label: {label}\")\n",
        "        print(f\"predicted label: {pred_l}\")\n",
        "        print(\"Time: \",end-start ,\" seconds\")\n",
        "        numb_of_found_after30 +=1\n",
        "        break\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Initial fitness: \n",
            " [-0.601101246810765, -0.6005961530474837, -0.6014134480220032, -0.6001644182925169, -0.6011998291637335, -0.6025931954191092, -0.6009784444580308, -0.6018473675227165, -0.6031249106807381, -0.601783794802139, -0.6029265960168553, -0.6002750216470719, -0.6024496066762344, -0.6044706753896447, -0.6014099455553323, -0.6011578390383602, -0.6008630359929445, -0.601889590359166, -0.6011236887190184, -0.6023807558853185, -0.601682805520339, -0.6001302782634745, -0.6022597241912634, -0.6032677382632557, -0.6013242593930396, -0.601605896592248, -0.6042563904742136, -0.6004496622367596, -0.6003989711782242, -0.6012764829763931, -0.6016090104667132, -0.6001552355556421, -0.6021555921087043, -0.6001738521371599, -0.6005702818915523, -0.6019471337659887, -0.6009771101911499, -0.6017631451558074, -0.6019195377535094, -0.6013487096641336, -0.6020705475930441, -0.6013949070361446, -0.6024318496525812, -0.6005009218131354, -0.6035317728711896, -0.6057794511502754, -0.6004617636066039, -0.6018629521048624, -0.600976089232135, -0.6005467486831819]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:74: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 0\n",
            "Max fitness value -0.6001302782634745\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/measure/_structural_similarity.py:17: UserWarning: Inputs have mismatched dtype.  Setting data_range based on im1.dtype.\n",
            "  **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 10\n",
            "Max fitness value -0.5322485786105723\n",
            "Generation 20\n",
            "Max fitness value 0.9675190190297775\n",
            "Generation 30\n",
            "Max fitness value 0.9708343346422046\n",
            "Generation 40\n",
            "Max fitness value 0.9715984308736879\n",
            "Generation 50\n",
            "Max fitness value 0.9726782730511343\n",
            "Generation 60\n",
            "Max fitness value 0.973399292104549\n",
            "Generation 70\n",
            "Max fitness value 0.973399292104549\n",
            "Generation 80\n",
            "Max fitness value 0.9741757952589084\n",
            "Generation 90\n",
            "Max fitness value 0.9741757952589084\n",
            "Generation 100\n",
            "Max fitness value 0.9741757952589084\n",
            "Generation 110\n",
            "Max fitness value 0.9741757952589084\n",
            "FITNESS DID NOT IMPROVE FOR 30 GENERATIONS\n",
            "Best adversarial image we could find: \n",
            "\n",
            "Left: adversarial \t Right: ground truth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:134: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "True label: 0\n",
            "predicted label: 2\n",
            "Time:  288.71509861946106  seconds\n",
            "Initial fitness: \n",
            " [-0.4689289719211269, -0.46957809971197995, -0.4793188227968375, -0.505378099002152, -0.5293533533707957, -0.3782140322668609, -0.5082534491670596, -0.48956132842378297, -0.500784969513157, -0.5260217601136528, -0.5082692661304691, -0.502914886653962, -0.5242862616942243, -0.49259882862431237, -0.46750780379949364, -0.5245596041925055, -0.5023181034050522, -0.5248631496605295, -0.4893942029687374, -0.4846835194849272, -0.48310070444580266, -0.49270109009397584, -0.5106686290403454, -0.5167635187344667, -0.5208375312622243, -0.4594937957890485, -0.41976468801581257, -0.4977758908783374, -0.5023965250504574, -0.5198112200411119, -0.4848810004183578, -0.5014906135305048, -0.46247733318091877, -0.486738495935319, -0.5427333439034658, -0.467252086666326, -0.39311625047966614, -0.516918687882488, -0.5081958890667654, -0.49457855433742487, -0.5395624566489512, -0.5103802899456958, -0.4472271249206967, -0.497751073800203, -0.38620902450325945, -0.5218312647092771, -0.4432326461457682, -0.41493570561550047, -0.47489157176213526, -0.5571336602067265]\n",
            "Generation 0\n",
            "Max fitness value -0.13217504931409418\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEMXgasB3Llv",
        "colab_type": "text"
      },
      "source": [
        "# Save files\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u43v4fe33RGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "file_ = open('GA_adv_cifar_ssim_Kcrossover', 'wb')\n",
        "pickle.dump(evolved_examples, file_)\n",
        "pickle.dump(times, file_)\n",
        "pickle.dump(ssim_values, file_)\n",
        "pickle.dump(fitness_of_evolved , file_)\n",
        "pickle.dump(predicted_class, file_)\n",
        "pickle.dump(number_of_rounds, file_)\n",
        "file_.close()\n",
        "\n",
        "print(f\"Max time: {np.max(times)}\")\n",
        "print(f\"Min time: {np.min(times)}\")\n",
        "print(f\"Mean time: {np.mean(times)}\")\n",
        "print(f\"Std time: {np.std(times)}\\n\")\n",
        "\n",
        "print(f\"Max fitness evolved: {np.max(fitness_of_evolved)}\")\n",
        "print(f\"Min fitness evolved:: {np.min(fitness_of_evolved)}\")\n",
        "print(f\"Mean fitness evolved: {np.mean(fitness_of_evolved)}\")\n",
        "print(f\"Std fitness evolved:: {np.std(fitness_of_evolved)}\\n\")\n",
        "\n",
        "print(f\"Max ssim: {np.max(ssim_values)}\")\n",
        "print(f\"Min ssim: {np.min(ssim_values)}\")\n",
        "print(f\"Mean ssim: {np.mean(ssim_values)}\")\n",
        "print(f\"Std ssim: {np.std(ssim_values)}\\n\")\n",
        "\n",
        "print(f\"Max ssim: {np.max(number_of_rounds)}\")\n",
        "print(f\"Min ssim: {np.min(number_of_rounds)}\")\n",
        "print(f\"Mean ssim: {np.mean(number_of_rounds)}\")\n",
        "print(f\"Std ssim: {np.std(number_of_rounds)}\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Percentage of adversarial founds sucessfully : {numb_of_adv_found/len(adversarial_y)} %\")\n",
        "print(f\"Percentage of adversarial founds after fitness not improving for 30 generations: {numb_of_found_after30/len(adversarial_y)} %\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQoHNMX_8nor",
        "colab_type": "text"
      },
      "source": [
        "Open adversarial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEK7GsD78oq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('GA_adv_cifar_ssim_Kcrossover', 'rb') as f:\n",
        "    evolved_examples = pickle.load(f)\n",
        "    times= pickle.load(f)\n",
        "    ssim_values = pickle.load(f)\n",
        "    fitness_of_evolved = pickle.load(f)\n",
        "    predicted_class = pickle.load(f)\n",
        "    number_of_rounds = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e9R7ACErtqK",
        "colab_type": "text"
      },
      "source": [
        "# Examples of what functions do"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpEVAzR7rtK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "population = init_pop_from_sample(50,adversarial[15],adversarial_y[15][0])\n",
        "fitness = pop_fitness(model,np.expand_dims(population.reshape(population.shape[0],CIFAR_IMG,CIFAR_IMG),axis=3),img.reshape(CIFAR_IMG,CIFAR_IMG),adversarial_y[15][0])\n",
        "print(fitness)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aYxCQLEu1BB",
        "colab_type": "code",
        "outputId": "6a29e5dc-27d0-4479-81b7-6e1288329285",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "plt.imshow(population[0].reshape(CIFAR_IMG,CIFAR_IMG))\n",
        "plt.show()\n",
        "print(f\"Class for this {adversarial_y[15][0]}\")\n",
        "print(model.predict(population[0].reshape(1,CIFAR_IMG,CIFAR_IMG,1) /255.0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Class for this 1\n",
            "[[2.2063480e-10 1.0000000e+00 6.6041472e-14 3.5760719e-12 3.9276270e-13\n",
            "  1.1313486e-13 8.8119643e-13 6.8588521e-13 1.9681285e-13 3.7839783e-08]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhxCaFZPGPpe",
        "colab_type": "code",
        "outputId": "35163672-1426-46f3-d021-b87dc280c722",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "parent1 = tournament(population, model, adversarial[15], adversarial_y[15]) \n",
        "parent2 = tournament(population, model, adversarial[15], adversarial_y[15])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/measure/_structural_similarity.py:17: UserWarning: Inputs have mismatched dtype.  Setting data_range based on im1.dtype.\n",
            "  **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gORkePYLv4EW",
        "colab_type": "code",
        "outputId": "17422d1a-b936-43f2-a2c2-33f4cb500bf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "fd, idx =  plt.subplots(1,2)\n",
        "idx[0].imshow(parent1.reshape(CIFAR_IMG,CIFAR_IMG),cmap=\"gray\")\n",
        "idx[1].imshow(parent2.reshape(CIFAR_IMG,CIFAR_IMG),cmap=\"gray\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8f5ea68dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAC5CAYAAAAxiWT3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAYF0lEQVR4nO3dbYxVRZoH8P8jNArSitC8NNCArWQNGhaxA0McQR1ZJ3xxJpmsuMlEEw2TzZpodj4MM5vszm72g7OZ0S8TZ8JEoiYsLLtq1Am7s2gcJ6hh7BloBUF5bWjeWt7kRXn12Q/39Hbfqudyq88999xTzf+XkO5T1D2n7umH4nY9p6pEVUFERPG5ptENICKidNiBExFFih04EVGk2IETEUWKHTgRUaTYgRMRRaqmDlxEvi0in4rIThFZnlWjiBqNsU0xkLTPgYvIMACfAVgMoAfAhwAeUdVPsmseUf4Y2xSL4TW8dh6Anaq6GwBEZA2AhwBUDPJx48bp9OnTy8qs/0BEpIZm0VAUEifd3d04duxYFsGTSWxfDUL/rXLCYGUhsb1v3z4cPXrUu9m1dOBTAOwfcNwDYP6VXjB9+nS8++67ZWVW46+5Jt3ITkiQWAFnXe/rr79O1QbLsGHDguoVNcizvBeWkAC22uDWWbRoUVZNyiS2LWk/nBQ1tocPD+tC3GtabW1E/Bc1tt2f28KFC83z1z2JKSLLRKRTRDqPHj1a78sR5YaxTY1WSwd+AEDbgOOpSVkZVV2hqh2q2tHS0lLD5Yhyw9imKNQyhPIhgJkicjNKwb0UwN9c6QUigqamprKyvMfArV8pretl+Ste6Lnq+es14P+qFvq6LNsVMhRS6bXV6mT4K3iq2B4xYkTV9tQztkPjuN6xnaXQdqWNhbTDtVYcZxnbof9WU3fgqnpJRJ4E8DsAwwCsVNWtac9HVBSMbYpFLZ/AoarrAKzLqC1EhcHYphhwJiYRUaTYgRMRRaqmIZTBUlVcunQpz0teFUKfZU2TGKy1XsjrQpJ9Wba9HlQVFy9ebNj1hyrG9pXr8BM4EVGk2IETEUWKHTgRUaQaPgZe77VQ3PGmei++EzpxIkuh5097Lyz1noiUZi2UtHGTBcZ2fTC2SyrFDT+BExFFih04EVGk2IETEUWKHTgRUaRyTWKKiLe5QdqEQZbJk9DEUsjC60VZqD5LoauspZX2512knZuuhtgO3Rwipn8Dscc2P4ETEUWKHTgRUaTYgRMRRaqmMXAR2QvgNIDLAC6pakcWjSJqNMY2xSCLJOZ9qhq8o6ub6AlJnmSploRBvRMSRU301HuGY8iKcw1KWBYmtkMSg6HbBVpC2hW6633oa68G9Y5tDqEQEUWq1g5cAfyviPxJRJZl0SCigmBsU+HVOoTyTVU9ICITAKwXke2q+oeBFZLgXwYAbW1tNV6OKDeMbSq8mj6Bq+qB5GsvgNcAzDPqrFDVDlXtaGlpqeVyRLlhbFMMUn8CF5HrAVyjqqeT7/8KwL9k0ai0g/qNSDJmObOu3klM9/yh16v3zLqQGX5ZLvFZTSyxHbKEai33KOS1oUnMosa21f4sl9u1ZBnbtQyhTATwWnKh4QD+XVX/p4bzERUFY5uikLoDV9XdAP4yw7YQFQJjm2LBxwiJiCKV+2qEaSYM1DJGFFKvlvG5LMf26n2ukEkFodKeK+17tF6XdtyzHqzVCCvVy/Ka1TC2By+m2OYncCKiSLEDJyKKFDtwIqJIsQMnIopUrklMVcWlS5fKytKu2JZ2FbQir4qWZVvrPfElZAJElsmmvLciGyxVxcWLF8vKGNv9GNuV1RLb/ARORBQpduBERJFiB05EFCl24EREkco1iQmEJWjcGW3WDLcst4qqZVW+kHNlOWs09JpWQiVtIinLhE3aBN3ly5dTnysvIe0ZPrz8n1y9t0FjbGdz/mrXGwz35+Y+2GHVqXiu1K0gIqKGYgdORBQpduBERJGq2oGLyEoR6RWRLQPKxorIehHZkXy9qb7NJMoeY5tiF5LEfBHALwG8PKBsOYC3VfUZEVmeHP8o5ILu4L+VoHTLaklWWcmvam0C0i8NGZpwtRIlVjIjy2uGtMFSS6ItRMhymnVqw4vIKLatpZKtNofUCcXYrqzesW3dw5CtAa2ykDhJPRMz2Yn7uFP8EICXku9fAvCdauchKhrGNsUu7X//E1X1UPL9YZT2ECQaChjbFI2ak5ha+l2i4u9kIrJMRDpFpPPo0aO1Xo4oN4OJ7c8//zzHlhGVpO3Aj4hIKwAkX3srVVTVFaraoaodLS0tKS9HlJtUsT1+/PjcGkjUJ+1MzDcAPArgmeTr6yEvEhFvJlpIMiDLWU+hrOSDu1yoVXb+/HmvTmgCp6mpqew4NMESkgQB/FmAI0aMCHpdaMIm7R6V1r0OOVed9sBMFduAn3BjbPcbarFtCZ2pmmZp2tR7YorIagAfAPgLEekRkcdRCu7FIrIDwAPJMVFUGNsUu6qfwFX1kQp/9a2M20KUK8Y2xY4zMYmIIpXraoTWZIeQcSNrTMoaszt+3H2kF3CffDl58qRX58KFC16ZNbbnjrMB/ljb6NGjvTqjRo0Kuubp06fLjs+ePevVOXXqlFdmPQHx1VdfeWXXX3992fGECRO8OnfccYdXNnXqVK8s7WSHkPFuq17IGHidxsSDZBnbVuwdO3bMK2Ns9ytCbIfGe5axzU/gRESRYgdORBQpduBERJFiB05EFKlck5iqmnorLpeV1Hn55Ze9sk2bNlU9V3Nzs1dmrfRmzSR1EypWouTBBx8MatfGjRvLjvfv3+/VufHGG70y615Y7Z82bVrZsZX0Xb9+vVe2dOlSr2zevHleWcgKgmknSVjvx31dliskDlaWsW0tOcHY7lfU2LaE1KsltvkJnIgoUuzAiYgixQ6ciChS7MCJiCKVaxIT8Afj067yZSVK1qxZ45W5M7Tuvfder467UhrgzxwDgHHjxnlla9euLTu2ki5WUsSqt2/fvrLjzZs3e3UeeOABr2z27NlemXXP2tvby46t9/jxxx97ZStXrvTKzp0755XddtttZcdWYsxaJS7tTLQiJTGt6zO2+zG2K5fVEtv8BE5EFCl24EREkWIHTkQUqZANHVaKSK+IbBlQ9lMROSAim5M/S+rbTKLsMbYpdiFJzBcB/BKAOxXsOVX9+WAuZi25ac1CcremOnDggFfntdde88r27Nnjld1+++1lx1ZSp6uryyuzEjGTJ0/2yrq7u8uO586d69Wxltd0ky4A0NPTc8VzA/YynNddd51X5ia4AP++WkuB3nXXXV7Ze++955U9//zzXtkTTzxRdnz33Xd7daz7b3GTNnVKUL6ISGJ79+7dXpk7M/Jqjm13OVyrzlCM7aqfwFX1DwD8ealEkWNsU+xqGQN/UkQ+Sn4NvalSJRFZJiKdItJpLc5OVECMbYpC2g78VwBuATAHwCEAv6hUUVVXqGqHqnaMHz8+5eWIcsPYpmikmsijqkf6vheR3wD4bdoGWOM/7nZp7kpmALBr1y6v7NZbb/XKrr322rLjHTt2eHWsrais8ThrgsWXX35Z9XUnTpzwyqyV1+65556y4xkzZnh1rHE2a6urkSNHVq1nba1lueGGG7yy1atXe2WHDx8uO7a2vrLGTK22upMi8pqkU9TYnjlzplfG2K5c72qJ7VSfwEWkdcDhdwFsqVSXKCaMbYpJ1U/gIrIawL0AWkSkB8A/AbhXROYAUAB7Afygjm0kqgvGNsWuageuqo8YxS/UoS1EuWJsU+w4E5OIKFK5r0boslbi+uyzz8qO3cQPADz88MNemVXPfaDfmrxibYVlJZKsCRZTpkwpO7YmXKxatcorsyYCzJ8/v+zYerLBmhxiJUGs++reH2v1NHdCBGBPirBWoXPrWVuDWcaOHeuVuRM4QttaJPWObTdxZyXMGNv9hmJs8xM4EVGk2IETEUWKHTgRUaTYgRMRRSr3LJC7Ypu1Mtr7779fdmwlHidNmuSVnTp1yitrbm4uO3ZnrwHA+fPnvTJrSyYrSeTO5Dpz5oxXZ8sWfy6ItfqbtaWUy1rF7fhxfz0mK9Hjzh5zfxZA2CqGAHDLLbd4Ze79OXjwoFfHmvlmnX/79u1lx9b9smbzNVLese3eSysZVtTYtpKTe/fu9cqyjG1rVqdVz4pt9+dkxbY1A7Xesc1P4EREkWIHTkQUKXbgRESRYgdORBSphk9ls5ZldGePhdQB7Jlc7owpK4lmva61tdUrW7x4sVfmJoSsBJGVdGlra/PK3Bly+/bt8+q4SVnAXjrTXQrUaoeVYLHaaiV6LO7P6dy5c0Hnt7a1euutt8qOlyzxt6Z87LHHqp67kay4dWOtlth2N5FgbPfLOrbda1o/N+v8GzZs8MqyjG1+AiciihQ7cCKiSFXtwEWkTUTeEZFPRGSriDyVlI8VkfUisiP5WnHvQKIiYmxT7EI+gV8C8ENVnQXgGwD+TkRmAVgO4G1VnQng7eSYKCaMbYpayIYOh1Da3BWqelpEtgGYAuAhlHYzAYCXAPwewI8G2wBrHzlrxpTLSvRY3Nlp1vKOViLDmlVl7S/ozrb74osvgs5vtf/NN98sO966datXZ+rUqV6Zu98gYCdZXFaix0oaWfWsMjdhZtWxZtt1dXV5ZW77rTruvQ7dB7FPI2LbStS5QmPbnVU8FGN74cKFXhlju9+gxsBFZAaAOwFsBDAx+QcAAIcBTBzMuYiKhLFNMQruwEVkNIBXADytqmULM2jpGRfzORcRWSYinSLS6T72RFQEjG2KVVAHLiJNKAX4KlV9NSk+0reDd/K113qtqq5Q1Q5V7bB24SBqJMY2xSxkV3pBaaPXbar67IC/egPAowCeSb6+HnLBkEk67tietYKgNUHBetjdHU+3VtuzzmWN7VnbWrmrvVnjf9a5rO2p3O22xo0b59XZv3+/V7Znzx6vrL293Stz2+9u7QTYY3tW+6167gpz1n09dOiQV2aNrY4ZM6ZqG9zV8ULHjvswtvsVNbatczG2+4XMxLwbwPcBfCwim5Oyn6AU3GtF5HEA3QD+OuBcREXC2KaohTyFsgGAv3hvybeybQ5RfhjbFDvOxCQiihQ7cCKiSOW6GqGqeoP/1rZThw8fLju2EhJNTU1e2fDh/ttxB/9DJ1eErlLmJjesZIOVyLASNu5qb1aix5qE4a64CAALFizwytxJTdZ7tMqshI3FvRfWqnHW/be2AnOf6rB+3m7iqpGrETK2+zG2K7cLCIttd+IOVyMkIhpi2IETEUWKHTgRUaTYgRMRRSr3LdXcRMgHH3zg1Vm3bl3Z8ciRI706VkLCSga4r73pJn9p50mTJnllVkLiyJEjXtnMmTPLjkeNGuXVsVYSs1Z/c9s6YcKEoNdZM/6sLavcRNhgZy4OZN1/9/zWjDYr+WMlktxZhW4SCShWEhNgbPdhbPdLG9vuz4hJTCKiIYYdOBFRpNiBExFFih04EVGkck9iuoPx586d8+q4s7asRIm1/KWVDHATElayxlqy0mqXNSvMTVzcd999Xh0rAXH27FmvzE30WImSkBmJgJ2ochMq1v2yhCYHQ7Y0s+6rtYWeu5ymlexz730tiassMLZLhmJsu7FlxVojYpufwImIIsUOnIgoUlU7cBFpE5F3ROQTEdkqIk8l5T8VkQMisjn5s6T+zSXKDmObYhcyBn4JwA9V9c8i0gzgTyKyPvm751T15/VrHlFdMbYpaiE78hwCcCj5/rSIbAMwJc3FVNVLSkybNs2sN5CVYLGSGxZ3z8GxY8d6dayESmhyqbu7u+zYWl7TKrNmnbkz6azEhZUgchNjAHDw4EGvzJ1JZy1RapVZCSEr+eMm1Xp6erw6mzZt8somTpzolbmsmXsnTpwoOw5dGrQPY/vK12Rs9ytqbA9qDFxEZgC4E8DGpOhJEflIRFaKiD+PlygSjG2KUXAHLiKjAbwC4GlVPQXgVwBuATAHpU8xv6jwumUi0ikindanDaJGY2xTrII6cBFpQinAV6nqqwCgqkdU9bKqfg3gNwDmWa9V1RWq2qGqHS0tLVm1mygTjG2KWdUxcCkNEr0AYJuqPjugvDUZQwSA7wLYUu1c58+fx969e8vKrDGiMWPGlB1v377dqxO6PdLs2bPLjhctWhR0LuuhfHdcCvDHGK3V09yxRMDebst931Yda5zQ2sLKGtN0t7Gytntyx1UBexzVeq27PZjVVmsShnX/W1tby47dbagAf3x0sGPgjO1+jO0rv7aosR3yFMrdAL4P4GMR2ZyU/QTAIyIyB4AC2AvgBwHnIioSxjZFLeQplA0ArHmp64wyomgwtil2nIlJRBQpduBERJHKdTXCCxcueIkeKyExa9assuOuri6vjjWBwEoYuA/JW08LWG0InQjgJnasB/x7e3u9MiuR5E6ACG2XteKZtbKbW+YmZgA70ROaEHLP397e7tWZMsWfJ2P93NxJKSHbeTVySzXGdr+hGNtuvSxj291iDQiPbX4CJyKKFDtwIqJIsQMnIooUO3AiokjlmsS8fPmyl6Bxtw4C/OTM/PnzvTpW8sRKgrjJr507d3p1rJXRrCSLVc9dzcxKWtx8881emZVwcpMZkydP9uo0Nzd7ZXPmzPHKQhIxVjLISupY78kqcxMtIferEreedS535lsjk5hZxra1NZr1s2Js94s5tq1Zlm4Zk5hEREMMO3AiokixAyciihQ7cCKiSOWaxFTVoMF5d6bS/fff79WxEjEhCYnQRENocsNdjtJanjI0ueae30rEWIlai/U+3bKQOkB4+0PqWXVCy4qMsT24azK2s8FP4EREkWIHTkQUqaoduIhcJyJ/FJEuEdkqIv+clN8sIhtFZKeI/IeI+A9ZEhUYY5tiFzLodB7A/ap6Jtk/cIOI/DeAvwfwnKquEZFfA3gcpc1gK1JV7wF46+F6t8x6wN8aswsZ47LGn6yH8q16oeNq9ZR2sgDgv6fQc6Ud5wyZEAHY9z9tGwaJsX2F8zO2+xU1tqt+AteSM8lhU/JHAdwP4L+S8pcAfCd1K4gagLFNsQvdlX5YsmdgL4D1AHYBOKmqfYvW9gDwF8MlKjjGNsUsqANX1cuqOgfAVADzANwWegERWSYinSLSeebMmeovIMoRY5tiNqinUFT1JIB3ACwAMEZE+sbQpwI4UOE1K1S1Q1U7rN01iIqAsU0xqprEFJHxAC6q6kkRGQlgMYCfoRTs3wOwBsCjAF4POFfQA/chCYm0kxas17nbFwF28iF0AkSIeieIrPO7E01C72voewx5T1bCxjq/e/9DkkGDxdiufK5KZSEY21c+f5axHfIUSiuAl0RkGEqf2Neq6m9F5BMAa0TkXwFsAvBC6lYQNQZjm6JWtQNX1Y8A3GmU70ZpzJAoSoxtih1nYhIRRYodOBFRpCTPVd9E5HMA3QBaABzN7cLZi7n9MbcduHL7p6vq+Dwb04exXQgxtx1IEdu5duD/f1GRTlXtyP3CGYm5/TG3HSh++4vevmpibn/MbQfStZ9DKEREkWIHTkQUqUZ14CsadN2sxNz+mNsOFL/9RW9fNTG3P+a2Ayna35AxcCIiqh2HUIiIIpV7By4i3xaRT5PdTpbnff3BEpGVItIrIlsGlI0VkfUisiP5elMj21iJiLSJyDsi8kmy48xTSXnh2x/bbjmM6/zEHNdAxrGtqrn9ATAMpfWW2wGMANAFYFaebUjR5oUA5gLYMqDs3wAsT75fDuBnjW5nhba3ApibfN8M4DMAs2JoPwABMDr5vgnARgDfALAWwNKk/NcA/rYAbWVc59v2aOM6aVtmsZ13wxcA+N2A4x8D+HGjb2hAu2c4gf4pgNYBwfRpo9sY+D5eR2nFvajaD2AUgD8DmI/SRIfhVjw1sH2M68a+jyjjOmlnTbGd9xDKFAD7BxzHutvJRFU9lHx/GMDERjYmhIjMQGnhpo2IpP0R7ZbDuG6QGOMayC62mcSskZb+uyz0ozwiMhrAKwCeVtVTA/+uyO3XGnbLodoUOS76xBrXQHaxnXcHfgBA24DjirudFNwREWkFgORrb4PbU5GUdlt/BcAqVX01KY6m/UC63XJyxrjO2VCIa6D22M67A/8QwMwk2zoCwFIAb+Tchiy8gdJOLUDgji2NIKVtRF4AsE1Vnx3wV4Vvv4iMF5Exyfd9u+VsQ/9uOUBx2s64zlHMcQ1kHNsNGLRfglLWeBeAf2h0EiGgvasBHAJwEaVxqccBjAPwNoAdAN4CMLbR7azQ9m+i9GvkRwA2J3+WxNB+ALNR2g3nIwBbAPxjUt4O4I8AdgL4TwDXNrqtSbsY1/m1Pdq4TtqfWWxzJiYRUaSYxCQiihQ7cCKiSLEDJyKKFDtwIqJIsQMnIooUO3AiokixAyciihQ7cCKiSP0fA6qWZLm7dtYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZJXShUyHIrS",
        "colab_type": "code",
        "outputId": "c26ae352-d1a1-4510-9da7-ae5e01d1ec43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "child1, child2 = multi_crossover(parent1, parent2,adversarial[15]) # crossover \n",
        "#child1, child2 = add_noise(child1), add_noise(child2) # apply mutation to pixels "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/measure/_structural_similarity.py:17: UserWarning: Inputs have mismatched dtype.  Setting data_range based on im1.dtype.\n",
            "  **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72tQ7R_RHZzZ",
        "colab_type": "code",
        "outputId": "c81cdb63-ed10-42c2-d477-894c5e91bcf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "fd, idx =  plt.subplots(1,2)\n",
        "idx[0].imshow(child1.reshape(CIFAR_IMG,CIFAR_IMG),cmap=\"gray\")\n",
        "idx[1].imshow(child2.reshape(CIFAR_IMG,CIFAR_IMG),cmap=\"gray\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8f5e585550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a3pXLQSwZlT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"diff between children {np.unique(child1-child2)}\")\n",
        "print(f\"diff between parents {np.unique(parent1-parent2)}\")\n",
        "print(f\"diff between p1 and c1 {np.unique(parent1-child1)}\")\n",
        "print(f\"diff between p1 and c2 {np.unique(parent1-child2)}\")\n",
        "print(f\"diff between p2 and c1 {np.unique(parent2-child1)}\")\n",
        "print(f\"diff between p2 and c2 {np.unique(parent2-child2)}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEPQapUpILBr",
        "colab_type": "code",
        "outputId": "ac694765-e044-4f9f-82ee-9c599a2eb431",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "bb = choose_better_child(child1, child2,adversarial[15],adversarial_y[15][0],model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/measure/_structural_similarity.py:17: UserWarning: Inputs have mismatched dtype.  Setting data_range based on im1.dtype.\n",
            "  **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCl4mvK99XYj",
        "colab_type": "code",
        "outputId": "fd9867bc-0c0a-486e-c393-ad74b8ef6298",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "fitness = pop_fitness(model,np.expand_dims(population.reshape(population.shape[0],CIFAR_IMG,CIFAR_IMG),axis=3),img.reshape(CIFAR_IMG,CIFAR_IMG),label) \n",
        "print(fitness)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/measure/_structural_similarity.py:17: UserWarning: Inputs have mismatched dtype.  Setting data_range based on im1.dtype.\n",
            "  **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[-0.26002962878595726, -0.25999958545736684, -0.26007314251448344, -0.26004007622401076, -0.26003266487525345, -0.26011373574731095, -0.2599816460817825, -0.25998496480763594, -0.2600353571926644, -0.2600021864303609, -0.260040721413234, -0.2600228430135187, -0.26003768485830203, -0.26002701209750284, -0.26006302743228543, -0.2599796432991168, -0.2600043346069123, -0.26003024147792836, -0.2600466627237271, -0.26003812318804226, -0.2600652442884724, -0.2600447098702882, -0.2600085762943468, -0.26001327339828323, -0.2599806557454484, -0.26007237070197037, -0.25996000471207786, -0.2600457997287944, -0.2600101441535663, -0.26005323947618036, -0.2600554130353725, -0.2600860828123626, -0.26003997918862914, -0.26004537198733424, -0.2600515291553301, -0.2600503663988854, -0.26001231736237695, -0.2600170667581806, -0.2600851316879575, -0.2599960477747653, -0.260017809873727, -0.2600171997460062, -0.2600455137861651, -0.26001145913341955, -0.2600466317811507, -0.2600557191632309, -0.26006128108305554, -0.2599700462660023, -0.26005349311420517, -0.2600591984831575]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}