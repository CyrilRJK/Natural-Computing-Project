{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is just for computing the accuracy on the adversarial examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "import time\n",
    "from skimage.measure import compare_ssim\n",
    "import tensorflow as tf\n",
    "from keras.models import Model,load_model\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, Input, Activation\n",
    "from keras.utils import to_categorical\n",
    "import keras\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set seeds\n",
    "random.seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 308,714\n",
      "Trainable params: 307,818\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Network 3 \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar10\n",
    "from keras import regularizers\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import numpy as np\n",
    "\n",
    "CIFAR_IMG= 32\n",
    "\n",
    "input_shape = (CIFAR_IMG,CIFAR_IMG,1)\n",
    "weight_decay = 1e-4\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=input_shape))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    " \n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    " \n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    " \n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    " \n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "'''\n",
    "history = model.fit(x=x_train_C,y=y_train_C, epochs=150, batch_size=64, validation_data=[x_test_C,y_test_C])\n",
    "\n",
    "score= model.evaluate(x_test_C, y_test_C,verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model.save_weights(\"CNN_CIFAR10_net3.h5\")\n",
    "files.download('CNN_CIFAR10_net3.h5')\n",
    "'''\n",
    "\n",
    "model = load_model(\"../Models/CNN_CIFAR10_net3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "X_sc = X_train / 255.0\n",
    "X_test_sc = X_test / 255.0\n",
    "y_cat = to_categorical(y_train)\n",
    "\n",
    "def grayscale(data, dtype='float32'):\n",
    "    # luma coding weighted average in video systems\n",
    "    r, g, b = np.asarray(.3, dtype=dtype), np.asarray(.59, dtype=dtype), np.asarray(.11, dtype=dtype)\n",
    "    rst = r * data[:, :, :, 0] + g * data[:, :, :, 1] + b * data[:, :, :, 2]\n",
    "    # add channel dimension\n",
    "    rst = np.expand_dims(rst, axis=3)\n",
    "    return rst\n",
    "\n",
    "X_sc = grayscale(X_sc)\n",
    "X_test_sc = grayscale(X_test_sc)\n",
    "X_train = grayscale(X_train)\n",
    "X_test = grayscale(X_test)\n",
    "\n",
    "y_pred_test = model.predict(np.expand_dims(X_test_sc.reshape(X_test_sc.shape[0],32,32),axis=3))\n",
    "y_pred_train = model.predict(np.expand_dims(X_sc.reshape(X_sc.shape[0],32,32),axis=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.958\n",
      "Test accuracy:  0.824\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy: \",round(accuracy_score(y_train,np.argmax(y_pred_train,axis=1)),3))\n",
    "print(\"Test accuracy: \",round(accuracy_score(y_test,np.argmax(y_pred_test,axis=1)),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make subset \n",
    "def sample_test_set(percentage,X_test,X_test_scaled,y_test,imsize,channels,num_clusters, num_classes,num_samples):\n",
    "    \n",
    "    original = []\n",
    "    adversarial = []\n",
    "    original_y = []\n",
    "    adversarial_y = []\n",
    "    for sample_class in range(num_classes):\n",
    "        labels = y_test[(y_test==sample_class).reshape(num_samples)]\n",
    "        samples_orig = X_test[(y_test==sample_class).reshape(num_samples)]\n",
    "        samples = X_test_scaled[(y_test==sample_class).reshape(num_samples)]\n",
    "        samples = samples.reshape((samples.shape[0],imsize*imsize*channels))\n",
    "        kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit_predict(samples)\n",
    "        for cluster in range(num_clusters):  \n",
    "            subsamples = np.where(kmeans==cluster)[0]\n",
    "            ori, adv = train_test_split(subsamples,random_state=0, test_size = percentage ,shuffle=True)\n",
    "            original.extend(samples_orig[ori])\n",
    "            original_y.extend(labels[ori])\n",
    "            adversarial.extend(samples_orig[adv])\n",
    "            adversarial_y.extend(labels[adv])\n",
    "    return np.array(original), np.array(adversarial), np.array(original_y), np.array(adversarial_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "discard,subsample, discard_y, subsample_y = sample_test_set(0.1,X_test,X_test_sc,y_test,32,1,10,10,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsample : (1047, 32, 32, 1)\n",
      "Subsample_y: (1047, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Subsample : {subsample.shape}\")\n",
    "print(f\"Subsample_y: {subsample_y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on subset before:  0.824\n"
     ]
    }
   ],
   "source": [
    "subsample_sc = subsample / 255.0\n",
    "y_pred_subsample = model.predict(np.expand_dims(subsample_sc.reshape(subsample_sc.shape[0],32,32),axis=3))\n",
    "print(\"Accuracy on subset before: \", round(accuracy_score(subsample_y,np.argmax(y_pred_subsample,axis=1)),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "original,adversarial, original_y, adversarial_y = sample_test_set(0.1,subsample,subsample_sc,subsample_y,32,1,6,10,1047)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on original:  0.824945295404814\n",
      "Accuracy on adversarial before:  0.82\n"
     ]
    }
   ],
   "source": [
    "original_sc = original / 255.0\n",
    "y_pred_original = model.predict(np.expand_dims(original_sc.reshape(original_sc.shape[0],32,32),axis=3))\n",
    "print(\"Accuracy on original: \", accuracy_score(original_y,np.argmax(y_pred_original,axis=1)))\n",
    "\n",
    "adversarial_sc = adversarial / 255.0\n",
    "y_pred_adversarial = model.predict(np.expand_dims(adversarial_sc.reshape(adversarial_sc.shape[0],32,32),axis=3))\n",
    "print(\"Accuracy on adversarial before: \", round(accuracy_score(adversarial_y,np.argmax(y_pred_adversarial,axis=1)),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape (914, 32, 32, 1)\n",
      "Adversarial shape (133, 32, 32, 1)\n",
      "Original labels shape (914, 1)\n",
      "Adversarial labels shape (133, 1)\n"
     ]
    }
   ],
   "source": [
    "with open('../subsets/subset_cifar', 'rb') as f:\n",
    "    original = pickle.load(f)\n",
    "    adversarial= pickle.load(f)\n",
    "    original_y = pickle.load(f)\n",
    "    adversarial_y = pickle.load(f)\n",
    "\n",
    "print(f\"Original shape {original.shape}\")\n",
    "print(f\"Adversarial shape {adversarial.shape}\")\n",
    "print(f\"Original labels shape {original_y.shape}\")\n",
    "print(f\"Adversarial labels shape {adversarial_y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def PSNR(original, compressed): \\n    mse = np.mean((original - compressed) ** 2) \\n    if(mse == 0):  # MSE is zero means no noise is present in the signal . \\n                  # Therefore PSNR have no importance. \\n        return 100\\n    max_pixel = 255.0\\n    psnr = 20 * log10(max_pixel / sqrt(mse)) \\n    return psnr\\n    \\n'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://www.geeksforgeeks.org/python-peak-signal-to-noise-ratio-psnr/\n",
    "from math import log10, sqrt \n",
    "import cv2 \n",
    "\n",
    "def PSNR(original,evolved):\n",
    "    psnr=[]\n",
    "    for i in range(original.shape[0]):\n",
    "        psnr_original = cv2.PSNR(original[i],original[i])\n",
    "        psnr_adv_org = cv2.PSNR(original[i],np.array(evolved[i],dtype=\"float32\"))\n",
    "        psnr.append(round((psnr_adv_org/psnr_original)*100,3))\n",
    "    return psnr\n",
    "\n",
    "'''def PSNR(original, compressed): \n",
    "    mse = np.mean((original - compressed) ** 2) \n",
    "    if(mse == 0):  # MSE is zero means no noise is present in the signal . \n",
    "                  # Therefore PSNR have no importance. \n",
    "        return 100\n",
    "    max_pixel = 255.0\n",
    "    psnr = 20 * log10(max_pixel / sqrt(mse)) \n",
    "    return psnr\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MULTICROSSOVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results/GA_adv_cifar_multicrossover_seed1', 'rb') as f:\n",
    "    evolved_examples = pickle.load(f)\n",
    "    times= pickle.load(f)\n",
    "    ssim_values = pickle.load(f)\n",
    "    fitness_of_evolved = pickle.load(f)\n",
    "    predicted_class = pickle.load(f)\n",
    "    number_of_rounds = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133, 1024)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(evolved_examples).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial after:  0.083\n"
     ]
    }
   ],
   "source": [
    "# computing accuracy on adversarial after \n",
    "evolved_examples = np.array(evolved_examples)\n",
    "evolved_examples=evolved_examples/ 255.0\n",
    "y_pred_adversarial = model.predict(np.expand_dims(evolved_examples.reshape(evolved_examples.shape[0],32,32),axis=3))\n",
    "print(\"Accuracy on adversarial after: \", round(accuracy_score(adversarial_y,np.argmax(y_pred_adversarial,axis=1)),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1047, 32, 32, 1)\n",
      "Accuracy on subsample after:  0.734\n"
     ]
    }
   ],
   "source": [
    "subsample = np.concatenate((original,evolved_examples.reshape(evolved_examples.shape[0],32,32,1)))\n",
    "print(subsample.shape)\n",
    "\n",
    "subsample_sc = subsample / 255.0\n",
    "subsample_y = np.concatenate((original_y,adversarial_y))\n",
    "y_pred_subsample = model.predict(np.expand_dims(subsample_sc.reshape(subsample_sc.shape[0],32,32),axis=3))\n",
    "print(\"Accuracy on subsample after: \", round(accuracy_score(subsample_y,np.argmax(y_pred_subsample,axis=1)),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean psnr 1.6\n",
      "Std psnr 0.558\n",
      "Min psnr 0.24\n",
      "Max psnr 3.331\n"
     ]
    }
   ],
   "source": [
    "psnr = PSNR(adversarial.reshape(adversarial.shape[0],32,32),evolved_examples.reshape(evolved_examples.shape[0],32,32))\n",
    "\n",
    "print(f\"Mean psnr {round(np.mean(psnr),3)}\")\n",
    "print(f\"Std psnr {round(np.std(psnr),3)}\")\n",
    "print(f\"Min psnr {round(np.min(psnr),3)}\")\n",
    "print(f\"Max psnr {round(np.max(psnr),3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-K CROSSOVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results/GA_adv_cifar_ssim_Kcrossover_seed1', 'rb') as f:\n",
    "    evolved_examples = pickle.load(f)\n",
    "    times= pickle.load(f)\n",
    "    ssim_values = pickle.load(f)\n",
    "    fitness_of_evolved = pickle.load(f)\n",
    "    predicted_class = pickle.load(f)\n",
    "    number_of_rounds = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial after:  0.06\n"
     ]
    }
   ],
   "source": [
    "# computing accuracy on adversarial after \n",
    "evolved_examples = np.array(evolved_examples)\n",
    "evolved_examples=evolved_examples/ 255.0\n",
    "y_pred_adversarial = model.predict(np.expand_dims(evolved_examples.reshape(evolved_examples.shape[0],32,32),axis=3))\n",
    "print(\"Accuracy on adversarial after: \", round(accuracy_score(adversarial_y,np.argmax(y_pred_adversarial,axis=1)),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1047, 32, 32, 1)\n",
      "Accuracy on subsample:  0.734\n"
     ]
    }
   ],
   "source": [
    "subsample = np.concatenate((original,evolved_examples.reshape(evolved_examples.shape[0],32,32,1)))\n",
    "print(subsample.shape)\n",
    "\n",
    "subsample_sc = subsample / 255.0\n",
    "subsample_y = np.concatenate((original_y,adversarial_y))\n",
    "y_pred_subsample = model.predict(np.expand_dims(subsample_sc.reshape(subsample_sc.shape[0],32,32),axis=3))\n",
    "print(\"Accuracy on subsample: \", round(accuracy_score(subsample_y,np.argmax(y_pred_subsample,axis=1)),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean psnr 1.6\n",
      "Std psnr 0.558\n",
      "Min psnr 0.24\n",
      "Max psnr 3.331\n"
     ]
    }
   ],
   "source": [
    "# computing PSNR\n",
    "\n",
    "psnr = PSNR(adversarial.reshape(adversarial.shape[0],32,32),evolved_examples.reshape(evolved_examples.shape[0],32,32))\n",
    "\n",
    "print(f\"Mean psnr {round(np.mean(psnr),3)}\")\n",
    "print(f\"Std psnr {round(np.std(psnr),3)}\")\n",
    "print(f\"Min psnr {round(np.min(psnr),3)}\")\n",
    "print(f\"Max psnr {round(np.max(psnr),3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUADRANT CROSSOVER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results/GA_adv_cifar_quadrant_seed1', 'rb') as f:\n",
    "    evolved_examples = pickle.load(f)\n",
    "    times= pickle.load(f)\n",
    "    ssim_values = pickle.load(f)\n",
    "    fitness_of_evolved = pickle.load(f)\n",
    "    predicted_class = pickle.load(f)\n",
    "    number_of_rounds = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial after:  0.105\n"
     ]
    }
   ],
   "source": [
    "# computing accuracy on adversarial after \n",
    "evolved_examples = np.array(evolved_examples)\n",
    "evolved_examples=evolved_examples/ 255.0\n",
    "y_pred_adversarial = model.predict(np.expand_dims(evolved_examples.reshape(evolved_examples.shape[0],32,32),axis=3))\n",
    "print(\"Accuracy on adversarial after: \", round(accuracy_score(adversarial_y,np.argmax(y_pred_adversarial,axis=1)),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1047, 32, 32, 1)\n",
      "Accuracy on subsample after:  0.734\n"
     ]
    }
   ],
   "source": [
    "# computing accuracy on subset after\n",
    "#concatenating original and evolved images\n",
    "subsample = np.concatenate((original,evolved_examples.reshape(evolved_examples.shape[0],32,32,1)))\n",
    "print(subsample.shape)\n",
    "\n",
    "subsample_sc = subsample / 255.0\n",
    "#concatenating the ground truth labels original + adversarial\n",
    "subsample_y = np.concatenate((original_y,adversarial_y))\n",
    "y_pred_subsample = model.predict(np.expand_dims(subsample_sc.reshape(subsample_sc.shape[0],32,32),axis=3))\n",
    "print(\"Accuracy on subsample after: \", round(accuracy_score(subsample_y,np.argmax(y_pred_subsample,axis=1)),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean psnr 1.591\n",
      "Std psnr 0.558\n",
      "Min psnr 0.231\n",
      "Max psnr 3.322\n",
      "Mean psnr 1.5907744360902256\n",
      "Std psnr 0.5582019148053428\n",
      "Min psnr 0.231\n",
      "Max psnr 3.322\n"
     ]
    }
   ],
   "source": [
    "# computing PSNR\n",
    "psnr = PSNR(adversarial.reshape(adversarial.shape[0],32,32),evolved_examples.reshape(evolved_examples.shape[0],32,32))\n",
    "\n",
    "print(f\"Mean psnr {round(np.mean(psnr),3)}\")\n",
    "print(f\"Std psnr {round(np.std(psnr),3)}\")\n",
    "print(f\"Min psnr {round(np.min(psnr),3)}\")\n",
    "print(f\"Max psnr {round(np.max(psnr),3)}\")\n",
    "\n",
    "\n",
    "print(f\"Mean psnr {np.mean(psnr)}\")\n",
    "print(f\"Std psnr {np.std(psnr)}\")\n",
    "print(f\"Min psnr {np.min(psnr)}\")\n",
    "print(f\"Max psnr {np.max(psnr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNIFORM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results/GA_adv_cifar_ssim_uniform_seed1', 'rb') as f:\n",
    "    evolved_examples = pickle.load(f)\n",
    "    times= pickle.load(f)\n",
    "    ssim_values = pickle.load(f)\n",
    "    fitness_of_evolved = pickle.load(f)\n",
    "    predicted_class = pickle.load(f)\n",
    "    number_of_rounds = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial after:  0.075\n"
     ]
    }
   ],
   "source": [
    "# computing accuracy on adversarial after \n",
    "evolved_examples = np.array(evolved_examples)\n",
    "evolved_examples=evolved_examples/ 255.0\n",
    "y_pred_adversarial = model.predict(np.expand_dims(evolved_examples.reshape(evolved_examples.shape[0],32,32),axis=3))\n",
    "print(\"Accuracy on adversarial after: \", round(accuracy_score(adversarial_y,np.argmax(y_pred_adversarial,axis=1)),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1047, 32, 32, 1)\n",
      "Accuracy on subsample after:  0.734\n"
     ]
    }
   ],
   "source": [
    "# computing accuracy on subset after\n",
    "#concatenating original and evolved images\n",
    "subsample = np.concatenate((original,evolved_examples.reshape(evolved_examples.shape[0],32,32,1)))\n",
    "print(subsample.shape)\n",
    "\n",
    "subsample_sc = subsample / 255.0\n",
    "#concatenating the ground truth labels original + adversarial\n",
    "subsample_y = np.concatenate((original_y,adversarial_y))\n",
    "y_pred_subsample = model.predict(np.expand_dims(subsample_sc.reshape(subsample_sc.shape[0],32,32),axis=3))\n",
    "print(\"Accuracy on subsample after: \", round(accuracy_score(subsample_y,np.argmax(y_pred_subsample,axis=1)),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean psnr 1.6\n",
      "Std psnr 0.558\n",
      "Min psnr 0.24\n",
      "Max psnr 3.331\n"
     ]
    }
   ],
   "source": [
    "psnr = PSNR(adversarial.reshape(adversarial.shape[0],32,32),evolved_examples.reshape(evolved_examples.shape[0],32,32))\n",
    "\n",
    "print(f\"Mean psnr {round(np.mean(psnr),3)}\")\n",
    "print(f\"Std psnr {round(np.std(psnr),3)}\")\n",
    "print(f\"Min psnr {round(np.min(psnr),3)}\")\n",
    "print(f\"Max psnr {round(np.max(psnr),3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
