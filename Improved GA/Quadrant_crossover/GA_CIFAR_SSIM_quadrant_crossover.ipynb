{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GA_CIFAR_SSIM_quadrant_crossover.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmqP9iw8qi2w",
        "colab_type": "text"
      },
      "source": [
        "# IMPORT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4o2nRW3uHkP",
        "colab_type": "text"
      },
      "source": [
        "In this notebook I did not normalized images before evolving, just when predicting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV-6sDntqd61",
        "colab_type": "code",
        "outputId": "17ca5e70-d828-4376-87e2-69afad4e5924",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.svm import SVC\n",
        "import pickle\n",
        "import time\n",
        "from skimage.measure import compare_ssim\n",
        "import tensorflow as tf\n",
        "from keras.models import Model,load_model\n",
        "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, Input, Activation\n",
        "from keras.utils import to_categorical\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGtAwbEMqmmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMYv1iroqpKy",
        "colab_type": "text"
      },
      "source": [
        "# GLOBAL VARS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JLxcgMPqoDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INDIVIDUALS = 50\n",
        "P_CROSS = 0.6\n",
        "P_MUTATION = 0.01\n",
        "CIFAR_IMG= 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhUutenzqt18",
        "colab_type": "text"
      },
      "source": [
        "# THE DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZTtcGJAJLuM",
        "colab_type": "code",
        "outputId": "06b09766-13ae-4802-a68e-3b5bef46a6c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "# The data, split between train and test sets:\n",
        "(x_train_C, y_train_C), (x_test_C, y_test_C) = cifar10.load_data()\n",
        "print('x_train shape:', x_train_C.shape)\n",
        "print(x_train_C.shape[0], 'train samples')\n",
        "print(x_test_C.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "num_classes=10\n",
        "epochs=10\n",
        "img_shape=32 \n",
        "y_train_C = to_categorical(y_train_C, num_classes)\n",
        "y_test_C = to_categorical(y_test_C, num_classes)\n",
        "\n",
        "\n",
        "input_shape=(32,32,1)\n",
        "\n",
        "x_train_C = x_train_C.astype('float32')\n",
        "x_test_C = x_test_C.astype('float32')\n",
        "x_train_C /= 255\n",
        "x_test_C /= 255\n",
        "\n",
        "\n",
        "print('x_train shape:', x_train_C.shape)\n",
        "print('Number of images in x_train', x_train_C.shape[0])\n",
        "print('Number of images in x_test', x_test_C.shape[0])\n",
        "print('y_train shape:', y_train_C.shape)\n",
        "print(\"input shape: \",input_shape)\n",
        "\n",
        "\n",
        "# CONVERT TO GRAY SCALE\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def grayscale(data, dtype='float32'):\n",
        "    # luma coding weighted average in video systems\n",
        "    r, g, b = np.asarray(.3, dtype=dtype), np.asarray(.59, dtype=dtype), np.asarray(.11, dtype=dtype)\n",
        "    rst = r * data[:, :, :, 0] + g * data[:, :, :, 1] + b * data[:, :, :, 2]\n",
        "    # add channel dimension\n",
        "    rst = np.expand_dims(rst, axis=3)\n",
        "    return rst\n",
        "\n",
        "x_train_C = grayscale(x_train_C)\n",
        "x_test_C = grayscale(x_test_C)\n",
        "\n",
        "# now we have only one channel in the images\n",
        "img_channels = 1\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "Number of images in x_train 50000\n",
            "Number of images in x_test 10000\n",
            "y_train shape: (50000, 10)\n",
            "input shape:  (32, 32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_--StA9kq4mw",
        "colab_type": "text"
      },
      "source": [
        "# READ PICKLE FILES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3glGbBeq2lz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('subset_cifar', 'rb') as f:\n",
        "    original = pickle.load(f)\n",
        "    adversarial= pickle.load(f)\n",
        "    original_y = pickle.load(f)\n",
        "    adversarial_y = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1LZoAPNq996",
        "colab_type": "code",
        "outputId": "7e1afde5-6d0a-4c39-a4d9-c00af27d5465",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(f\"Original shape {original.shape}\")\n",
        "print(f\"Adversarial shape {adversarial.shape}\")\n",
        "print(f\"Original labels shape {original_y.shape}\")\n",
        "print(f\"Adversarial labels shape {adversarial_y.shape}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original shape (914, 32, 32, 1)\n",
            "Adversarial shape (133, 32, 32, 1)\n",
            "Original labels shape (914, 1)\n",
            "Adversarial labels shape (133, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr0TMOV_q_9J",
        "colab_type": "text"
      },
      "source": [
        "# LOAD THE MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JibFPCmerJwW",
        "colab_type": "text"
      },
      "source": [
        "3. CNN v2\n",
        "\n",
        "This network is made for CIFAR 10. The network is taken from [this blog]( https://appliedmachinelearning.blog/2018/03/24/achieving-90-accuracy-in-object-recognition-task-on-cifar-10-dataset-with-keras-convolutional-neural-networks/) . In this version below I didn't use some things used in the blog e.g. z-score and data augmentation.\n",
        "\n",
        "\n",
        "This network has training accuracy: 0.8940 , validation accuracy: 0.8245.\n",
        "\n",
        "**NOTE:** Training really slow, try to avoid it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjDjKgyWJwqY",
        "colab_type": "code",
        "outputId": "dd0287a4-c00a-4dea-b3d9-8620c0c30b90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Network 3 \n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.datasets import cifar10\n",
        "from keras import regularizers\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "import numpy as np\n",
        "\n",
        "input_shape = (CIFAR_IMG,CIFAR_IMG,1)\n",
        "weight_decay = 1e-4\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=input_shape))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        " \n",
        "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        " \n",
        "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        " \n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='softmax'))\n",
        " \n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "'''\n",
        "history = model.fit(x=x_train_C,y=y_train_C, epochs=150, batch_size=64, validation_data=[x_test_C,y_test_C])\n",
        "\n",
        "score= model.evaluate(x_test_C, y_test_C,verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "model.save_weights(\"CNN_CIFAR10_net3.h5\")\n",
        "files.download('CNN_CIFAR10_net3.h5')\n",
        "'''\n",
        "\n",
        "model = load_model(\"CNN_CIFAR10_net3.h5\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        320       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 308,714\n",
            "Trainable params: 307,818\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGSQOJJprRG-",
        "colab_type": "text"
      },
      "source": [
        "# GENETIC ALGORITHM FUNCTIONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQuqZrKL4qqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def computing_SSIM(individual,target):\n",
        "    return compare_ssim(individual.reshape(CIFAR_IMG,CIFAR_IMG), target.reshape(CIFAR_IMG,CIFAR_IMG))\n",
        "\n",
        "def calculate_fitness(model,ind,target_image,label,l1=0.2, l2=0.8, N=50, num_classes=10):\n",
        "  # predict the population\n",
        "  predictions=model.predict(ind.reshape(1,CIFAR_IMG,CIFAR_IMG,1) / 255.0)  \n",
        "  # po is the ground truth prediction, so for label = 0, it will be prediciton[0]\n",
        "  predictions=predictions[0]\n",
        "  po=predictions[label]\n",
        "  # set that value to 0\n",
        "  predictions[label]=0\n",
        "  # take next highest one\n",
        "  pd = np.max(predictions)\n",
        "  diff=pd-po\n",
        "  return l1*computing_SSIM(ind.reshape(CIFAR_IMG,CIFAR_IMG),target_image.reshape(CIFAR_IMG,CIFAR_IMG)) +l2*(diff)\n",
        "  \n",
        "\n",
        "\n",
        "def pop_fitness(model,pop,target,label):\n",
        "    return [calculate_fitness(model, p, target, label) for p in pop]\n",
        "\n",
        "def flatten(imgs):\n",
        "    # flatten all images in np array or list\n",
        "    return np.array([im.flatten() for im in imgs])\n",
        "\n",
        "def gaussian_noise():\n",
        "    # draw one sample of noise from zero mean 1 variance Gaussian\n",
        "    return np.random.normal(0, 10)\n",
        "\n",
        "def p_noise(x):\n",
        "  if 0.01 > np.random.uniform():\n",
        "    return x + gaussian_noise()\n",
        "  else:\n",
        "    return x\n",
        "    \n",
        "def add_noise(image):\n",
        "    noise_v=np.vectorize(p_noise)\n",
        "    return noise_v(image) #np.array([x + gaussian_noise() if P_MUTATION > np.random.uniform(0.0, 1.0) else x+0 for x in image])\n",
        "\n",
        "def k_crossover(im1, im2, k=2):\n",
        "    c1, c2 = [], []\n",
        "    # get k crossover points\n",
        "    points = sorted([np.random.randint(0, CIFAR_IMG*CIFAR_IMG-1, 1) for p in range(k)])\n",
        "    points = sorted([np.random.randint(0,CIFAR_IMG*CIFAR_IMG-1,1) for p in range(k)])\n",
        "    im_1_split = np.split(im1, [int(p) for p in points])\n",
        "    im_2_split = np.split(im2, [int(p) for p in points])\n",
        "    \n",
        "    # alternate between lists to realise crossover (theres got to be a more clever way to do this)\n",
        "    for i in range(k+1):\n",
        "        if i % 2 == 0:\n",
        "            c1.append(im_1_split[i])\n",
        "            c2.append(im_2_split[i])\n",
        "        else:\n",
        "            c1.append(im_2_split[i])\n",
        "            c2.append(im_1_split[i])\n",
        "    return np.concatenate(c1, axis=0), np.concatenate(c2, axis=0)\n",
        "\n",
        "def tournament(pop, model, ground_truth, target, k=3):\n",
        "\n",
        "    indices = np.random.choice(range(len(pop)), k, replace=False) #we get 3 indxes [2 34 46]    \n",
        "    individuals = pop.take(indices,axis=0)\n",
        "    scores = pop_fitness(model,np.expand_dims(individuals.reshape(individuals.shape[0],CIFAR_IMG,CIFAR_IMG),axis=3), ground_truth.reshape(CIFAR_IMG,CIFAR_IMG), target)\n",
        "    index_max = np.argmax(scores)\n",
        "    winner = individuals[index_max]\n",
        "    return winner\n",
        "\n",
        "\n",
        "def check_adv_termination(ind, label,ground_truth, model):\n",
        "  # individual - the best one from the generation\n",
        "  # label - class we want\n",
        "  # ground_truth - the image (32,32)\n",
        "  # model we are using \n",
        "  dist = 1-compare_ssim(ind.reshape(CIFAR_IMG,CIFAR_IMG),ground_truth.reshape(CIFAR_IMG,CIFAR_IMG))\n",
        "  predictions= model.predict(ind.reshape(1,CIFAR_IMG,CIFAR_IMG,1)/255.0)\n",
        "  predicted_label= np.argmax(predictions[0])\n",
        "  if label != predicted_label and dist < 0.001:\n",
        "    print(\"FOUND ADVERSARIAL\")\n",
        "    print(f\"Fitness of the adversarial {calculate_fitness(model,ind,ground_truth,label)}\")\n",
        "    return ind\n",
        "  return []\n",
        "\n",
        "def init_pop_from_sample(n,img,label):\n",
        "    x = np.array([add_noise(img) for i in range(n)])\n",
        "    return x.reshape(n, CIFAR_IMG*CIFAR_IMG)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-epJQRlguXyK",
        "colab_type": "text"
      },
      "source": [
        "Functions from the past, just didn't want to erase them yet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlm5dKzOuXNw",
        "colab_type": "code",
        "outputId": "00d4613d-f533-4e7a-cce0-cd5ad53ee562",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''\n",
        "def check_adverserial(pop, model, fitness, target,ground_truth):\n",
        "    #print(f\"this is adversarial function\")\n",
        "    preds=model.predict(pop.reshape(pop.shape[0],28,28,1))\n",
        "    #print(f\"These are predictions made here {preds}\")\n",
        "    for ind, pr in zip(pop,preds): \n",
        "      #print(f\"prediction for an individual {pr}\")\n",
        "      preds=np.argmax(pr)\n",
        "      #print(f\"getting the index of highest value in predictions {preds}\")\n",
        "      #setting the value to 0\n",
        "      pr[0]=0\n",
        "      #print(f\"this is our target {target}\")\n",
        "      #print(f\"this is out ground_truth {ground_truth.shape}\")\n",
        "      fitness=computing_SSIM(ind.reshape(28,28),ground_truth.reshape(28,28))\n",
        "      #print(f\"these are the fitness values {fitness}\")\n",
        "      next_highest = np.argmax(pr)\n",
        "      #print(f\"getting the next highest value {next_highest}\")\n",
        "      if next_highest != target and fitness > 0.98:\n",
        "          return ind, True\n",
        "      return None, False\n",
        "\n",
        "def init_pop(n, num, data, labels):\n",
        "    indices = np.where(labels==num)[0]\n",
        "    n_indices = np.random.choice(indices, n, replace=True)\n",
        "    sample = np.take(data, n_indices, axis=0)\n",
        "    return sample, np.full((n), num, dtype=int) # return sample+array of labels\n",
        "\n",
        "\n",
        "Cyrils model\n",
        "\n",
        "def save_trained_model(model, filename='SVC_model.sav'):\n",
        "    pickle.dump(model, open(filename, 'wb'))\n",
        "    \n",
        "def load_trained_model(filename='SVC_model.sav'):\n",
        "    return pickle.load(open(filename, 'rb'))\n",
        "\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef check_adverserial(pop, model, fitness, target,ground_truth):\\n    #print(f\"this is adversarial function\")\\n    preds=model.predict(pop.reshape(pop.shape[0],28,28,1))\\n    #print(f\"These are predictions made here {preds}\")\\n    for ind, pr in zip(pop,preds): \\n      #print(f\"prediction for an individual {pr}\")\\n      preds=np.argmax(pr)\\n      #print(f\"getting the index of highest value in predictions {preds}\")\\n      #setting the value to 0\\n      pr[0]=0\\n      #print(f\"this is our target {target}\")\\n      #print(f\"this is out ground_truth {ground_truth.shape}\")\\n      fitness=computing_SSIM(ind.reshape(28,28),ground_truth.reshape(28,28))\\n      #print(f\"these are the fitness values {fitness}\")\\n      next_highest = np.argmax(pr)\\n      #print(f\"getting the next highest value {next_highest}\")\\n      if next_highest != target and fitness > 0.98:\\n          return ind, True\\n      return None, False\\n\\ndef init_pop(n, num, data, labels):\\n    indices = np.where(labels==num)[0]\\n    n_indices = np.random.choice(indices, n, replace=True)\\n    sample = np.take(data, n_indices, axis=0)\\n    return sample, np.full((n), num, dtype=int) # return sample+array of labels\\n\\n\\nCyrils model\\n\\ndef save_trained_model(model, filename=\\'SVC_model.sav\\'):\\n    pickle.dump(model, open(filename, \\'wb\\'))\\n    \\ndef load_trained_model(filename=\\'SVC_model.sav\\'):\\n    return pickle.load(open(filename, \\'rb\\'))\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOEo4wAfggNs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' my part of the code ''' \n",
        "''' I know it is ugly, I will fix it . this is the intial version'''\n",
        "# from Goorge Clooney paper\n",
        "def quadrant_crossover(parent_1,parent_2):\n",
        "\n",
        "  # reshape parents\n",
        "  parent_1,parent_2= parent_1.reshape((CIFAR_IMG,CIFAR_IMG)), parent_2.reshape((CIFAR_IMG,CIFAR_IMG))\n",
        "  # quadrants for both parents\n",
        "  p1,p2,p3,p4,q1,q2,q3,q4 = [],[],[],[],[],[],[],[]\n",
        "  child1, child2 = [],[]\n",
        "  # getting random (x,y) point in 2D matrix\n",
        "  x,y = np.random.randint(0,CIFAR_IMG-1), np.random.randint(0,CIFAR_IMG-1)  \n",
        "\n",
        "  # choose which quadrant we want to crossover\n",
        "  N = np.random.randint(0,3)\n",
        "  #make quadrants\n",
        "  for i in range(CIFAR_IMG):\n",
        "    if (i<=x):\n",
        "      p1.append(parent_1[i][:y+1])\n",
        "      p2.append(parent_1[i][y+1:])\n",
        "      q1.append(parent_2[i][:y+1])\n",
        "      q2.append(parent_2[i][y+1:])\n",
        "    else:\n",
        "      p3.append(parent_1[i][:y+1])\n",
        "      p4.append(parent_1[i][y+1:])\n",
        "      q3.append(parent_2[i][:y+1])\n",
        "      q4.append(parent_2[i][y+1:])\n",
        "\n",
        "  if (N==0):\n",
        "    ch1 = connect_quadrants(p1,q2,q3,q4)\n",
        "    ch2 = connect_quadrants(q1,p2,p3,p4)\n",
        "  elif (N==1):\n",
        "    ch1 = connect_quadrants(q1,p2,q3,q4)\n",
        "    ch2 = connect_quadrants(p1,q2,p3,p4)\n",
        "  elif (N==2):\n",
        "    ch1 = connect_quadrants(q1,q2,p3,q4)\n",
        "    ch2 = connect_quadrants(p1,p2,q3,p4)\n",
        "  else:\n",
        "    ch1 = connect_quadrants(q1,q2,q3,p4)\n",
        "    ch2 = connect_quadrants(p1,p2,p3,q4)\n",
        "\n",
        "  return ch1,ch2\n",
        "\n",
        "def connect_quadrants(q1,q2,q3,q4):\n",
        "  left = np.concatenate((q1,q3))\n",
        "  right = np.concatenate((q2,q4))\n",
        "  image = np.concatenate((left,right),axis=1)\n",
        "  return image.flatten()\n",
        "\n",
        "\n",
        "def multi_crossover(parent1,parent2,target):\n",
        "  pop= []\n",
        "  # 2-k crossover\n",
        "  pop.append(k_crossover(parent1, parent2))\n",
        "  # Gorge Clooney crossover\n",
        "  pop.append(quadrant_crossover(parent1,parent2))\n",
        "  # uniform crossover\n",
        "  pop.append(k_crossover(parent1, parent2,1))\n",
        "  # SSIM similarity \n",
        "  flattened_list = [y for x in pop for y in x] # need to flatten the list because pop is list of lists, cause every crossover function returns 2 obj\n",
        "  ssim = [computing_SSIM(ind,target) for ind in flattened_list ]\n",
        "  # taking the index of largest two score\n",
        "  id1=np.argmax(ssim)\n",
        "  ssim[id1]=0\n",
        "  id2 = np.argmax(ssim)\n",
        "  #returning parents\n",
        "  return flattened_list[id1],flattened_list[id2]\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7Z_4b8EqUmj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def return_best_individual(pop,fitness):\n",
        "  index = np.argmax(fitness)\n",
        "  best = pop[index]\n",
        "  return best, np.max(fitness)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcVTicSPvYoy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def choose_better_child(ch1, ch2,ground_truth,label,model):\n",
        "  # I named it better child, but we choose by this parents as well\n",
        "  ch1_f = calculate_fitness(model,ch1.reshape(CIFAR_IMG,CIFAR_IMG),ground_truth.reshape(CIFAR_IMG,CIFAR_IMG),label)\n",
        "  ch2_f = calculate_fitness(model,ch2.reshape(CIFAR_IMG,CIFAR_IMG),ground_truth.reshape(CIFAR_IMG,CIFAR_IMG),label)\n",
        "  # change this into ternary operator\n",
        "  if ch1_f>ch2_f:\n",
        "    return ch1\n",
        "  else:\n",
        "    return ch2              \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiXxgPDmriTE",
        "colab_type": "text"
      },
      "source": [
        "# THE MAIN LOOP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-8hS44GPb2B",
        "colab_type": "code",
        "outputId": "3661aaab-b99a-4560-cacf-0335b114d94b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "'''\n",
        "This not necessary when using subset \n",
        "'''\n",
        "'''\n",
        "X = flatten(x_train)\n",
        "X_t = flatten(x_test)\n",
        "print(f\"X train shape {X.shape}\")\n",
        "print(f\"X test shape {X_t.shape}\")\n",
        "print(f\"y train shape {y.shape}\")\n",
        "print(f\"y test shape {y_t.shape}\")\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nX = flatten(x_train)\\nX_t = flatten(x_test)\\nprint(f\"X train shape {X.shape}\")\\nprint(f\"X test shape {X_t.shape}\")\\nprint(f\"y train shape {y.shape}\")\\nprint(f\"y test shape {y_t.shape}\")\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r99NLfBt-ngX",
        "colab_type": "code",
        "outputId": "8685d05f-e1ee-4c0c-e8bb-c46349d8acbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        }
      },
      "source": [
        "# for each image and label in adversarial\n",
        "n=50\n",
        "import time\n",
        "# these are the examples that are found as adversarialwe will save these at the end in a file\n",
        "evolved_examples= []\n",
        "# fitness of the adversarials\n",
        "fitness_of_evolved=[]\n",
        "# time necessary to evolve the adversarial\n",
        "times=[]\n",
        "# the distance between the original image and the adversarial\n",
        "ssim_values=[]\n",
        "# number of round necessary to produce adversarial \n",
        "number_of_rounds=[]\n",
        "# this will serve to see if the fitness changes or not \n",
        "best_fitness = 0\n",
        "\n",
        "\n",
        "numb_of_found_after30=0\n",
        "numb_of_adv_found=0\n",
        "\n",
        "#dictionary to keep the best individual to check if the fitness is improving or not \n",
        "\n",
        "\n",
        "predicted_class= []\n",
        "for img,label in zip(adversarial,adversarial_y):\n",
        "  winner_of_gen = {\"image\":[],\"label\": None, \"fitness\": None}\n",
        "  #temporary variable to check generations:\n",
        "  fitness_no_change = 0\n",
        "  start = time.time()\n",
        "  label=label[0]\n",
        "  #intialize population from the image and with the given label\n",
        "  population = init_pop_from_sample(n,img,label)\n",
        "  # calculate fitness of these individuals\n",
        "  fitness = pop_fitness(model,np.expand_dims(population.reshape(population.shape[0],CIFAR_IMG,CIFAR_IMG),axis=3),img.reshape(CIFAR_IMG,CIFAR_IMG),label)\n",
        "  print(f\"Initial fitness: \\n {fitness}\")\n",
        "  #retun the best one from the population\n",
        "  best,fit_max = return_best_individual(population,fitness)\n",
        "  #check if adversarial\n",
        "  check_adv = check_adv_termination(best,label,img, model)\n",
        "  #define max generation\n",
        "  max_gen=0\n",
        "\n",
        "  while (len(check_adv)==0 or max_gen<10000):\n",
        "      new_pop=[]\n",
        "      for i in range(50):\n",
        "        parent1= tournament(population, model, img, label) \n",
        "        parent2 = tournament(population, model, img, label)\n",
        "        if 0.8 > np.random.uniform(0.0, 1.0):\n",
        "          child1, child2 = quadrant_crossover(parent1, parent2) # crossover\n",
        "          new_pop.append(add_noise(choose_better_child(child1, child2,img,label,model)))\n",
        "        else:\n",
        "          new_pop.append(add_noise(choose_better_child(parent1, parent2,img,label,model)))\n",
        "\n",
        "      # to reshape into an array \n",
        "      population= np.array(new_pop)\n",
        "      #check fitness of the generation\n",
        "      fitness = pop_fitness(model,np.expand_dims(population.reshape(population.shape[0],CIFAR_IMG,CIFAR_IMG),axis=3),img.reshape(CIFAR_IMG,CIFAR_IMG),label) \n",
        "      #find the highest fitness\n",
        "      best,fit_max1 = return_best_individual(population,fitness)\n",
        "      # check adversarial - check if pred != target, distance < 0.001 or fitness didn't improve 0.001 after 30 generations(this is in else condition)\n",
        "      check_adv = check_adv_termination(best,label,img,model)\n",
        "\n",
        "      #check if the first termination true \n",
        "      if(len(check_adv) != 0):\n",
        "        print(\"Adversarial example image: \\n\")\n",
        "        evolved_examples.append(check_adv) #add evolved example\n",
        "        ssim_values.append(1-compare_ssim(check_adv.rehspe(CIFAR_IMG,CIFAR_IMG),img.reshape(CIFAR_IMG,CIFAR_IMG))) #add the distance\n",
        "        end=time.time()\n",
        "        times.append(end-start) #add the time \n",
        "        fitness_of_evolved.append(calculate_fitness(model,check_adv,img,label)) #add the fitness value of adversarial\n",
        "        number_of_rounds.append(max_gen)\n",
        "        pred_l=np.argmax(model.predict(check_adv.reshape(1,CIFAR_IMG,CIFAR_IMG,1)/255.0))\n",
        "        predicted_class.append(pred_l)\n",
        "        print(\"Left: adversarial \\t Right: ground truth\")\n",
        "        fd, idx = plt.subplots(1,2)\n",
        "        idx[0].imshow(check_adv.reshape(CIFAR_IMG,CIFAR_IMG),cmap='gray')\n",
        "        idx[1].imshow(img.reshape(CIFAR_IMG,CIFAR_IMG),cmap='gray')\n",
        "        plt.show()\n",
        "        print(f\"True label: {label}\")\n",
        "        print(f\"predicted label: {pred_l}\") \n",
        "        print(\"Time: \",end-start ,\" seconds\")\n",
        "        numb_of_adv_found+=1\n",
        "        break\n",
        "      #check the second termination \n",
        "      else:\n",
        "          #check if fitness increases, if not , add +1 to temporary var\n",
        "        if fit_max1>fit_max:\n",
        "          fit_max=fit_max1\n",
        "          winner_of_gen.update(image= best)\n",
        "          winner_of_gen.update(label= label)\n",
        "          winner_of_gen.update(fitness= fit_max1)\n",
        "          fitness_no_change=0\n",
        "        else:\n",
        "          fitness_no_change+=1\n",
        "      \n",
        "      #print after every 10 generations to see the progress\n",
        "      if (max_gen % 10 == 0):\n",
        "        print(f\"Generation {max_gen}\")\n",
        "        print(f\"Max fitness value {fit_max}\")\n",
        "      max_gen+=1\n",
        "\n",
        "      # if fitness did not improve for 30 generations, save the image that was best , saved it in a dicitonary\n",
        "      if fitness_no_change==30:\n",
        "        print(\"FITNESS DID NOT IMPROVE FOR 30 GENERATIONS\")\n",
        "        print(\"Best adversarial image we could find: \\n\")\n",
        "        evolved_examples.append(winner_of_gen[\"image\"])\n",
        "        ssim_values.append(1-compare_ssim(np.array(winner_of_gen[\"image\"]).reshape(CIFAR_IMG,CIFAR_IMG),img.reshape(CIFAR_IMG,CIFAR_IMG)))\n",
        "        number_of_rounds.append(max_gen)\n",
        "        end=time.time()\n",
        "        times.append(end-start)\n",
        "        fitness_of_evolved.append(winner_of_gen[\"fitness\"])\n",
        "        pred_l=np.argmax(model.predict(np.array(winner_of_gen[\"image\"]).reshape(1,CIFAR_IMG,CIFAR_IMG,1)/255.0))\n",
        "        predicted_class.append(pred_l)\n",
        "        print(\"Left: adversarial \\t Right: ground truth\")\n",
        "        fd, idx = plt.subplots(1,2)\n",
        "        idx[0].imshow(np.array(winner_of_gen[\"image\"]).reshape(CIFAR_IMG,CIFAR_IMG),cmap='gray')\n",
        "        idx[1].imshow(img.reshape(CIFAR_IMG,CIFAR_IMG),cmap='gray')\n",
        "        plt.show()\n",
        "        print(f\"True label: {label}\")\n",
        "        print(f\"predicted label: {pred_l}\")\n",
        "        print(\"Time: \",end-start ,\" seconds\")\n",
        "        numb_of_found_after30 +=1\n",
        "        break\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Initial fitness: \n",
            " [-0.6010976456294307, -0.6022689701523863, -0.602735085941775, -0.600263577518728, -0.6004837724653709, -0.6001231147149579, -0.6004651497793057, -0.6005222574354647, -0.5998941929190198, -0.6034711283498593, -0.6032364779574653, -0.6017120308282579, -0.6027275385881912, -0.6013435297556654, -0.6007687433088569, -0.6007116198844941, -0.6045636483108575, -0.6013854053890274, -0.6003963202277068, -0.602256690671736, -0.6008555136517845, -0.6000661861240545, -0.6002978818096093, -0.600411770646208, -0.602347152632159, -0.6010247078277335, -0.6003311551125605, -0.6024765107085656, -0.6014261367251998, -0.6004568278739513, -0.6002165397766208, -0.6007035253772012, -0.6019765282742845, -0.6018680460156803, -0.6010888438668501, -0.601701768908935, -0.5998234114610749, -0.600542318833699, -0.6013584281022999, -0.6001534594812556, -0.6018259178867369, -0.6006751201175372, -0.6003416806244822, -0.6008784457132075, -0.6008489912861967, -0.6031788222475647, -0.6007272496199317, -0.603386702572797, -0.5998847547580053, -0.6012337369670537]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:74: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 0\n",
            "Max fitness value -0.5998234114610749\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/measure/_structural_similarity.py:17: UserWarning: Inputs have mismatched dtype.  Setting data_range based on im1.dtype.\n",
            "  **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 10\n",
            "Max fitness value -0.2092300900118719\n",
            "Generation 20\n",
            "Max fitness value 0.9690052197033905\n",
            "Generation 30\n",
            "Max fitness value 0.9714973333452399\n",
            "Generation 40\n",
            "Max fitness value 0.9720817110292501\n",
            "Generation 50\n",
            "Max fitness value 0.9727539288863118\n",
            "Generation 60\n",
            "Max fitness value 0.9727539288863118\n",
            "Generation 70\n",
            "Max fitness value 0.9730438725139803\n",
            "Generation 80\n",
            "Max fitness value 0.9730438725139803\n",
            "Generation 90\n",
            "Max fitness value 0.9730438725139803\n",
            "FITNESS DID NOT IMPROVE FOR 30 GENERATIONS\n",
            "Best adversarial image we could find: \n",
            "\n",
            "Left: adversarial \t Right: ground truth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:134: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "True label: 0\n",
            "predicted label: 2\n",
            "Time:  231.70782327651978  seconds\n",
            "Initial fitness: \n",
            " [-0.48622379010637495, -0.5439337374844601, -0.42773517246128434, -0.5302037573714499, -0.5079860545827883, -0.5008313774115405, -0.4800257889835421, -0.49472101859386597, -0.44224987998031484, -0.5124167960747891, -0.5437820776264932, -0.4442677775951278, -0.49101346847251737, -0.5106837714997077, -0.49620921398386486, -0.523387280797339, -0.562502000331222, -0.4879150719728623, -0.4750806979608897, -0.5056282208683844, -0.5213454523445296, -0.4792421179296522, -0.507027451240475, -0.5002687300482511, -0.48790276693540024, -0.521736159059263, -0.5135958828122484, -0.4455860830392424, -0.500595549088564, -0.5504735545977997, -0.45787015599565106, -0.5378466423098346, -0.4590451047392202, -0.4820391633104478, -0.4693870184358587, -0.4622230330415975, -0.5105102920034233, -0.5146691764845727, -0.4398960281979063, -0.4654981700160424, -0.4339285312503377, -0.5370728951716593, -0.527158486613633, -0.47083027258204413, -0.5204621483150628, -0.4614868997096586, -0.5396127803154059, -0.5216759523294363, -0.5305950769205132, -0.5404695759469992]\n",
            "Generation 0\n",
            "Max fitness value -0.24985655837860624\n",
            "Generation 10\n",
            "Max fitness value 0.9335856097730612\n",
            "Generation 20\n",
            "Max fitness value 0.9940046188401017\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEMXgasB3Llv",
        "colab_type": "text"
      },
      "source": [
        "# Save files\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u43v4fe33RGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "file_ = open('GA_adv_cifar_QUADRANT_multicrossover', 'wb')\n",
        "pickle.dump(evolved_examples, file_)\n",
        "pickle.dump(times, file_)\n",
        "pickle.dump(ssim_values, file_)\n",
        "pickle.dump(fitness_of_evolved , file_)\n",
        "pickle.dump(predicted_class, file_)\n",
        "pickle.dump(number_of_rounds, file_)\n",
        "file_.close()\n",
        "\n",
        "print(f\"Max time: {np.max(times)}\")\n",
        "print(f\"Min time: {np.min(times)}\")\n",
        "print(f\"Mean time: {np.mean(times)}\")\n",
        "print(f\"Std time: {np.std(times)}\\n\")\n",
        "\n",
        "print(f\"Max fitness evolved: {np.max(fitness_of_evolved)}\")\n",
        "print(f\"Min fitness evolved:: {np.min(fitness_of_evolved)}\")\n",
        "print(f\"Mean fitness evolved: {np.mean(fitness_of_evolved)}\")\n",
        "print(f\"Std fitness evolved:: {np.std(fitness_of_evolved)}\\n\")\n",
        "\n",
        "print(f\"Max ssim: {np.max(ssim_values)}\")\n",
        "print(f\"Min ssim: {np.min(ssim_values)}\")\n",
        "print(f\"Mean ssim: {np.mean(ssim_values)}\")\n",
        "print(f\"Std ssim: {np.std(ssim_values)}\\n\")\n",
        "\n",
        "print(f\"Max ssim: {np.max(number_of_rounds)}\")\n",
        "print(f\"Min ssim: {np.min(number_of_rounds)}\")\n",
        "print(f\"Mean ssim: {np.mean(number_of_rounds)}\")\n",
        "print(f\"Std ssim: {np.std(number_of_rounds)}\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Percentage of adversarial founds sucessfully : {numb_of_adv_found/len(adversarial_y)} %\")\n",
        "print(f\"Percentage of adversarial founds after fitness not improving for 30 generations: {numb_of_found_after30/len(adversarial_y)} %\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQoHNMX_8nor",
        "colab_type": "text"
      },
      "source": [
        "Open adversarial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEK7GsD78oq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('GA_adv_cifar_QUADRANT_multicrossover', 'rb') as f:\n",
        "    evolved_examples = pickle.load(f)\n",
        "    times= pickle.load(f)\n",
        "    ssim_values = pickle.load(f)\n",
        "    fitness_of_evolved = pickle.load(f)\n",
        "    predicted_class = pickle.load(f)\n",
        "    number_of_rounds = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e9R7ACErtqK",
        "colab_type": "text"
      },
      "source": [
        "# Examples of what functions do"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpEVAzR7rtK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "population = init_pop_from_sample(50,adversarial[15],adversarial_y[15][0])\n",
        "fitness = pop_fitness(model,np.expand_dims(population.reshape(population.shape[0],CIFAR_IMG,CIFAR_IMG),axis=3),img.reshape(CIFAR_IMG,CIFAR_IMG),adversarial_y[15][0])\n",
        "print(fitness)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aYxCQLEu1BB",
        "colab_type": "code",
        "outputId": "6a29e5dc-27d0-4479-81b7-6e1288329285",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "plt.imshow(population[0].reshape(CIFAR_IMG,CIFAR_IMG))\n",
        "plt.show()\n",
        "print(f\"Class for this {adversarial_y[15][0]}\")\n",
        "print(model.predict(population[0].reshape(1,CIFAR_IMG,CIFAR_IMG,1) /255.0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Class for this 1\n",
            "[[2.2063480e-10 1.0000000e+00 6.6041472e-14 3.5760719e-12 3.9276270e-13\n",
            "  1.1313486e-13 8.8119643e-13 6.8588521e-13 1.9681285e-13 3.7839783e-08]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhxCaFZPGPpe",
        "colab_type": "code",
        "outputId": "35163672-1426-46f3-d021-b87dc280c722",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "parent1 = tournament(population, model, adversarial[15], adversarial_y[15]) \n",
        "parent2 = tournament(population, model, adversarial[15], adversarial_y[15])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/measure/_structural_similarity.py:17: UserWarning: Inputs have mismatched dtype.  Setting data_range based on im1.dtype.\n",
            "  **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gORkePYLv4EW",
        "colab_type": "code",
        "outputId": "17422d1a-b936-43f2-a2c2-33f4cb500bf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "fd, idx =  plt.subplots(1,2)\n",
        "idx[0].imshow(parent1.reshape(CIFAR_IMG,CIFAR_IMG),cmap=\"gray\")\n",
        "idx[1].imshow(parent2.reshape(CIFAR_IMG,CIFAR_IMG),cmap=\"gray\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8f5ea68dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZJXShUyHIrS",
        "colab_type": "code",
        "outputId": "c26ae352-d1a1-4510-9da7-ae5e01d1ec43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "child1, child2 = multi_crossover(parent1, parent2,adversarial[15]) # crossover \n",
        "#child1, child2 = add_noise(child1), add_noise(child2) # apply mutation to pixels "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/measure/_structural_similarity.py:17: UserWarning: Inputs have mismatched dtype.  Setting data_range based on im1.dtype.\n",
            "  **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72tQ7R_RHZzZ",
        "colab_type": "code",
        "outputId": "c81cdb63-ed10-42c2-d477-894c5e91bcf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "fd, idx =  plt.subplots(1,2)\n",
        "idx[0].imshow(child1.reshape(CIFAR_IMG,CIFAR_IMG),cmap=\"gray\")\n",
        "idx[1].imshow(child2.reshape(CIFAR_IMG,CIFAR_IMG),cmap=\"gray\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8f5e585550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAC5CAYAAAAxiWT3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAXMElEQVR4nO3dbaxV1ZkH8P9fXhSEFuHycnkRxJAxpGGo3kCNrajVaeMX22Qy6iSNJjY0kzGxmX4o7SQzncl8aCd9+dK0DY1ETRgZZ6zRNs500Dg2WkN7W0BBUdCAgLyIb4AvCPjMh7OZe89az7ln3X322ees+v8lN/fuxTp7r3Pu43Lf9ey1Fs0MIiKSn/N63QARESlHHbiISKbUgYuIZEoduIhIptSBi4hkSh24iEimOurASX6R5Isk95BcV1WjRHpNsS05YNnnwElOAPASgBsAHADwewC3mtnz1TVPpH6KbcnFxA5euwrAHjN7BQBIbgJwE4CWQT5r1ixbvHhxU5n3PxCSHTSr/6S+H02qai0lTvbt24c33nijiuBRbCdSbHeuk9jupANfAGD/qOMDAFaP9YLFixfjySefbCrzGn/eeeVGdlKCxAs473offfRRqTZ4Jk5M+5irvGaVut2ulAD22hDWWbNmTVVNUmwnUmyPrdux3fUkJsm1JIdJDh87dqzblxOpjWJbeq2TDvwggEWjjhcWZU3MbL2ZDZnZ0MDAQAeXE6mNYluy0MkQyu8BLCN5CRrBfQuAvx7rBSQxefLkprK6xwm9c6eWdZDwLfW6VKntKvvnYtk/+73rpfy5CKS9p7BOheOsiu0OrlklxfbYryndgZvZGZJ3Avg1gAkANpjZzrLnE+kXim3JRSd34DCzRwE8WlFbRPqGYltyoJmYIiKZUgcuIpKpjoZQxsvMcPr06Tov+bGQmsApkzzptF7K61KSfVW2vRsU292h2B67ju7ARUQypQ5cRCRT6sBFRDJV+xj4mTNnorJQletFhONN3V58J3XiRJVSz1/2s/BUOUmlqvUiysZNFRTb3aHYbmgVN7oDFxHJlDpwEZFMqQMXEcmUOnARkUzVmsQkiQkTJjSVlU0YVJk8SU0secmG8LXeuVIf8K9b6kppqausVdmOlDr9tLuNYnvssrp9XGJbd+AiIplSBy4ikil14CIimepoDJzkXgAnAJwFcMbMhqpolEivKbYlB1UkMa81s+QdXcNET0rypEreuVMTHinJhrIzx/pFL9qVsuJcjz4vxXabOh7F9ohux7aGUEREMtVpB24A/ofkH0iuraJBIn1CsS19r9MhlM+a2UGScwBsJrnLzH4zukIR/GsBYNGiRR1eTqQ2im3pex3dgZvZweL7UQAPAVjl1FlvZkNmNjQwMNDJ5URqo9iWHJS+Ayd5IYDzzOxE8fNfAPjnKhpVdlC/yllPnSR/QqmJq27PYAvPn3q91Bl4KVJ/t2Hyp8olPttRbKdfU7E9ohex3ckQylwADxUXmgjg38zsvzs4n0i/UGxLFkp34Gb2CoA/r7AtIn1BsS250GOEIiKZ6vlqhK3qVXnNdjoZn6tybK/b50qZVJCq7LnKvseUVe96uQqeYru35/q4xrbuwEVEMqUOXEQkU+rARUQypQ5cRCRTtSYxzQynT59uKiu7YlvqBIKyK6r1QpVt7fbEl5QJEJ0km8Lz9/GKhQAU2+0otlufv5PY1h24iEim1IGLiGRKHbiISKbUgYuIZKrWJCaQlqCZOLG5WalbRZW9XuoMqrIz37q9FVVqQqVsIqnKmW+pCbqURE83tycrQ7Hd2flTr6nYHlUvqZaIiPQddeAiIplSBy4ikqm2HTjJDSSPktwxqmwmyc0kdxffL+puM0Wqp9iW3KUkMe8B8GMA940qWwfgcTP7Lsl1xfE3252IZDQ47w3Wp9RJdfbs2bZ1UreYSuEtKeqd30tcnDlzpqvXTGmDp5NEW8rrvHaEZVW2YZR7oNhOptgeWy9iu230FDtxvxkU3wTg3uLnewF8KelqIn1EsS25K/u//7lmdqj4+TAaewiK/ClQbEs2Ok5iWuPvsZZ/k5FcS3KY5PDrr7/e6eVEaqPYln5XtgM/QnIQAIrvR1tVNLP1ZjZkZkOzZ88ueTmR2ii2JRtlZ2I+AuA2AN8tvj+c+sIwKeElVMJB/U6SVWWTRF7yIVwu1Cs7depUVCc1gTNp0qSm49TkRkqyDIhnAU6ePDnpdSm/o1b1UuqkJNq830eX9sBUbLcoU2yPrRexnfIY4f0AngHwZyQPkLwDjeC+geRuANcXxyJZUWxL7tregZvZrS3+6fMVt0WkVoptyZ1mYoqIZKrW1Qi9yQ4p40bemJQ39vbGG29EZceOHWs6fvvtt6M6H374YdL5w3E2IB5rmzZtWlRn6tSpSdc8ceJE0/G7774b1Tl+/HhU5j0B8f7770dlF154YdPxnDlzojqf+tSnorKFCxdGZWVXr0td/S0sSzlXl8bEkyi2x76mYrt1WSexrTtwEZFMqQMXEcmUOnARkUypAxcRyVStSUwzK71dUShM4ADAfffdF5Vt3bq17bmmT58elXkrvQ0MDERlYULFS5R84QtfSGrXli1bmo73798f1fnkJz8ZlXkJLq/9F198cdPxm2+G6zgBmzdvjspuueWWqGzVqlVRWZhoKbvFlMd7P+H1KlidsDTF9tjtUmy31kls6w5cRCRT6sBFRDKlDlxEJFPqwEVEMlVrEhOIB+PLrvLlJUo2bdoUlYUztK655pqoTrhSGhDPHAOAWbNmRWUPPPBA07GXdPGSIl69V199tel427ZtUZ3rr78+KluxYkVU5n1mS5cubTr23uNzzz0XlW3YsCEq++CDD6Kyyy67rOnYS4x5q8SVnYnWT0lM7/qK7RGK7dZlncS27sBFRDKlDlxEJFPqwEVEMpWyocMGkkdJ7hhV9h2SB0luK75u7G4zRaqn2JbcpSQx7wHwYwDhVLAfmdn3x3Mxb8lNbxZSuDXVwYMHozoPPfRQVPbKK69EZeHsMS+ps3379qjMS8TMnz8/Ktu3b1/T8eWXXx7V8ZbXDJMuAHDgwIExzw34y3BecMEFUVmY4ALiz9Wrc8UVV0RlTz/9dFT2k5/8JCr76le/2nR81VVXRXW8z98TJm26lKC8B4ptAIrt0XKK7bZ34Gb2GwDxvFSRzCm2JXedjIHfSfLZ4s/Qi1pVIrmW5DDJYW9xdpE+pNiWLJTtwH8K4FIAKwEcAvCDVhXNbL2ZDZnZ0OzZs0teTqQ2im3JRqmJPGZ25NzPJH8O4FdlG+CN/5w+fbrpOFzJDABefvnlqGzZsmVR2fnnn990vHv37qiOtxWVNx7nTbB477332r7urbfeisq8ldc+97nPNR0vWbIkquONs3lbXU2ZMqVtPW9rLc8nPvGJqOz++++Pyg4fPtx07G195Y2Zem0NJ0XUNUlHsT1CsT2iX2O71B04ycFRh18GsKNVXZGcKLYlJ23vwEneD+AaAAMkDwD4RwDXkFwJwADsBfC1LrZRpCsU25K7th24md3qFN/dhbaI1EqxLbnTTEwRkUzVvhphyFuJ66WXXmo6DhM/AHDzzTdHZV698IH+qVOnRnW8rbC8RJI3wWLBggVNx96Ei40bN0Zl3kSA1atXNx17TzZ4k0O8JIj3uYafj7d62sSJcUh4kyK8VejCet7WYJ6ZM2dGZeEEjtS29hPF9gjF9ogqY1t34CIimVIHLiKSKXXgIiKZUgcuIpKp2rNA4Ypt3spov/3tb5uOveTMvHnzorLjx49HZeFMKy9hcOrUqajM25LJm1UVnv/kyZNRnR074rkg3upv4ZZSXgJn7969Udmbb8brMXmJnnD2WPi7APyZb169Sy+9NCoLf0+vvfZaVMebpReuJAcAu3btajr2Pi9vNl8v1R3b06dPbzoOZ2YCH5/YDrdB887/pxjbugMXEcmUOnARkUypAxcRyZQ6cBGRTPV8Kpu3LGM4I8ur480w82ZyhQvte8tHeq8bHByMym644YaoLEwIeQkiL+myaNGiqCycIffqq69GdcLEFeAvnRkuBeq1w0uweG31Ej2e8Jre7807/1NPPRWVPfbYY03HN94Yb015++23tz13L3U7tsPZgIrtEVXHdvh76pfY1h24iEim1IGLiGSqbQdOchHJJ0g+T3InybuK8pkkN5PcXXxvuXegSD9SbEvuUu7AzwD4hpktB/AZAH9LcjmAdQAeN7NlAB4vjkVyotiWrKVs6HAIjc1dYWYnSL4AYAGAm9DYzQQA7gXwvwC+Od4GePvIecmMkJfo8YSz07zlHb1EhjeryttfMJxt98477ySd32v/L3/5y6bjnTt3RnUWLlwYlV199dVRmZdkCXmJHi9p5NXzysKEmVfHm223ffv2qCxsv1cn/KxT90E8R7E9QrE9dlm/xva4xsBJLgHwaQBbAMwt/gMAgMMA5o7nXCL9RLEtOUruwElOA/AggK+bWdPCDNZ4xsV9zoXkWpLDJIfDR/pE+oFiW3KV1IGTnIRGgG80s18UxUfO7eBdfD/qvdbM1pvZkJkNebtwiPSSYltylrIrPdHY6PUFM/vhqH96BMBtAL5bfH845YLh+Jg3nhWO7XmrrHkTFLyH3cMVyLwtlLxzeWN73rZW4Wpv3vifdy5ve6pwu61Zs2ZFdfbv3590rqVLl0ZlYfvDrZ0Af2zPa79XL1wBzvtcDx06FJV5Y6szZsxo24ZwdbzUseNzFNsjFNtj1+vX2E6ZiXkVgK8AeI7ktqLs22gE9wMk7wCwD8BfJZxLpJ8otiVrKU+hPAUgXly34fPVNkekPoptyZ1mYoqIZEoduIhIpmpdjdDMosF/b9upw4cPNx17CYlJkyZFZRMnxm8nHPxPnVyRukpZmNzwkg1eIsNL2ISrvXmJHm8SRrgqHQBceeWVUVm4nZz3Hr0yL2HjCT8Lb9U47/P3trkLn+rwft/h5IZerkao2B6h2G7dLqDa2NYduIhIptSBi4hkSh24iEim1IGLiGSq9i3VwkTIM888E9V59NFHm46nTJkS1fESEl4yIHztRRfFSzvPmzcvKvMSEkeOHInKli1b1nQ8derUqI63kpi3+lvY1jlz5iS9zpvx521ZFSbCxjtzcTTv8w/P781o85I/XiIpnFUYJpGA+HfU6y3VFNsNiu0R3Y5t3YGLiGRKHbiISKbUgYuIZEoduIhIpmpPYoaD8R988EFUJ5y15SVKvOUvvWRAmJDwkjXekpVeu7xZYWHi4tprr43qeAmId999NyoLEz1eosRLZnmfhZeoChMq3uflSU0OhokjL5Hkfa7hsqhAvJyml+wLP/tOEldVUGw3KLZHdDu2dQcuIpIpdeAiIplq24GTXETyCZLPk9xJ8q6i/DskD5LcVnzd2P3milRHsS25SxkDPwPgG2b2R5LTAfyB5Obi335kZt/vXvNEukqxLVlL2ZHnEIBDxc8nSL4AYEGZi5lZlJS4+OKL3XqjeQkWL7nhCfccnDlzZlTHS6ikJpf27dvXdOwtr+mVebPOwpl0XuLCSxCFiTEAeO2116KycCadt0SpV+YlhLzkT5hUO3DgQFRn69atUdncuXOjspA3c++tt95qOk5dGvQcxfbY11Rsj+jX2B7XGDjJJQA+DWBLUXQnyWdJbiAZz+MVyYRiW3KU3IGTnAbgQQBfN7PjAH4K4FIAK9G4i/lBi9etJTlMcti72xDpNcW25CqpAyc5CY0A32hmvwAAMztiZmfN7CMAPwewynutma03syEzGxoYGKiq3SKVUGxLztqOgbMxSHQ3gBfM7IejygeLMUQA+DKAHe3OderUKezdu7epzBsjmjFjRtPxrl27ojqp2yOtWLGi6XjNmjVJ5/Ieyg/HpYB4jNFbPS0cSwT87bbC9+3V8cYJvS2svDHNcBsrb7uncFwV8MdRvdeG24N5bfUmYXif/+DgYNNxuA0VEI+PjncMXLE9QrE99mv7NbZTnkK5CsBXADxHcltR9m0At5JcCcAA7AXwtYRzifQTxbZkLeUplKcAePNSH3XKRLKh2JbcaSamiEim1IGLiGSq1tUIP/zwwyjR4yUkli9f3nS8ffv2qI43gcBLGIQPyXtPC3htSJ0IECZ2vAf8jx49GpV5iaRwAkRqu7wVz7yV3cKyMDED+Ime1IRQWG/p0qVRnQUL4nky3u8tnJQSbkMFxBNSermlmmJ7hGJ7RLdjW3fgIiKZUgcuIpIpdeAiIplSBy4ikqlak5hnz56NEjTh1kFAnJxZvXp1VMfbPspLboSrlO3Zsyeq462M5iVZvHrhamZe0uKSSy6JyryEU5jMmD9/flRn+vTpUdnKlSujspREjPd5eUkd7z15ZWGiJeXzaiWs581EC8t6mcRUbI9QbI+tytjWHbiISKbUgYuIZEoduIhIptSBi4hkqtYkppklDc6HM5Wuu+66qI6XiElJSKQmGlKTG+FylN7ylKnJtfD8XiLGm63m8d5nWJZSB0hvf0o9r05qWT9TbI/vmortaugOXEQkU+rARUQy1bYDJ3kByd+R3E5yJ8l/KsovIbmF5B6S/04yfshSpI8ptiV3KYNOpwBcZ2Yni/0DnyL5XwD+DsCPzGwTyZ8BuAONzWBbMrPoAXjv4fqwzHvA3xuzSxnj8safvIfyvXqp42rdVHayABC/p9RzlR3nTJkQAfiff9k2jJNie4zzK7ZH9Gtst70Dt4aTxeGk4ssAXAfgP4vyewF8qXQrRHpAsS25S92VfkKxZ+BRAJsBvAzgbTM7t2jtAQDxYrgifU6xLTlL6sDN7KyZrQSwEMAqAJelXoDkWpLDJIdPnjzZ/gUiNVJsS87G9RSKmb0N4AkAVwKYQfLcGPpCAAdbvGa9mQ2Z2ZC3u4ZIP1BsS47aJjFJzgZw2szeJjkFwA0AvodGsP8lgE0AbgPwcMK5kh64T0lIlJ204L0u3L4I8JMPqRMgUnQ7QeSdP5xokvq5pr7HlPfkJWy884eff0oyaLwU263P1aoshWJ77PNXGdspT6EMAriX5AQ07tgfMLNfkXwewCaS/wJgK4C7S7dCpDcU25K1th24mT0L4NNO+StojBmKZEmxLbnTTEwRkUypAxcRyRTrXPWN5OsA9gEYAHCstgtXL+f259x2YOz2Lzaz2XU25hzFdl/Iue1AidiutQP//4uSw2Y2VPuFK5Jz+3NuO9D/7e/39rWTc/tzbjtQrv0aQhERyZQ6cBGRTPWqA1/fo+tWJef259x2oP/b3+/tayfn9ufcdqBE+3syBi4iIp3TEIqISKZq78BJfpHki8VuJ+vqvv54kdxA8ijJHaPKZpLcTHJ38f2iXraxFZKLSD5B8vlix5m7ivK+b39uu+UoruuTc1wDFce2mdX2BWACGustLwUwGcB2AMvrbEOJNl8N4HIAO0aV/SuAdcXP6wB8r9ftbNH2QQCXFz9PB/ASgOU5tB8AAUwrfp4EYAuAzwB4AMAtRfnPAPxNH7RVcV1v27ON66JtlcV23Q2/EsCvRx1/C8C3ev2BJrR7SRDoLwIYHBVML/a6jYnv42E0VtzLqv0ApgL4I4DVaEx0mOjFUw/bp7ju7fvIMq6LdnYU23UPoSwAsH/Uca67ncw1s0PFz4cBzO1lY1KQXILGwk1bkEn7M9otR3HdIznGNVBdbCuJ2SFr/O+yrx/lITkNwIMAvm5mx0f/Wz+33zrYLUc6089xcU6ucQ1UF9t1d+AHASwaddxyt5M+d4TkIAAU34/2uD0tsbHb+oMANprZL4ribNoPlNstp2aK65r9KcQ10Hls192B/x7AsiLbOhnALQAeqbkNVXgEjZ1agMQdW3qBjW1E7gbwgpn9cNQ/9X37Sc4mOaP4+dxuOS9gZLccoH/arriuUc5xDVQc2z0YtL8RjazxywD+vtdJhIT23g/gEIDTaIxL3QFgFoDHAewG8BiAmb1uZ4u2fxaNPyOfBbCt+Loxh/YDWIHGbjjPAtgB4B+K8qUAfgdgD4D/AHB+r9tatEtxXV/bs43rov2VxbZmYoqIZEpJTBGRTKkDFxHJlDpwEZFMqQMXEcmUOnARkUypAxcRyZQ6cBGRTKkDFxHJ1P8B29KZfI7fD8IAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a3pXLQSwZlT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"diff between children {np.unique(child1-child2)}\")\n",
        "print(f\"diff between parents {np.unique(parent1-parent2)}\")\n",
        "print(f\"diff between p1 and c1 {np.unique(parent1-child1)}\")\n",
        "print(f\"diff between p1 and c2 {np.unique(parent1-child2)}\")\n",
        "print(f\"diff between p2 and c1 {np.unique(parent2-child1)}\")\n",
        "print(f\"diff between p2 and c2 {np.unique(parent2-child2)}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEPQapUpILBr",
        "colab_type": "code",
        "outputId": "ac694765-e044-4f9f-82ee-9c599a2eb431",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "bb = choose_better_child(child1, child2,adversarial[15],adversarial_y[15][0],model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/measure/_structural_similarity.py:17: UserWarning: Inputs have mismatched dtype.  Setting data_range based on im1.dtype.\n",
            "  **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCl4mvK99XYj",
        "colab_type": "code",
        "outputId": "fd9867bc-0c0a-486e-c393-ad74b8ef6298",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "fitness = pop_fitness(model,np.expand_dims(population.reshape(population.shape[0],CIFAR_IMG,CIFAR_IMG),axis=3),img.reshape(CIFAR_IMG,CIFAR_IMG),label) \n",
        "print(fitness)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/measure/_structural_similarity.py:17: UserWarning: Inputs have mismatched dtype.  Setting data_range based on im1.dtype.\n",
            "  **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[-0.26002962878595726, -0.25999958545736684, -0.26007314251448344, -0.26004007622401076, -0.26003266487525345, -0.26011373574731095, -0.2599816460817825, -0.25998496480763594, -0.2600353571926644, -0.2600021864303609, -0.260040721413234, -0.2600228430135187, -0.26003768485830203, -0.26002701209750284, -0.26006302743228543, -0.2599796432991168, -0.2600043346069123, -0.26003024147792836, -0.2600466627237271, -0.26003812318804226, -0.2600652442884724, -0.2600447098702882, -0.2600085762943468, -0.26001327339828323, -0.2599806557454484, -0.26007237070197037, -0.25996000471207786, -0.2600457997287944, -0.2600101441535663, -0.26005323947618036, -0.2600554130353725, -0.2600860828123626, -0.26003997918862914, -0.26004537198733424, -0.2600515291553301, -0.2600503663988854, -0.26001231736237695, -0.2600170667581806, -0.2600851316879575, -0.2599960477747653, -0.260017809873727, -0.2600171997460062, -0.2600455137861651, -0.26001145913341955, -0.2600466317811507, -0.2600557191632309, -0.26006128108305554, -0.2599700462660023, -0.26005349311420517, -0.2600591984831575]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}