{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OmqP9iw8qi2w"
   },
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a4o2nRW3uHkP"
   },
   "source": [
    "In this notebook I did not normalized images before evolving, just when predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "lV-6sDntqd61",
    "outputId": "ffb83916-fdf4-4f3d-e692-75b0492fb415"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "import time\n",
    "from skimage.measure import compare_ssim\n",
    "import tensorflow as tf\n",
    "from keras.models import Model,load_model\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, Input, Activation\n",
    "from keras.utils import to_categorical\n",
    "import keras\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kGtAwbEMqmmv"
   },
   "outputs": [],
   "source": [
    "#Set seeds\n",
    "random.seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UMYv1iroqpKy"
   },
   "source": [
    "# GLOBAL VARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3JLxcgMPqoDE"
   },
   "outputs": [],
   "source": [
    "INDIVIDUALS = 50\n",
    "P_CROSS = 0.8\n",
    "P_MUTATION = 0.01\n",
    "CIFAR_IMG= 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uhUutenzqt18"
   },
   "source": [
    "# THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "ZZTtcGJAJLuM",
    "outputId": "6f4c82ab-6bd0-404f-dbbe-61250e2d8d6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "Number of images in x_train 50000\n",
      "Number of images in x_test 10000\n",
      "y_train shape: (50000, 10)\n",
      "input shape:  (32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_train_C, y_train_C), (x_test_C, y_test_C) = cifar10.load_data()\n",
    "print('x_train shape:', x_train_C.shape)\n",
    "print(x_train_C.shape[0], 'train samples')\n",
    "print(x_test_C.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "num_classes=10\n",
    "epochs=10\n",
    "img_shape=32 \n",
    "y_train_C = to_categorical(y_train_C, num_classes)\n",
    "y_test_C = to_categorical(y_test_C, num_classes)\n",
    "\n",
    "\n",
    "input_shape=(32,32,1)\n",
    "\n",
    "x_train_C = x_train_C.astype('float32')\n",
    "x_test_C = x_test_C.astype('float32')\n",
    "x_train_C /= 255\n",
    "x_test_C /= 255\n",
    "\n",
    "\n",
    "print('x_train shape:', x_train_C.shape)\n",
    "print('Number of images in x_train', x_train_C.shape[0])\n",
    "print('Number of images in x_test', x_test_C.shape[0])\n",
    "print('y_train shape:', y_train_C.shape)\n",
    "print(\"input shape: \",input_shape)\n",
    "\n",
    "\n",
    "# CONVERT TO GRAY SCALE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def grayscale(data, dtype='float32'):\n",
    "    # luma coding weighted average in video systems\n",
    "    r, g, b = np.asarray(.3, dtype=dtype), np.asarray(.59, dtype=dtype), np.asarray(.11, dtype=dtype)\n",
    "    rst = r * data[:, :, :, 0] + g * data[:, :, :, 1] + b * data[:, :, :, 2]\n",
    "    # add channel dimension\n",
    "    rst = np.expand_dims(rst, axis=3)\n",
    "    return rst\n",
    "\n",
    "x_train_C = grayscale(x_train_C)\n",
    "x_test_C = grayscale(x_test_C)\n",
    "\n",
    "# now we have only one channel in the images\n",
    "img_channels = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_--StA9kq4mw"
   },
   "source": [
    "# READ PICKLE FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F3glGbBeq2lz"
   },
   "outputs": [],
   "source": [
    "with open('../../Subsets/subset_cifar', 'rb') as f:\n",
    "    original = pickle.load(f)\n",
    "    adversarial= pickle.load(f)\n",
    "    original_y = pickle.load(f)\n",
    "    adversarial_y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "n1LZoAPNq996",
    "outputId": "54c614df-984f-4efb-c242-1c6bb0527396"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape (914, 32, 32, 1)\n",
      "Adversarial shape (133, 32, 32, 1)\n",
      "Original labels shape (914, 1)\n",
      "Adversarial labels shape (133, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original shape {original.shape}\")\n",
    "print(f\"Adversarial shape {adversarial.shape}\")\n",
    "print(f\"Original labels shape {original_y.shape}\")\n",
    "print(f\"Adversarial labels shape {adversarial_y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zr0TMOV_q_9J"
   },
   "source": [
    "# LOAD THE MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JibFPCmerJwW"
   },
   "source": [
    "3. CNN v2\n",
    "\n",
    "This network is made for CIFAR 10. The network is taken from [this blog]( https://appliedmachinelearning.blog/2018/03/24/achieving-90-accuracy-in-object-recognition-task-on-cifar-10-dataset-with-keras-convolutional-neural-networks/) . In this version below I didn't use some things used in the blog e.g. z-score and data augmentation.\n",
    "\n",
    "\n",
    "This network has training accuracy: 0.8940 , validation accuracy: 0.8245.\n",
    "\n",
    "**NOTE:** Training really slow, try to avoid it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "DjDjKgyWJwqY",
    "outputId": "2c0dc9b9-4318-489e-8cf3-43eef2f8cca7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 308,714\n",
      "Trainable params: 307,818\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Network 3 \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar10\n",
    "from keras import regularizers\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import numpy as np\n",
    "\n",
    "input_shape = (CIFAR_IMG,CIFAR_IMG,1)\n",
    "weight_decay = 1e-4\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=input_shape))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    " \n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    " \n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    " \n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    " \n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "'''\n",
    "history = model.fit(x=x_train_C,y=y_train_C, epochs=150, batch_size=64, validation_data=[x_test_C,y_test_C])\n",
    "\n",
    "score= model.evaluate(x_test_C, y_test_C,verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model.save_weights(\"CNN_CIFAR10_net3.h5\")\n",
    "files.download('CNN_CIFAR10_net3.h5')\n",
    "'''\n",
    "\n",
    "model = load_model(\"../../Models/CNN_CIFAR10_net3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1918babfeb8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MGSQOJJprRG-"
   },
   "source": [
    "# GENETIC ALGORITHM FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQuqZrKL4qqW"
   },
   "outputs": [],
   "source": [
    "\n",
    "def computing_SSIM(individual,target):\n",
    "    return compare_ssim(individual.reshape(CIFAR_IMG,CIFAR_IMG), target.reshape(CIFAR_IMG,CIFAR_IMG))\n",
    "\n",
    "def calculate_fitness(model,ind,target_image,label,l1=0.2, l2=0.8, N=50, num_classes=10):\n",
    "  # predict the population\n",
    "  predictions=model.predict(ind.reshape(1,CIFAR_IMG,CIFAR_IMG,1) / 255.0)  \n",
    "  # po is the ground truth prediction, so for label = 0, it will be prediciton[0]\n",
    "  predictions=predictions[0]\n",
    "  po=predictions[label]\n",
    "  # set that value to 0\n",
    "  predictions[label]=0\n",
    "  # take next highest one\n",
    "  pd = np.max(predictions)\n",
    "  diff=pd-po\n",
    "  return l1*computing_SSIM(ind.reshape(CIFAR_IMG,CIFAR_IMG),target_image.reshape(CIFAR_IMG,CIFAR_IMG)) +l2*(diff)\n",
    "  \n",
    "\n",
    "\n",
    "def pop_fitness(model,pop,target,label):\n",
    "    return [calculate_fitness(model, p, target, label) for p in pop]\n",
    "\n",
    "def flatten(imgs):\n",
    "    # flatten all images in np array or list\n",
    "    return np.array([im.flatten() for im in imgs])\n",
    "\n",
    "def gaussian_noise():\n",
    "    # draw one sample of noise from zero mean 1 variance Gaussian\n",
    "    return np.random.normal(0, 10)\n",
    "\n",
    "def p_noise(x):\n",
    "  if 0.01 > np.random.uniform():\n",
    "    return x + gaussian_noise()\n",
    "  else:\n",
    "    return x\n",
    "    \n",
    "def add_noise(image):\n",
    "    noise_v=np.vectorize(p_noise)\n",
    "    return noise_v(image) #np.array([x + gaussian_noise() if P_MUTATION > np.random.uniform(0.0, 1.0) else x+0 for x in image])\n",
    "\n",
    "def k_crossover(im1, im2, k=2):\n",
    "    c1, c2 = [], []\n",
    "    # get k crossover points\n",
    "    points = sorted([np.random.randint(0, CIFAR_IMG*CIFAR_IMG-1, 1) for p in range(k)])\n",
    "    points = sorted([np.random.randint(0,CIFAR_IMG*CIFAR_IMG-1,1) for p in range(k)])\n",
    "    im_1_split = np.split(im1, [int(p) for p in points])\n",
    "    im_2_split = np.split(im2, [int(p) for p in points])\n",
    "    \n",
    "    # alternate between lists to realise crossover (theres got to be a more clever way to do this)\n",
    "    for i in range(k+1):\n",
    "        if i % 2 == 0:\n",
    "            c1.append(im_1_split[i])\n",
    "            c2.append(im_2_split[i])\n",
    "        else:\n",
    "            c1.append(im_2_split[i])\n",
    "            c2.append(im_1_split[i])\n",
    "    return np.concatenate(c1, axis=0), np.concatenate(c2, axis=0)\n",
    "\n",
    "def tournament(pop, model, ground_truth, target, k=3):\n",
    "\n",
    "    indices = np.random.choice(range(len(pop)), k, replace=False) #we get 3 indxes [2 34 46]    \n",
    "    individuals = pop.take(indices,axis=0)\n",
    "    scores = pop_fitness(model,np.expand_dims(individuals.reshape(individuals.shape[0],CIFAR_IMG,CIFAR_IMG),axis=3), ground_truth.reshape(CIFAR_IMG,CIFAR_IMG), target)\n",
    "    index_max = np.argmax(scores)\n",
    "    winner = individuals[index_max]\n",
    "    return winner\n",
    "\n",
    "\n",
    "def check_adv_termination(ind, label,ground_truth, model):\n",
    "  # individual - the best one from the generation\n",
    "  # label - class we want\n",
    "  # ground_truth - the image (32,32)\n",
    "  # model we are using \n",
    "  dist = 1-compare_ssim(ind.reshape(CIFAR_IMG,CIFAR_IMG),ground_truth.reshape(CIFAR_IMG,CIFAR_IMG))\n",
    "  predictions= model.predict(ind.reshape(1,CIFAR_IMG,CIFAR_IMG,1)/255.0)\n",
    "  predicted_label= np.argmax(predictions[0])\n",
    "  if label != predicted_label and dist < 0.001:\n",
    "    print(\"FOUND ADVERSARIAL\")\n",
    "    print(f\"Fitness of the adversarial {calculate_fitness(model,ind,ground_truth,label)}\")\n",
    "    return ind\n",
    "  return []\n",
    "\n",
    "def init_pop_from_sample(n,img,label):\n",
    "    x = np.array([add_noise(img) for i in range(n)])\n",
    "    return x.reshape(n, CIFAR_IMG*CIFAR_IMG)\n",
    "\n",
    "def uniform(p1, p2):\n",
    "    LEN=1024\n",
    "    for i in range(LEN):\n",
    "        if np.random.uniform() > P_CROSS:\n",
    "            a = p1[i]\n",
    "            p1[i] = p2[i]\n",
    "            p2[i] = a\n",
    "    return p1, p2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-epJQRlguXyK"
   },
   "source": [
    "Functions from the past, just didn't want to erase them yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "zlm5dKzOuXNw",
    "outputId": "00d4613d-f533-4e7a-cce0-cd5ad53ee562"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef check_adverserial(pop, model, fitness, target,ground_truth):\\n    #print(f\"this is adversarial function\")\\n    preds=model.predict(pop.reshape(pop.shape[0],28,28,1))\\n    #print(f\"These are predictions made here {preds}\")\\n    for ind, pr in zip(pop,preds): \\n      #print(f\"prediction for an individual {pr}\")\\n      preds=np.argmax(pr)\\n      #print(f\"getting the index of highest value in predictions {preds}\")\\n      #setting the value to 0\\n      pr[0]=0\\n      #print(f\"this is our target {target}\")\\n      #print(f\"this is out ground_truth {ground_truth.shape}\")\\n      fitness=computing_SSIM(ind.reshape(28,28),ground_truth.reshape(28,28))\\n      #print(f\"these are the fitness values {fitness}\")\\n      next_highest = np.argmax(pr)\\n      #print(f\"getting the next highest value {next_highest}\")\\n      if next_highest != target and fitness > 0.98:\\n          return ind, True\\n      return None, False\\n\\ndef init_pop(n, num, data, labels):\\n    indices = np.where(labels==num)[0]\\n    n_indices = np.random.choice(indices, n, replace=True)\\n    sample = np.take(data, n_indices, axis=0)\\n    return sample, np.full((n), num, dtype=int) # return sample+array of labels\\n\\n\\nCyrils model\\n\\ndef save_trained_model(model, filename=\\'SVC_model.sav\\'):\\n    pickle.dump(model, open(filename, \\'wb\\'))\\n    \\ndef load_trained_model(filename=\\'SVC_model.sav\\'):\\n    return pickle.load(open(filename, \\'rb\\'))\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def check_adverserial(pop, model, fitness, target,ground_truth):\n",
    "    #print(f\"this is adversarial function\")\n",
    "    preds=model.predict(pop.reshape(pop.shape[0],28,28,1))\n",
    "    #print(f\"These are predictions made here {preds}\")\n",
    "    for ind, pr in zip(pop,preds): \n",
    "      #print(f\"prediction for an individual {pr}\")\n",
    "      preds=np.argmax(pr)\n",
    "      #print(f\"getting the index of highest value in predictions {preds}\")\n",
    "      #setting the value to 0\n",
    "      pr[0]=0\n",
    "      #print(f\"this is our target {target}\")\n",
    "      #print(f\"this is out ground_truth {ground_truth.shape}\")\n",
    "      fitness=computing_SSIM(ind.reshape(28,28),ground_truth.reshape(28,28))\n",
    "      #print(f\"these are the fitness values {fitness}\")\n",
    "      next_highest = np.argmax(pr)\n",
    "      #print(f\"getting the next highest value {next_highest}\")\n",
    "      if next_highest != target and fitness > 0.98:\n",
    "          return ind, True\n",
    "      return None, False\n",
    "\n",
    "def init_pop(n, num, data, labels):\n",
    "    indices = np.where(labels==num)[0]\n",
    "    n_indices = np.random.choice(indices, n, replace=True)\n",
    "    sample = np.take(data, n_indices, axis=0)\n",
    "    return sample, np.full((n), num, dtype=int) # return sample+array of labels\n",
    "\n",
    "\n",
    "Cyrils model\n",
    "\n",
    "def save_trained_model(model, filename='SVC_model.sav'):\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    \n",
    "def load_trained_model(filename='SVC_model.sav'):\n",
    "    return pickle.load(open(filename, 'rb'))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FOEo4wAfggNs"
   },
   "outputs": [],
   "source": [
    "''' my part of the code ''' \n",
    "''' I know it is ugly, I will fix it . this is the intial version'''\n",
    "# from Goorge Clooney paper\n",
    "def quadrant_crossover(parent_1,parent_2):\n",
    "\n",
    "  # reshape parents\n",
    "  parent_1,parent_2= parent_1.reshape((CIFAR_IMG,CIFAR_IMG)), parent_2.reshape((CIFAR_IMG,CIFAR_IMG))\n",
    "  # quadrants for both parents\n",
    "  p1,p2,p3,p4,q1,q2,q3,q4 = [],[],[],[],[],[],[],[]\n",
    "  child1, child2 = [],[]\n",
    "  # getting random (x,y) point in 2D matrix\n",
    "  x,y = np.random.randint(0,CIFAR_IMG-1), np.random.randint(0,CIFAR_IMG-1)  \n",
    "\n",
    "  # choose which quadrant we want to crossover\n",
    "  N = np.random.randint(0,3)\n",
    "  #make quadrants\n",
    "  for i in range(CIFAR_IMG):\n",
    "    if (i<=x):\n",
    "      p1.append(parent_1[i][:y+1])\n",
    "      p2.append(parent_1[i][y+1:])\n",
    "      q1.append(parent_2[i][:y+1])\n",
    "      q2.append(parent_2[i][y+1:])\n",
    "    else:\n",
    "      p3.append(parent_1[i][:y+1])\n",
    "      p4.append(parent_1[i][y+1:])\n",
    "      q3.append(parent_2[i][:y+1])\n",
    "      q4.append(parent_2[i][y+1:])\n",
    "\n",
    "  if (N==0):\n",
    "    ch1 = connect_quadrants(p1,q2,q3,q4)\n",
    "    ch2 = connect_quadrants(q1,p2,p3,p4)\n",
    "  elif (N==1):\n",
    "    ch1 = connect_quadrants(q1,p2,q3,q4)\n",
    "    ch2 = connect_quadrants(p1,q2,p3,p4)\n",
    "  elif (N==2):\n",
    "    ch1 = connect_quadrants(q1,q2,p3,q4)\n",
    "    ch2 = connect_quadrants(p1,p2,q3,p4)\n",
    "  else:\n",
    "    ch1 = connect_quadrants(q1,q2,q3,p4)\n",
    "    ch2 = connect_quadrants(p1,p2,p3,q4)\n",
    "\n",
    "  return ch1,ch2\n",
    "\n",
    "def connect_quadrants(q1,q2,q3,q4):\n",
    "  left = np.concatenate((q1,q3))\n",
    "  right = np.concatenate((q2,q4))\n",
    "  image = np.concatenate((left,right),axis=1)\n",
    "  return image.flatten()\n",
    "\n",
    "\n",
    "def multi_crossover(parent1,parent2,target):\n",
    "  pop= []\n",
    "  # 2-k crossover\n",
    "  pop.append(k_crossover(parent1, parent2))\n",
    "  # Gorge Clooney crossover\n",
    "  pop.append(quadrant_crossover(parent1,parent2))\n",
    "  # uniform crossover\n",
    "  pop.append(k_crossover(parent1, parent2,1))\n",
    "  pop.append(uniform(parent1,parent2))\n",
    "  # SSIM similarity \n",
    "  flattened_list = [y for x in pop for y in x] # need to flatten the list because pop is list of lists, cause every crossover function returns 2 obj\n",
    "  ssim = [computing_SSIM(ind,target) for ind in flattened_list ]\n",
    "  # taking the index of largest two score\n",
    "  id1=np.argmax(ssim)\n",
    "  ssim[id1]=0\n",
    "  id2 = np.argmax(ssim)\n",
    "  #returning parents\n",
    "  return flattened_list[id1],flattened_list[id2]\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J7Z_4b8EqUmj"
   },
   "outputs": [],
   "source": [
    "def return_best_individual(pop,fitness):\n",
    "  index = np.argmax(fitness)\n",
    "  best = pop[index]\n",
    "  return best, np.max(fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tcVTicSPvYoy"
   },
   "outputs": [],
   "source": [
    "def choose_better_child(ch1, ch2,ground_truth,label,model):\n",
    "  # I named it better child, but we choose by this parents as well\n",
    "  ch1_f = calculate_fitness(model,ch1.reshape(CIFAR_IMG,CIFAR_IMG),ground_truth.reshape(CIFAR_IMG,CIFAR_IMG),label)\n",
    "  ch2_f = calculate_fitness(model,ch2.reshape(CIFAR_IMG,CIFAR_IMG),ground_truth.reshape(CIFAR_IMG,CIFAR_IMG),label)\n",
    "  # change this into ternary operator\n",
    "  if ch1_f>ch2_f:\n",
    "    return ch1\n",
    "  else:\n",
    "    return ch2              \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UiXxgPDmriTE"
   },
   "source": [
    "# THE MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "T-8hS44GPb2B",
    "outputId": "3661aaab-b99a-4560-cacf-0335b114d94b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX = flatten(x_train)\\nX_t = flatten(x_test)\\nprint(f\"X train shape {X.shape}\")\\nprint(f\"X test shape {X_t.shape}\")\\nprint(f\"y train shape {y.shape}\")\\nprint(f\"y test shape {y_t.shape}\")\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This not necessary when using subset \n",
    "'''\n",
    "'''\n",
    "X = flatten(x_train)\n",
    "X_t = flatten(x_test)\n",
    "print(f\"X train shape {X.shape}\")\n",
    "print(f\"X test shape {X_t.shape}\")\n",
    "print(f\"y train shape {y.shape}\")\n",
    "print(f\"y test shape {y_t.shape}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "r99NLfBt-ngX",
    "outputId": "7d79a329-77e7-484d-a066-0db3771c2b91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial fitness: \n",
      " [-0.6003421846829813, -0.6014233009400011, -0.6021710252132082, -0.6010787395273278, -0.6017296644445892, -0.6006246064342724, -0.6016371008769117, -0.6015986491587476, -0.6013498892158472, -0.5999955458140832, -0.601020590562576, -0.6017574466266108, -0.602747413741685, -0.6017573611414601, -0.6005499628970601, -0.6009253942964956, -0.6012076525904644, -0.6017729240012388, -0.601591565086971, -0.6002356500571928, -0.6020833207438715, -0.6014473382482549, -0.6047364836056387, -0.6036656071764964, -0.6028087296464472, -0.6002553189157103, -0.6011277407964598, -0.600873706128894, -0.6002998612753933, -0.5999804860611871, -0.6004737955634604, -0.6011875444301396, -0.6008069189157474, -0.6019352034546327, -0.6000528284646404, -0.6013990531717441, -0.600529128618289, -0.6021990828935389, -0.5999799240095858, -0.6013059022818715, -0.6010262546795597, -0.6028610166065058, -0.6013173335334538, -0.6016748774691136, -0.6015680422549939, -0.6016282783645052, -0.6015389422224486, -0.6002344390427716, -0.60037182666477, -0.602540684945236]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lora\\Anaconda3\\lib\\site-packages\\skimage\\measure\\_structural_similarity.py:155: UserWarning: Inputs have mismatched dtype.  Setting data_range based on X.dtype.\n",
      "  warn(\"Inputs have mismatched dtype.  Setting data_range based on \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0\n",
      "Max fitness value -0.5999799240095858\n",
      "Generation 10\n",
      "Max fitness value -0.5999799240095858\n"
     ]
    }
   ],
   "source": [
    "# for each image and label in adversarial\n",
    "n=50\n",
    "import time\n",
    "# these are the examples that are found as adversarialwe will save these at the end in a file\n",
    "evolved_examples= []\n",
    "# fitness of the adversarials\n",
    "fitness_of_evolved=[]\n",
    "# time necessary to evolve the adversarial\n",
    "times=[]\n",
    "# the distance between the original image and the adversarial\n",
    "ssim_values=[]\n",
    "# number of round necessary to produce adversarial \n",
    "number_of_rounds=[]\n",
    "# this will serve to see if the fitness changes or not \n",
    "best_fitness = 0\n",
    "\n",
    "\n",
    "numb_of_found_after30=0\n",
    "numb_of_adv_found=0\n",
    "\n",
    "#dictionary to keep the best individual to check if the fitness is improving or not \n",
    "\n",
    "\n",
    "predicted_class= []\n",
    "for img,label in zip(adversarial,adversarial_y):\n",
    "  winner_of_gen = {\"image\":[],\"label\": None, \"fitness\": None}\n",
    "  #temporary variable to check generations:\n",
    "  fitness_no_change = 0\n",
    "  start = time.time()\n",
    "  label=label[0]\n",
    "  #intialize population from the image and with the given label\n",
    "  population = init_pop_from_sample(n,img,label)\n",
    "  # calculate fitness of these individuals\n",
    "  fitness = pop_fitness(model,np.expand_dims(population.reshape(population.shape[0],CIFAR_IMG,CIFAR_IMG),axis=3),img.reshape(CIFAR_IMG,CIFAR_IMG),label)\n",
    "  print(f\"Initial fitness: \\n {fitness}\")\n",
    "  #retun the best one from the population\n",
    "  best,fit_max = return_best_individual(population,fitness)\n",
    "  #check if adversarial\n",
    "  check_adv = check_adv_termination(best,label,img, model)\n",
    "  #define max generation\n",
    "  max_gen=0\n",
    "  winner_of_gen.update(image= best)\n",
    "  winner_of_gen.update(label= label)\n",
    "  winner_of_gen.update(fitness= fit_max)\n",
    "  while (len(check_adv)==0 or max_gen<10000):\n",
    "      new_pop=[]\n",
    "      for i in range(50):\n",
    "        parent1= tournament(population, model, img, label) \n",
    "        parent2 = tournament(population, model, img, label)\n",
    "        if 0.8 > np.random.uniform(0.0, 1.0):\n",
    "          child1, child2 = multi_crossover(parent1, parent2,img) # crossover\n",
    "          new_pop.append(add_noise(choose_better_child(child1, child2,img,label,model)))\n",
    "        else:\n",
    "          new_pop.append(add_noise(choose_better_child(parent1, parent2,img,label,model)))\n",
    "\n",
    "      # to reshape into an array \n",
    "      population= np.array(new_pop)\n",
    "      #check fitness of the generation\n",
    "      fitness = pop_fitness(model,np.expand_dims(population.reshape(population.shape[0],CIFAR_IMG,CIFAR_IMG),axis=3),img.reshape(CIFAR_IMG,CIFAR_IMG),label) \n",
    "      #find the highest fitness\n",
    "      best,fit_max1 = return_best_individual(population,fitness)\n",
    "      # check adversarial - check if pred != target, distance < 0.001 or fitness didn't improve 0.001 after 30 generations(this is in else condition)\n",
    "      check_adv = check_adv_termination(best,label,img,model)\n",
    "\n",
    "      #check if the first termination true \n",
    "      if(len(check_adv) != 0):\n",
    "        print(\"Adversarial example image: \\n\")\n",
    "        evolved_examples.append(check_adv) #add evolved example\n",
    "        ssim_values.append(1-compare_ssim(check_adv.reshape(CIFAR_IMG,CIFAR_IMG),img.reshape(CIFAR_IMG,CIFAR_IMG))) #add the distance\n",
    "        end=time.time()\n",
    "        times.append(end-start) #add the time \n",
    "        fitness_of_evolved.append(calculate_fitness(model,check_adv,img,label)) #add the fitness value of adversarial\n",
    "        number_of_rounds.append(max_gen)\n",
    "        pred_l=np.argmax(model.predict(check_adv.reshape(1,CIFAR_IMG,CIFAR_IMG,1)/255.0))\n",
    "        predicted_class.append(pred_l)\n",
    "        print(\"Left: adversarial \\t Right: ground truth\")\n",
    "        fd, idx = plt.subplots(1,2)\n",
    "        idx[0].imshow(check_adv.reshape(CIFAR_IMG,CIFAR_IMG),cmap='gray')\n",
    "        idx[1].imshow(img.reshape(CIFAR_IMG,CIFAR_IMG),cmap='gray')\n",
    "        plt.show()\n",
    "        print(f\"True label: {label}\")\n",
    "        print(f\"predicted label: {pred_l}\") \n",
    "        print(\"Time: \",end-start ,\" seconds\")\n",
    "        numb_of_adv_found+=1\n",
    "        break\n",
    "      #check the second termination \n",
    "      else:\n",
    "          #check if fitness increases, if not , add +1 to temporary var\n",
    "        if fit_max1>fit_max:\n",
    "          fit_max=fit_max1\n",
    "          winner_of_gen.update(image= best)\n",
    "          winner_of_gen.update(label= label)\n",
    "          winner_of_gen.update(fitness= fit_max1)\n",
    "          fitness_no_change=0\n",
    "        else:\n",
    "          fitness_no_change+=1\n",
    "      \n",
    "      #print after every 10 generations to see the progress\n",
    "      if (max_gen % 10 == 0):\n",
    "        print(f\"Generation {max_gen}\")\n",
    "        print(f\"Max fitness value {fit_max}\")\n",
    "      max_gen+=1\n",
    "\n",
    "      # if fitness did not improve for 30 generations, save the image that was best , saved it in a dicitonary\n",
    "      if fitness_no_change==30:\n",
    "        print(\"FITNESS DID NOT IMPROVE FOR 30 GENERATIONS\")\n",
    "        print(\"Best adversarial image we could find: \\n\")\n",
    "        evolved_examples.append(winner_of_gen[\"image\"])\n",
    "        ssim_values.append(1-compare_ssim(np.array(winner_of_gen[\"image\"]).reshape(CIFAR_IMG,CIFAR_IMG),img.reshape(CIFAR_IMG,CIFAR_IMG)))\n",
    "        number_of_rounds.append(max_gen)\n",
    "        end=time.time()\n",
    "        times.append(end-start)\n",
    "        fitness_of_evolved.append(winner_of_gen[\"fitness\"])\n",
    "        pred_l=np.argmax(model.predict(np.array(winner_of_gen[\"image\"]).reshape(1,CIFAR_IMG,CIFAR_IMG,1)/255.0))\n",
    "        predicted_class.append(pred_l)\n",
    "        print(\"Left: adversarial \\t Right: ground truth\")\n",
    "        fd, idx = plt.subplots(1,2)\n",
    "        idx[0].imshow(np.array(winner_of_gen[\"image\"]).reshape(CIFAR_IMG,CIFAR_IMG),cmap='gray')\n",
    "        idx[1].imshow(img.reshape(CIFAR_IMG,CIFAR_IMG),cmap='gray')\n",
    "        plt.show()\n",
    "        print(f\"True label: {label}\")\n",
    "        print(f\"predicted label: {pred_l}\")\n",
    "        print(\"Time: \",end-start ,\" seconds\")\n",
    "        numb_of_found_after30 +=1\n",
    "        break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XEMXgasB3Llv"
   },
   "source": [
    "# Save files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u43v4fe33RGZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max time: 1156.6763889789581\n",
      "Min time: 1.9638023376464844\n",
      "Mean time: 417.7622298244247\n",
      "Std time: 229.2042221482553\n",
      "\n",
      "Max fitness evolved: 0.998783635723865\n",
      "Min fitness evolved:: -0.6022439641919571\n",
      "Mean fitness evolved: 0.8545252948084725\n",
      "Std fitness evolved:: 0.4410646831327256\n",
      "\n",
      "Max ssim: 0.265159994831463\n",
      "Min ssim: 1.7113638396515363e-05\n",
      "Mean ssim: 0.027153931511297455\n",
      "Std ssim: 0.032421658245761396\n",
      "\n",
      "Max rounds: 280\n",
      "Min rounds: 0\n",
      "Mean rounds: 100.23308270676692\n",
      "Std rounds: 54.66052268430095\n",
      "\n",
      "Percentage of adversarial founds sucessfully : 0.022556390977443608 %\n",
      "Percentage of adversarial founds after fitness not improving for 30 generations: 0.9774436090225563 %\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "file_ = open('GA_adv_cifar_multicrossover_seed1', 'wb')\n",
    "pickle.dump(evolved_examples, file_)\n",
    "pickle.dump(times, file_)\n",
    "pickle.dump(ssim_values, file_)\n",
    "pickle.dump(fitness_of_evolved , file_)\n",
    "pickle.dump(predicted_class, file_)\n",
    "pickle.dump(number_of_rounds, file_)\n",
    "file_.close()\n",
    "\n",
    "print(f\"Max time: {np.max(times)}\")\n",
    "print(f\"Min time: {np.min(times)}\")\n",
    "print(f\"Mean time: {np.mean(times)}\")\n",
    "print(f\"Std time: {np.std(times)}\\n\")\n",
    "\n",
    "print(f\"Max fitness evolved: {np.max(fitness_of_evolved)}\")\n",
    "print(f\"Min fitness evolved:: {np.min(fitness_of_evolved)}\")\n",
    "print(f\"Mean fitness evolved: {np.mean(fitness_of_evolved)}\")\n",
    "print(f\"Std fitness evolved:: {np.std(fitness_of_evolved)}\\n\")\n",
    "\n",
    "print(f\"Max ssim: {np.max(ssim_values)}\")\n",
    "print(f\"Min ssim: {np.min(ssim_values)}\")\n",
    "print(f\"Mean ssim: {np.mean(ssim_values)}\")\n",
    "print(f\"Std ssim: {np.std(ssim_values)}\\n\")\n",
    "\n",
    "print(f\"Max rounds: {np.max(number_of_rounds)}\")\n",
    "print(f\"Min rounds: {np.min(number_of_rounds)}\")\n",
    "print(f\"Mean rounds: {np.mean(number_of_rounds)}\")\n",
    "print(f\"Std rounds: {np.std(number_of_rounds)}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Percentage of adversarial founds sucessfully : {numb_of_adv_found/len(adversarial_y)} %\")\n",
    "print(f\"Percentage of adversarial founds after fitness not improving for 30 generations: {numb_of_found_after30/len(adversarial_y)} %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uQoHNMX_8nor"
   },
   "source": [
    "Open adversarial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rEK7GsD78oq5"
   },
   "outputs": [],
   "source": [
    "with open('GA_adv_cifar_multicrossover_seed1', 'rb') as f:\n",
    "    evolved_examples = pickle.load(f)\n",
    "    times= pickle.load(f)\n",
    "    ssim_values = pickle.load(f)\n",
    "    fitness_of_evolved = pickle.load(f)\n",
    "    predicted_class = pickle.load(f)\n",
    "    number_of_rounds = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max ssim: 0.9999828863616035\n",
      "Min ssim: 0.734840005168537\n",
      "Mean ssim: 0.9728460684887026\n",
      "Std ssim: 0.032421658245761396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Correction of ssim values\n",
    "new_ssim=[]\n",
    "for s in ssim_values:\n",
    "    new_ssim.append(1-s)\n",
    "    \n",
    "print(f\"Max ssim: {np.max(new_ssim)}\")\n",
    "print(f\"Min ssim: {np.min(new_ssim)}\")\n",
    "print(f\"Mean ssim: {np.mean(new_ssim)}\")\n",
    "print(f\"Std ssim: {np.std(new_ssim)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correctionf of rounds  (replacing 0 with 1)\n",
    "number_of_rounds = np.where(np.array(number_of_rounds)==0, 1, number_of_rounds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([118,  87,  77, 151,  71,  57, 163, 138,  83,  54,  61,  53,  78,\n",
       "       104,  62,  31,  94,  61,  76,  30, 108,  30,  80,  30,  30, 134,\n",
       "        58,  62,   2, 208,  55,  75,  85, 125, 254,  64,  31,  30, 147,\n",
       "        42,  66, 142, 147,  61,  92, 115,  70,  88, 112, 196,  63,  68,\n",
       "        30,  64,  78, 116,  54,  82,  67,   1, 106,  86, 109, 103, 111,\n",
       "        48,  59, 166,  66, 158,  66,  72, 155, 162, 137, 113,  91, 164,\n",
       "       119,  56,  30, 115,  52, 275,  82, 164, 167,  68, 162, 118, 185,\n",
       "        78, 154, 142,  73, 280,  77,  89, 162,  88,  95,  59, 119, 157,\n",
       "       132,  71, 111,  92,  70,  98, 137, 167,  60,  87,  59,  73,  30,\n",
       "       137,  55, 237, 164, 140,  69,  74,  30, 152, 194, 195, 221,  89,\n",
       "        72, 167,   1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max rounds: 280\n",
      "Min rounds: 1\n",
      "Mean rounds: 100.24812030075188\n",
      "Std rounds: 54.6330762705389\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Max rounds: {np.max(number_of_rounds)}\")\n",
    "print(f\"Min rounds: {np.min(number_of_rounds)}\")\n",
    "print(f\"Mean rounds: {np.mean(number_of_rounds)}\")\n",
    "print(f\"Std rounds: {np.std(number_of_rounds)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0e9R7ACErtqK"
   },
   "source": [
    "# Examples of what functions do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cpEVAzR7rtK8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7985892726591407, -0.7986649463807212, -0.7985705252188005, -0.7986603324640114, -0.7986640443846431, -0.7983015319368282, -0.798545200422354, -0.7983238295714443, -0.7986448602525132, -0.7986523954988857, -0.7985887420905552, -0.7985393478998531, -0.7989564462911779, -0.7988277150040406, -0.7989882228910968, -0.7986940212720168, -0.7988727765084926, -0.7987316295436042, -0.7984438426216252, -0.7990896847279569, -0.7988467516858758, -0.7984860210372816, -0.7986454906217331, -0.7986385435250732, -0.7987805617963863, -0.7986695314192882, -0.7987035827823399, -0.7987494380575793, -0.7989881134607149, -0.798920478946215, -0.7986249369840608, -0.7985955019172958, -0.7982727963182844, -0.7987309617863311, -0.7986727631087088, -0.7987490886114068, -0.7987777222228992, -0.7989488590725383, -0.7987275123124932, -0.7984690902712791, -0.7985118906684375, -0.7987075963889337, -0.7986641486373497, -0.7986463555893116, -0.7985731207770441, -0.7987383184102791, -0.7986167203393824, -0.7988712274292329, -0.7987522211469823, -0.7989383692241568]\n"
     ]
    }
   ],
   "source": [
    "population = init_pop_from_sample(50,adversarial[15],adversarial_y[15][0])\n",
    "fitness = pop_fitness(model,np.expand_dims(population.reshape(population.shape[0],CIFAR_IMG,CIFAR_IMG),axis=3),img.reshape(CIFAR_IMG,CIFAR_IMG),adversarial_y[15][0])\n",
    "print(fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "colab_type": "code",
    "id": "0aYxCQLEu1BB",
    "outputId": "6a29e5dc-27d0-4479-81b7-6e1288329285"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAZp0lEQVR4nO2da4xd1XXH/+veufP0+DEePwbbeMyjTQgJhkwoKiGhpKVAo0JUEoUPiLYojqogNVL6AVGpoVKkJm0hyoc2rWmckCoNEB4NTVEAoUQklUIYO2AMTsDYxvg1M/aMPe+Z+1j9cA/SQPZaM3Pm3nMH9v8njebO2Xefs+4+53/Pvfs/a21RVRBC3vvkGh0AISQbKHZCIoFiJyQSKHZCIoFiJyQSKHZCIqFpKZ1F5DoA3wCQB/AfqvpV7/lrunK6aXP4kJ4BmHNbF49CUvUTIw5vb1kbm+le2XuX5WIse9ecdV1V3D5hjh0tYWS4EmxOLXYRyQP4FwB/BOAogOdF5HFVfcXqs2lzEx7+3+5gW1ntF9YslbRhho+VUhIF46Tknd2Vnast7avyPo4VUry02o7u8sIb/1rjjaN3zeWN62pW7TOdl3Cfm//klNlnKR/jLwdwQFUPquosgAcA3LiE/RFC6shSxL4JwJtz/j6abCOELEOWIvbQ55Lf+mwhIjtEpF9E+keG38sfGAlZ3ixF7EcBbJnz92YAx9/5JFXdqap9qtq3pouT/4Q0iqWo73kAF4rINhFpBvBZAI/XJixCSK1JPRuvqiURuQPAk6hab7tU9WWvTx6KTmMWsWxsR7Lz2pJuirYg4RnVvDPTmsvZbRUn43BC7a88HWK/R+eMGLPGe20WZee8FFNmZzrDnwr3i6gbot2Yxh2y3CsvhCX57Kr6BIAnlrIPQkg28Es0IZFAsRMSCRQ7IZFAsRMSCRQ7IZGwpNn4xVIBMG14A56lUet3pNQJKKb9k84WShvHjGPLpRmrevxfo5XEsbXJvuQOlcqpjpXGuqo4iVdp8eJIkwiT6nV5NvCi90YIeVdCsRMSCRQ7IZFAsRMSCRQ7IZGQ6Wx8GYIxDR/Smx0tZFiWypoZBdLVwvNmR9PixWGVK8oaK46j5aLZxyup5Z2XNJSdhKFaHwvIriyVf/0SQqKAYickEih2QiKBYickEih2QiKBYickEjK13nIAWiWc7OBaEynspHrYJ9Y7o7cijIe3Wom3T+8dmsW63441xrVeUmx+UlzDbl1GaykyWm+ERA/FTkgkUOyERALFTkgkUOyERALFTkgkLMl6E5HDAMYAlAGUVLXPe34OilbDTig6loGXDZUlpvWWdn8pX5d3vDSxpKv89i5hmVw76Zy+2tpotfDZ/0BVT9VgP4SQOsKP8YREwlLFrgCeEpHdIrKjFgERQurDUj/GX6mqx0VkPYCnReTXqvrs3CckbwI7AOCcTfwgQUijWJL6VPV48nsQwGMALg88Z6eq9qlq39ouip2QRpFafSLSISKdbz0GcC2AfbUKjBBSW5byMX4DgMekWrivCcB/qeqP0+7Me9ep9eeBtFZZ3ihSmDY+L470+1y811TOPAMsjJexVzaX3vKxxjhzu9E5LVZmnr/80+LHI7XYVfUggEvS9ieEZAu/RBMSCRQ7IZFAsRMSCRQ7IZFAsRMSCZkWnBQABa+xhtTaXvOoR5HH9PtMsx5ddqzPd5htR0rjmcXhFftMOx6+VZZif876h9axvLUFeWcnJBIodkIigWInJBIodkIigWInJBIynY2vAJg0ZkFn1X7faZbw/Ki7DFLqJZm8JXfeBaRwE7xxTJNY43GqPGG2taaIPS1e8o+XJOPN1OdSJutYeMs/WefMW9aKd3ZCIoFiJyQSKHZCIoFiJyQSKHZCIoFiJyQSsk+EMd0V29RoMfp4Vk1ay6ggi3//S1vDzYuxHvu0yNXhPb9inU+1z7Nbky+lLVex7DC3vFtKCy2lc2iNftEJI28cywuBd3ZCIoFiJyQSKHZCIoFiJyQSKHZCIoFiJyQS5rXeRGQXgE8CGFTVi5NtXQAeBNAL4DCAz6jqyEIOaL27WPYaYFtsaWyy+ZjWxS8MlNZCKy76SFVaxTapLBut6ORyTWraSGxajHOT1kIrOpadh3WNuBlqToyrxKyiiOHKrNnmRW+1WfYakO4uvZA+3wFw3Tu23QngGVW9EMAzyd+EkGXMvGJP1lsffsfmGwHcnzy+H8BNNY6LEFJj0n4O3qCqJwAg+b2+diERQupB3SfoRGSHiPSLSP/wcJYVygkhc0kr9gER6QGA5Peg9URV3amqfara19XFyX9CGkVa9T0O4Lbk8W0AflibcAgh9WIh1tv3AVwNoFtEjgL4MoCvAnhIRG4HcATApxdysJwIOgwrxLOoLPuk1sUQAQA1tvOKjsUzVvHabIvndKXdbJuotAS3542inQDQIbZlVJCS2ZZ3z1nY6iu4cdjHWpWzz7VnwVpZb2n6AL5N6WVheteBZYqmses85hW7qt5iNH0ixfEIIQ2CX6IJiQSKnZBIoNgJiQSKnZBIoNgJiYQGFJw0spAcG8ey2ApO9teYk4H04uxKs23PVK/Z9urExuD2s8VWs89s2R7i1ibbxllVmDLbNraMmm09hTPB7WfLtl33xvRas21weoXZdmLCHseB06uC28tT9jlrarett561Z822v9z6f2bbDR2HgtvTrsvmWV6zzj69fmWjW9HLptRwW9npwzs7IZFAsRMSCRQ7IZFAsRMSCRQ7IZFAsRMSCZlab4qUhQMNN8HOCwP2zKw22z7/1F+YbWv22taQGBbJbKdtdzhJXpjpcuzGKXufsxfZttxX+v47uP2+1680+0zu7jbbOo7aMc6usmPsOh3u543H+OZmu22kzWz7pzU3m20/+9O9we1f2/Sk2ce7QguOtVVwst7ctfuMbtOelWdcjF4mIu/shEQCxU5IJFDshEQCxU5IJFDshERC5okw1vI/Xt0vi7LT594j15ptFzxoJ6AUO+x9Hvt4eLgqBXv+tjDuzKp32Usynf8DOylkeNhOvNn3gc3B7SMjdkJLlzPjvu6X9qpeb17fZbYNX2zs00jgAIBC75jZNjJuz9SveCVcdw8Ann/oQ8HtO26yZ/f/vMdOrPlIi1lIGatydowVZ47fmql3+xjXvleVkXd2QiKBYickEih2QiKBYickEih2QiKBYickEhay/NMuAJ8EMKiqFyfb7gbwOQBDydPuUtUn5t0XBAWEE01mYFtNrRIO88nJcJ0zADj2xFazbcvLvzHbih85z2yrFMJ2R9c+2/BoH7LttbFNdtJNy6tHzbbih3vNttFS2JZ735aTZp/XLrDHatWhDrOtMGE2YXJzeKy0wznP+XSr/E5ttxODVvwibLG9+e0LzD7/eqttod1z3sNmW2cuXfxWjUX3Tmwl3TjJOAu5s38HwHWB7V9X1e3Jz7xCJ4Q0lnnFrqrPAhjOIBZCSB1Zynf2O0Rkr4jsEpE1NYuIEFIX0or9mwDOB7AdwAkA91hPFJEdItIvIv2nTtvfXwkh9SWV2FV1QFXLqloBcB+Ay53n7lTVPlXt615rT0gRQupLKrGLSM+cPz8FYF9twiGE1IuFWG/fB3A1gG4ROQrgywCuFpHtqJaVOwzg80sNxMqGA+ylnP7hwPVmn9UH7a8Msx+0raZSu/3+t/JguK31jH2swrhtNa3vnzTbKqN2BliT3Q0Hx8P15HpXOHOsv2c3vbplgx1HwY5xbftMcHtXmx38urZxs216nX2pVpxMutc7wuORe8SuUXhw0F4O6+RWO3vwTMXOpjwnb7/uzlw4fsuSq7L4rLd5xa6qtwQ2f2u+foSQ5QX/g46QSKDYCYkEip2QSKDYCYkEip2QSMi04KSHV3Dy22fDRQNninb4Q38WtusAoFKyDYpmxxrqaAvbSaNl+5+Fxt6wM/POC6/UBABouuBcs2316/ZrO/bwtuD2/VdsNPvccnG/2fbB1cfNtqmyvQBXzlieyLPJpsp2tllHU3jsAaAtb1teG9vC9uCPP3KJ2We1YRsCwJ6pXrOtova985K2I2bbunw4xq6cfZ5bjWFUR0e8sxMSCRQ7IZFAsRMSCRQ7IZFAsRMSCRQ7IZGQ+VpvBQnbVL+atUP59xc/Ftze5lgk53SfMduGJ9rNtq4O23prL4StkPFZe62xaWett1K7bdnNrnIKPY7ZWXbdL4WLL0722OvDbfvwkNmWF7uI4o+GwpYoABwZDRcvUsd6m5i2rbdczraUVrXbBScLRhHIznNH7f21TZttPzt9odnW23HabGvJ2fbgrpGPBrdfteaA2efmzpfNNgve2QmJBIqdkEig2AmJBIqdkEig2AmJhGWTCHOyZNcEU2NCeGrKnr0tl+33sUrFnhE+ObzSbFvVGZ71LTnHmt1gz8K++Ql7+AvOLH5h3DltxqR1cbM9w/zYwKVm22+O2zXoOlfYs+ClSnhMJidt50Kd85J3loYaqdjuijWLL0aiDgCMTtsxem1eks//7N5utm38adiVuffaXrPPH1/zSnB72alCxzs7IZFAsRMSCRQ7IZFAsRMSCRQ7IZFAsRMSCQtZ/mkLgO8C2AigAmCnqn5DRLoAPAigF9UloD6jqiNpAzlTtu2T9hXhhBfPPimV7CQTLxmj0Gwv17R1VXgJpSYj2QIAznTaSySdGLVtvtERezxmx5zTZtUmc+zBQ0+F69YBwMb9dtLN+CY7xsnfDycUlacWbxsCgDbZ8Xs2q2W95Rwrz7t2PAvw18fsOn+r9tn1+gpT4Wuuc59t8712VXiJqhlHggu5s5cAfElV3w/gCgBfEJGLANwJ4BlVvRDAM8nfhJBlyrxiV9UTqroneTwGYD+ATQBuBHB/8rT7AdxUryAJIUtnUd/ZRaQXwKUAngOwQVVPANU3BADrax0cIaR2LFjsIrICwCMAvqiqdub/b/fbISL9ItI/dNr+/kcIqS8LEruIFFAV+vdU9dFk84CI9CTtPQAGQ31Vdaeq9qlq37q19sQHIaS+zCt2ERFU12Pfr6r3zml6HMBtyePbAPyw9uERQmrFQrLergRwK4CXROSFZNtdAL4K4CERuR3AEQCfnm9HCqCo4Y/yA0V7maTWQtiaWNFi16CbdZZk8ljrLP+0vnU8uL3sWHk5x0+abLOz9macmnwzTnYYDKup9bBt46w+YNtJU132/aDzqG1TTrzRFm7YamfKVYr2sZpa7GPl886SR4Yt6llozui6mW04aY9xy1k7xulV4WvVWU0KB2fC2Ygz+obZZ16xq+rPYb/+T8zXnxCyPOB/0BESCRQ7IZFAsRMSCRQ7IZFAsRMSCZkWnKxAMaNhC2Xf2Dlmv1NDncHtZ1rsrKumgv3fegXDygOAslEoEQCmSuHMpZ72s2aflrx9LA9x/R/H6hsNn9KOY7b10zxqj9XUWscCXGnbmy2nwzF299lZWW1NdnHO5pwdY85Zoqqktf1HrjPThqUIoDhh28dl22XF1LrwWKmjzslKeIeeNcg7OyGRQLETEgkUOyGRQLETEgkUOyGRQLETEgmZWm8KoGhkgf3iV79j9jv3yXCfUqsdvuZtC6JcsNtKrWYTTq4J9zu0fpPZJ1e0j9U6ZLfNbHMKfbTbbVIK77N1xLanih32e/50tx1jxa6hiCYjue3IQJfdySs46WWbpUCM7EDAz4jzrK2CMfYAIGWnOGq70ea85LOlsAVYdu7fvLMTEgkUOyGRQLETEgkUOyGRQLETEgmZzsZDFWU1luOZtqcem0fCteZyHXb4+Vl7RlWdLBOv7ldpMJxUsfKQM0M7ac+ctw5Om21DEyvMtjNXzZptouEp8sK4HUep3U4WqThXiDsbXwyf58qks0OnlpxbGM7D2KVzJFScFy0F+7rK2yURUex0rpGJ8HZjwh0AMDQbTg4rVuxzyTs7IZFAsRMSCRQ7IZFAsRMSCRQ7IZFAsRMSCfNabyKyBcB3AWwEUAGwU1W/ISJ3A/gcgKHkqXep6hPevsoQjBmJBLnN9rJLYvhhrQNOn9l0td8qbbafVCmEa955STdSsk0eL8bOI3bb8JgdY8toOBbLvgSA6bUdZps4+ThNk05du7FwW8tJ+5LzrCZtso/ltZmWnee9ObfAtkP22K/fbY/xRI9ThM4IcrrbtvkOjHYHt884tuFCfPYSgC+p6h4R6QSwW0SeTtq+rqr/vIB9EEIazELWejsB4ETyeExE9gOwczoJIcuSRX1nF5FeAJcCeC7ZdIeI7BWRXSKypsaxEUJqyILFLiIrADwC4IuqOgrgmwDOB7Ad1Tv/PUa/HSLSLyL9I8P2dxBCSH1ZkNhFpICq0L+nqo8CgKoOqGpZVSsA7gNweaivqu5U1T5V7VvjrPVNCKkv86pPRATAtwDsV9V752zvmfO0TwHYV/vwCCG1YiGz8VcCuBXASyLyQrLtLgC3iMh2VE2MwwA+P9+ORsrtePjsZcG2revsZYFmunqC29t3/9rso3k7+0dLtq1VvPJis+34VeHh8jLl8jPOEklnbDvG22duyv46tOLNsKfUdMIe35a1duG91mE7ECtbCwBWHgpn9OWK9rGmu5y6gc12HJUWOw4rCczL2Cu32r5ck+32Il90Mi2d8zm1wcgQ7LaXwxqeCNvApbJ9oIXMxv8cYSPQ9dQJIcsLfokmJBIodkIigWInJBIodkIigWInJBIyLTg5WmrF0wPvC7ZNl+xQxj4Qbuv4RbjoHgCUh4bMNuRsO2xyg+3JFLvCKWDWkksAoHn7/XR2jW3VtA7YMbYft/fZPhi2a3TS9oxaT9mFL8fOtc+LU9sQsyvD4+hZXhVnWa6ysyxXxUkoKzcbtpbTp1KwrbfxXrttsscO0rPeyqvDVnBzm229eRabBe/shEQCxU5IJFDshEQCxU5IJFDshEQCxU5IJGRqvZXKOZw2snUmJ53UJaPw3plrzje7dBzfbLaVW+z3uGK7bf90HAoPlzg1OXJO3UspO5l53tpmzlv02W1hb2uq+3fNPqXwKQEATJxjB1LqsF/48IfCr63S4gxWwa5uKc12W84pOJnLhY+XyzmFQJ1ilFqxB1+cju7pNPppxe5VnDUyMJ0Lh3d2QiKBYickEih2QiKBYickEih2QiKBYickEjK13hRAqWTYTY5lUF4T9q9OfNyxQUpOWpPrgzhFAz1Pxtyf0+btL5+yzfXsjDDy9mtOY2t55J3X7NphzsvyLC/PirL72G0Vp9E7lnfliNEvxdXmxs47OyGRQLETEgkUOyGRQLETEgkUOyGRMO9svIi0AngWQEvy/IdV9csisg3AAwC6AOwBcKuqzro7U0HF+Of+poKdMWK1VTrs2c+8M2OddvbWmumsOPXAvP15cbgz9csEb/bcwptV92aS3bFy8PZp4b2uXM5OyPHOdbmcwiVJ46w4XRZyZ58BcI2qXoLq8szXicgVAL4G4OuqeiGAEQC3LzoyQkhmzCt2rTKe/FlIfhTANQAeTrbfD+CmukRICKkJC12fPZ+s4DoI4GkArwM4o6pvfb4+CmBTfUIkhNSCBYldVcuquh3AZgCXA3h/6GmhviKyQ0T6RaS/POqs8UsIqSuLmo1X1TMAfgrgCgCrReStCb7NAI4bfXaqap+q9uVXdiwlVkLIEphX7CKyTkRWJ4/bAPwhgP0AfgLg5uRptwH4Yb2CJIQsnYUkwvQAuF9E8qi+OTykqj8SkVcAPCAiXwHwKwDfWsgBLWsgjR2W1l7LO4kfljVY3Wd4u1NmzrXlcl4CSgpbyyOtdVVrPGuo7IyVW9/Ns5tS2YPprquKU58u59xWrX5l2+VLxbxiV9W9AC4NbD+I6vd3Qsi7AP4HHSGRQLETEgkUOyGRQLETEgkUOyGRIJomLSjtwUSGALyR/NkN4FRmB7dhHG+Hcbydd1scW1V1XaghU7G/7cAi/ara15CDMw7GEWEc/BhPSCRQ7IREQiPFvrOBx54L43g7jOPtvGfiaNh3dkJItvBjPCGR0BCxi8h1IvIbETkgInc2IoYkjsMi8pKIvCAi/Rked5eIDIrIvjnbukTkaRF5Lfm9pkFx3C0ix5IxeUFEbsggji0i8hMR2S8iL4vIXyfbMx0TJ45Mx0REWkXklyLyYhLH3yfbt4nIc8l4PCgizhpnAVQ10x8AeVTLWp0HoBnAiwAuyjqOJJbDALobcNyPAbgMwL452/4RwJ3J4zsBfK1BcdwN4G8yHo8eAJcljzsBvArgoqzHxIkj0zFBdTXCFcnjAoDnUC0Y8xCAzybb/w3AXy1mv424s18O4ICqHtRq6ekHANzYgDgahqo+C2D4HZtvRLVwJ5BRAU8jjsxR1ROquid5PIZqcZRNyHhMnDgyRavUvMhrI8S+CcCbc/5uZLFKBfCUiOwWkR0NiuEtNqjqCaB60QFY38BY7hCRvcnH/Lp/nZiLiPSiWj/hOTRwTN4RB5DxmNSjyGsjxB6qK9IoS+BKVb0MwPUAviAiH2tQHMuJbwI4H9U1Ak4AuCerA4vICgCPAPiiqo5mddwFxJH5mOgSirxaNELsRwFsmfO3Wayy3qjq8eT3IIDH0NjKOwMi0gMAye/BRgShqgPJhVYBcB8yGhMRKaAqsO+p6qPJ5szHJBRHo8YkOfaii7xaNELszwO4MJlZbAbwWQCPZx2EiHSISOdbjwFcC2Cf36uuPI5q4U6ggQU83xJXwqeQwZiIiKBaw3C/qt47pynTMbHiyHpM6lbkNasZxnfMNt6A6kzn6wD+tkExnIeqE/AigJezjAPA91H9OFhE9ZPO7QDWAngGwGvJ764GxfGfAF4CsBdVsfVkEMdHUf1IuhfAC8nPDVmPiRNHpmMC4EOoFnHdi+oby9/NuWZ/CeAAgB8AaFnMfvkfdIREAv+DjpBIoNgJiQSKnZBIoNgJiQSKnZBIoNgJiQSKnZBIoNgJiYT/BxLBY9wCWINSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class for this 1\n",
      "[[2.3925936e-10 1.0000000e+00 5.6845797e-14 4.3043689e-12 4.4440273e-13\n",
      "  1.9210852e-13 1.0372402e-12 5.7237066e-13 2.6933677e-13 5.6719582e-08]]\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(population[0].reshape(CIFAR_IMG,CIFAR_IMG))\n",
    "plt.show()\n",
    "print(f\"Class for this {adversarial_y[15][0]}\")\n",
    "print(model.predict(population[0].reshape(1,CIFAR_IMG,CIFAR_IMG,1) /255.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "xhxCaFZPGPpe",
    "outputId": "35163672-1426-46f3-d021-b87dc280c722"
   },
   "outputs": [],
   "source": [
    "parent1 = tournament(population, model, adversarial[15], adversarial_y[15]) \n",
    "parent2 = tournament(population, model, adversarial[15], adversarial_y[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "colab_type": "code",
    "id": "gORkePYLv4EW",
    "outputId": "17422d1a-b936-43f2-a2c2-33f4cb500bf4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19191f89630>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fd, idx =  plt.subplots(1,2)\n",
    "idx[0].imshow(parent1.reshape(CIFAR_IMG,CIFAR_IMG),cmap=\"gray\")\n",
    "idx[1].imshow(parent2.reshape(CIFAR_IMG,CIFAR_IMG),cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "HZJXShUyHIrS",
    "outputId": "c26ae352-d1a1-4510-9da7-ae5e01d1ec43"
   },
   "outputs": [],
   "source": [
    "child1, child2 = multi_crossover(parent1, parent2,adversarial[15]) # crossover \n",
    "#child1, child2 = add_noise(child1), add_noise(child2) # apply mutation to pixels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "colab_type": "code",
    "id": "72tQ7R_RHZzZ",
    "outputId": "c81cdb63-ed10-42c2-d477-894c5e91bcf7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x191919e6fd0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fd, idx =  plt.subplots(1,2)\n",
    "idx[0].imshow(child1.reshape(CIFAR_IMG,CIFAR_IMG),cmap=\"gray\")\n",
    "idx[1].imshow(child2.reshape(CIFAR_IMG,CIFAR_IMG),cmap=\"gray\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4a3pXLQSwZlT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff between children [-5.633789  -4.149948  -3.062912   0.         5.7095413  9.564171 ]\n",
      "diff between parents [-16.72924    -9.685455   -9.564171   -8.706863   -5.7095413  -4.29274\n",
      "  -3.8920288  -2.7790756  -1.6091766   0.          1.1050491   2.2260437\n",
      "   3.0292664   3.062912    4.149948    4.1768646   5.633789    6.016098\n",
      "   6.0724335  10.647095   17.198486   21.725456 ]\n",
      "diff between p1 and c1 [-16.72924    -9.685455   -9.564171   -5.7095413  -4.29274    -3.8920288\n",
      "  -2.7790756  -1.6091766   0.          1.1050491   2.2260437   3.0292664\n",
      "   3.062912    4.149948    4.1768646   5.633789    6.016098    6.0724335\n",
      "  10.647095   17.198486   21.725456 ]\n",
      "diff between p1 and c2 [-16.72924    -9.685455   -4.29274    -3.8920288  -2.7790756  -1.6091766\n",
      "   0.          1.1050491   2.2260437   3.0292664   4.1768646   6.016098\n",
      "   6.0724335  10.647095   17.198486   21.725456 ]\n",
      "diff between p2 and c1 [0.       8.706863]\n",
      "diff between p2 and c2 [-5.633789  -4.149948  -3.062912   0.         5.7095413  8.706863\n",
      "  9.564171 ]\n"
     ]
    }
   ],
   "source": [
    "print(f\"diff between children {np.unique(child1-child2)}\")\n",
    "print(f\"diff between parents {np.unique(parent1-parent2)}\")\n",
    "print(f\"diff between p1 and c1 {np.unique(parent1-child1)}\")\n",
    "print(f\"diff between p1 and c2 {np.unique(parent1-child2)}\")\n",
    "print(f\"diff between p2 and c1 {np.unique(parent2-child1)}\")\n",
    "print(f\"diff between p2 and c2 {np.unique(parent2-child2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "xEPQapUpILBr",
    "outputId": "ac694765-e044-4f9f-82ee-9c599a2eb431"
   },
   "outputs": [],
   "source": [
    "bb = choose_better_child(child1, child2,adversarial[15],adversarial_y[15][0],model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "UCl4mvK99XYj",
    "outputId": "fd9867bc-0c0a-486e-c393-ad74b8ef6298"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8014106319734277, 0.8013349582518472, 0.8014293794137679, 0.8013389999639673, 0.801335669513062, 0.8016970375516973, 0.8014547042102144, 0.8016758843262608, 0.8013547582777604, 0.801347223031388, 0.8014111625420132, 0.8014605567327152, 0.8010434583413905, 0.8011719988936645, 0.8010114910066083, 0.8013058833605515, 0.8011271281240757, 0.8012682750889641, 0.8015560620109432, 0.8009099338023167, 0.8011529622118293, 0.8015138835952867, 0.8013537464388139, 0.8013613611074951, 0.8012191521013188, 0.8013303732132802, 0.8012963218502285, 0.8012501804726944, 0.8010117911718535, 0.8010794256863534, 0.8013749676485076, 0.8014044027152726, 0.801727108314284, 0.801269038213669, 0.8013271415238595, 0.8012508160211615, 0.8012221824096691, 0.80105104556003, 0.801272201585212, 0.8015308143612893, 0.8014880139641308, 0.8012923082436346, 0.8013355652603554, 0.8013535490432567, 0.8014264977532295, 0.8012615862222893, 0.801383184293186, 0.8011283911010407, 0.8012473973832913, 0.8010615354084115]\n"
     ]
    }
   ],
   "source": [
    "fitness = pop_fitness(model,np.expand_dims(population.reshape(population.shape[0],CIFAR_IMG,CIFAR_IMG),axis=3),img.reshape(CIFAR_IMG,CIFAR_IMG),label) \n",
    "print(fitness)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GA_CIFAR_SSIM_multicrossover.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
